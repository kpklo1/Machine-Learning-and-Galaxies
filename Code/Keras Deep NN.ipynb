{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123, 1600)\n"
     ]
    }
   ],
   "source": [
    "galaxy = np.zeros(1600)\n",
    "for filepath in glob.iglob('../Data/cutouts/galaxyfits/*fits', recursive=True):\n",
    "    fp = Path(filepath)\n",
    "    hdulist = fits.open(fp)\n",
    "    scidata = hdulist[0].data\n",
    "    scidata = scidata.flatten()\n",
    "    galaxy = np.vstack((galaxy,scidata.transpose()))\n",
    "galaxy = galaxy[1:,]\n",
    "print(galaxy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3123"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(galaxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 26.60893512  60.82042313  30.41021156 ...  60.82042313 -19.00638223\n",
      "    1.        ]\n",
      " [ 64.62169957  22.80765867 -11.40382934 ...  -7.60255289 -38.01276445\n",
      "    1.        ]\n",
      " [ 48.78079796 115.3000679  -88.69235992 ... -53.21541595 -31.04232597\n",
      "    1.        ]\n",
      " ...\n",
      " [  0.          69.7310257    8.71637821 ... -17.43275642  47.94008017\n",
      "    1.        ]\n",
      " [  4.35818911  52.29826927  39.22370195 ... -30.50732374 -43.58189106\n",
      "    1.        ]\n",
      " [ 21.79094553  47.94008017  78.44740391 ...  21.79094553 -61.01464748\n",
      "    1.        ]]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((len(galaxy),1))\n",
    "galaxy = np.hstack((galaxy,ones))\n",
    "print(galaxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123, 1600)\n"
     ]
    }
   ],
   "source": [
    "star = np.zeros(1600)\n",
    "count = 0\n",
    "for filepath in glob.iglob('../Data/cutouts/starfits/*fits', recursive=True):\n",
    "    fp = Path(filepath)\n",
    "    hdulist = fits.open(fp)\n",
    "    scidata = hdulist[0].data\n",
    "    scidata = scidata.flatten()\n",
    "    star = np.vstack((star,scidata.transpose()))\n",
    "    count += 1\n",
    "    if count == len(galaxy):\n",
    "        break\n",
    "star = star[1:,]\n",
    "print(star.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.90063822e+01  3.80127645e+01  1.52051058e+01 ... -1.14038293e+02\n",
      "   4.18140409e+01  0.00000000e+00]\n",
      " [ 4.99866815e-12  5.70191467e+01  1.14038293e+01 ... -1.10237017e+02\n",
      "   4.99866815e-12  0.00000000e+00]\n",
      " [-3.80127645e+00  7.22242525e+01  7.60255289e+00 ... -7.60255289e+00\n",
      "   4.94165938e+01  0.00000000e+00]\n",
      " ...\n",
      " [ 3.44787161e+01 -3.76131449e+01 -1.25377150e+01 ... -3.76131449e+01\n",
      "  -3.13442874e+00  0.00000000e+00]\n",
      " [-3.13442874e+01  4.07475736e+01  2.19410012e+01 ... -3.13442874e+01\n",
      "   3.13442874e+01  0.00000000e+00]\n",
      " [ 1.56721437e+01 -3.13442874e+01 -3.76131449e+01 ... -4.38820024e+01\n",
      "   9.40328622e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "zeros = np.zeros((len(star),1))\n",
    "star = np.hstack((star,zeros))\n",
    "print(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack((galaxy,star)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0           1          2          3             4           5     \\\n",
      "0     26.608935   60.820423  30.410212 -19.006382 -4.561532e+01   11.403829   \n",
      "1     64.621700   22.807659 -11.403829  -3.801276  4.998668e-12  125.442123   \n",
      "2     48.780798  115.300068 -88.692360 -35.476944 -3.552714e-15  -53.215416   \n",
      "3      8.716378  -39.223702  13.074567  -4.358189 -3.486551e+01   17.432756   \n",
      "4     -8.716378   17.432756  56.656458 -13.074567  6.537284e+01  -26.149135   \n",
      "...         ...         ...        ...        ...           ...         ...   \n",
      "6241   6.268857   -6.268857  25.075430 -12.537715  9.403286e+00   18.806572   \n",
      "6242 -12.537715   75.226290   3.134429   9.403286 -2.820986e+01   -3.134429   \n",
      "6243  34.478716  -37.613145 -12.537715  12.537715  6.268857e+00    6.268857   \n",
      "6244 -31.344287   40.747574  21.941001  -6.268857  2.194100e+01   15.672144   \n",
      "6245  15.672144  -31.344287 -37.613145 -34.478716  2.194100e+01   34.478716   \n",
      "\n",
      "           6             7          8             9     ...       1590  \\\n",
      "0    -22.807659  4.998668e-12  41.814041  7.602553e+01  ...   7.602553   \n",
      "1     45.615317  3.421149e+01  72.224252  1.900638e+01  ...  41.814041   \n",
      "2    -13.303854  4.434618e+00  44.346180 -3.552714e-15  ... -39.911562   \n",
      "3    -43.581891 -2.179095e+01 -30.507324  3.050732e+01  ...  13.074567   \n",
      "4      0.000000  4.794008e+01 -21.790946  3.922370e+01  ... -26.149135   \n",
      "...         ...           ...        ...           ...  ...        ...   \n",
      "6241   9.403286  2.194100e+01  31.344287 -6.895743e+01  ...  28.209859   \n",
      "6242 -28.209859 -1.567214e+01   9.403286  1.253771e+01  ...   6.268857   \n",
      "6243 -31.344287  2.507543e+01  18.806572  1.253771e+01  ... -37.613145   \n",
      "6244  21.941001 -1.880657e+01 -12.537715  3.761314e+01  ...  28.209859   \n",
      "6245   6.268857 -2.820986e+01 -18.806572 -4.074757e+01  ...  37.613145   \n",
      "\n",
      "           1591       1592          1593       1594       1595        1596  \\\n",
      "0    -26.608935  30.410212  3.801276e+00   3.801276 -15.205106  -11.403829   \n",
      "1     68.422976  -7.602553  4.998668e-12  53.217870  57.019147  -76.025529   \n",
      "2     62.084652  44.346180 -2.660771e+01  66.519270  -8.869236  137.473158   \n",
      "3    -82.805593   4.358189  2.179095e+01   8.716378  47.940080  -21.790946   \n",
      "4     74.089215  -4.358189 -4.358189e+01 -69.731026 -43.581891   30.507324   \n",
      "...         ...        ...           ...        ...        ...         ...   \n",
      "6241 -47.016431  37.613145 -5.955415e+01 -56.419717   3.134429   25.075430   \n",
      "6242 -56.419717  15.672144 -4.701643e+01  -6.268857 -25.075430    0.000000   \n",
      "6243 -15.672144  34.478716 -9.403286e+00 -56.419717  47.016431  -43.882002   \n",
      "6244   9.403286  -6.268857  3.134429e+01 -31.344287  -6.268857   -9.403286   \n",
      "6245 -28.209859 -50.150860  1.880657e+01  21.941001  21.941001    6.268857   \n",
      "\n",
      "           1597        1598       1599  \n",
      "0     72.224252   60.820423 -19.006382  \n",
      "1     26.608935   -7.602553 -38.012764  \n",
      "2    -48.780798  -53.215416 -31.042326  \n",
      "3      0.000000 -100.238349  56.656458  \n",
      "4     -4.358189    8.716378 -21.790946  \n",
      "...         ...         ...        ...  \n",
      "6241 -37.613145   -6.268857  43.882002  \n",
      "6242  -3.134429    0.000000   3.134429  \n",
      "6243   0.000000  -37.613145  -3.134429  \n",
      "6244  47.016431  -31.344287  31.344287  \n",
      "6245   0.000000  -43.882002   9.403286  \n",
      "\n",
      "[6246 rows x 1600 columns] 0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "6241    0.0\n",
      "6242    0.0\n",
      "6243    0.0\n",
      "6244    0.0\n",
      "6245    0.0\n",
      "Name: 1600, Length: 6246, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([1600],axis=1)\n",
    "y = df[1600]\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.93621959e-05,  1.35685019e-04,  6.78425096e-05, ...,\n",
       "         1.61125960e-04,  1.35685019e-04, -4.24015685e-05],\n",
       "       [ 1.67091678e-04,  5.89735333e-05, -2.94867667e-05, ...,\n",
       "         6.88024556e-05, -1.96578444e-05, -9.82892222e-05],\n",
       "       [ 2.28522769e-04,  5.40144726e-04, -4.15495943e-04, ...,\n",
       "        -2.28522769e-04, -2.49297566e-04, -1.45423580e-04],\n",
       "       ...,\n",
       "       [ 1.58349807e-03, -1.72745244e-03, -5.75817480e-04, ...,\n",
       "         0.00000000e+00, -1.72745244e-03, -1.43954370e-04],\n",
       "       [-2.35911285e-03,  3.06684671e-03,  1.65137900e-03, ...,\n",
       "         3.53866928e-03, -2.35911285e-03,  2.35911285e-03],\n",
       "       [ 6.55707920e-04, -1.31141584e-03, -1.57369901e-03, ...,\n",
       "         0.00000000e+00, -1.83598218e-03,  3.93424752e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "transformer = Normalizer().fit(X)\n",
    "transformer\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1590</th>\n",
       "      <th>1591</th>\n",
       "      <th>1592</th>\n",
       "      <th>1593</th>\n",
       "      <th>1594</th>\n",
       "      <th>1595</th>\n",
       "      <th>1596</th>\n",
       "      <th>1597</th>\n",
       "      <th>1598</th>\n",
       "      <th>1599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "      <td>6246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.012327</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>0.014302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.046769</td>\n",
       "      <td>-0.048820</td>\n",
       "      <td>-0.046747</td>\n",
       "      <td>-0.052804</td>\n",
       "      <td>-0.043172</td>\n",
       "      <td>-0.044975</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>-0.039824</td>\n",
       "      <td>-0.226332</td>\n",
       "      <td>-0.109372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>-0.039813</td>\n",
       "      <td>-0.086491</td>\n",
       "      <td>-0.056570</td>\n",
       "      <td>-0.057899</td>\n",
       "      <td>-0.046037</td>\n",
       "      <td>-0.057203</td>\n",
       "      <td>-0.045459</td>\n",
       "      <td>-0.045208</td>\n",
       "      <td>-0.163675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>-0.001454</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.001419</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>-0.001526</td>\n",
       "      <td>-0.001472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>-0.001348</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>-0.001396</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>-0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.001564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.749077</td>\n",
       "      <td>0.477454</td>\n",
       "      <td>0.233318</td>\n",
       "      <td>0.194644</td>\n",
       "      <td>0.156820</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>0.563615</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.524072</td>\n",
       "      <td>0.381915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337170</td>\n",
       "      <td>0.348117</td>\n",
       "      <td>0.256195</td>\n",
       "      <td>0.249393</td>\n",
       "      <td>0.359902</td>\n",
       "      <td>0.464029</td>\n",
       "      <td>0.309904</td>\n",
       "      <td>0.416777</td>\n",
       "      <td>0.448118</td>\n",
       "      <td>0.496360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  6246.000000  6246.000000  6246.000000  6246.000000  6246.000000   \n",
       "mean      0.000532     0.000486     0.000338     0.000296     0.000464   \n",
       "std       0.013333     0.010730     0.009127     0.008808     0.009077   \n",
       "min      -0.046769    -0.048820    -0.046747    -0.052804    -0.043172   \n",
       "25%      -0.001335    -0.001454    -0.001463    -0.001422    -0.001363   \n",
       "50%       0.000028     0.000009     0.000014     0.000019     0.000027   \n",
       "75%       0.001716     0.001667     0.001618     0.001653     0.001638   \n",
       "max       0.749077     0.477454     0.233318     0.194644     0.156820   \n",
       "\n",
       "              5            6            7            8            9     ...  \\\n",
       "count  6246.000000  6246.000000  6246.000000  6246.000000  6246.000000  ...   \n",
       "mean      0.000487     0.000361     0.000509     0.000427     0.000288  ...   \n",
       "std       0.010037     0.012365     0.012497     0.012327     0.010209  ...   \n",
       "min      -0.044975    -0.045145    -0.039824    -0.226332    -0.109372  ...   \n",
       "25%      -0.001419    -0.001452    -0.001504    -0.001526    -0.001472  ...   \n",
       "50%       0.000030     0.000019     0.000035     0.000026     0.000045  ...   \n",
       "75%       0.001633     0.001526     0.001597     0.001476     0.001614  ...   \n",
       "max       0.315806     0.563615     0.499648     0.524072     0.381915  ...   \n",
       "\n",
       "              1590         1591         1592         1593         1594  \\\n",
       "count  6246.000000  6246.000000  6246.000000  6246.000000  6246.000000   \n",
       "mean      0.000649     0.000550     0.000410     0.000222     0.000313   \n",
       "std       0.010240     0.009897     0.009812     0.009531     0.009817   \n",
       "min      -0.043176    -0.039813    -0.086491    -0.056570    -0.057899   \n",
       "25%      -0.001276    -0.001348    -0.001394    -0.001491    -0.001396   \n",
       "50%       0.000048     0.000047     0.000042     0.000019     0.000031   \n",
       "75%       0.001796     0.001596     0.001631     0.001401     0.001592   \n",
       "max       0.337170     0.348117     0.256195     0.249393     0.359902   \n",
       "\n",
       "              1595         1596         1597         1598         1599  \n",
       "count  6246.000000  6246.000000  6246.000000  6246.000000  6246.000000  \n",
       "mean      0.000460     0.000475     0.000501     0.000525     0.000699  \n",
       "std       0.010328     0.010026     0.010827     0.012201     0.014302  \n",
       "min      -0.046037    -0.057203    -0.045459    -0.045208    -0.163675  \n",
       "25%      -0.001397    -0.001305    -0.001434    -0.001432    -0.001381  \n",
       "50%       0.000024     0.000024     0.000012     0.000016     0.000011  \n",
       "75%       0.001641     0.001656     0.001641     0.001589     0.001564  \n",
       "max       0.464029     0.309904     0.416777     0.448118     0.496360  \n",
       "\n",
       "[8 rows x 1600 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(transformer.transform(X))\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "4996/4996 [==============================] - 1s 140us/step - loss: 0.6903 - accuracy: 0.5308\n",
      "Epoch 2/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.5432 - accuracy: 0.7414\n",
      "Epoch 3/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.4269 - accuracy: 0.8233\n",
      "Epoch 4/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.4080 - accuracy: 0.8419\n",
      "Epoch 5/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3917 - accuracy: 0.8553\n",
      "Epoch 6/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.3787 - accuracy: 0.8639\n",
      "Epoch 7/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.3760 - accuracy: 0.8661\n",
      "Epoch 8/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.3600 - accuracy: 0.8699\n",
      "Epoch 9/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.3485 - accuracy: 0.8757\n",
      "Epoch 10/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3455 - accuracy: 0.8743\n",
      "Epoch 11/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3356 - accuracy: 0.8793\n",
      "Epoch 12/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.3305 - accuracy: 0.8897\n",
      "Epoch 13/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.3258 - accuracy: 0.8845\n",
      "Epoch 14/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3106 - accuracy: 0.8921\n",
      "Epoch 15/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.3028 - accuracy: 0.8965\n",
      "Epoch 16/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.2952 - accuracy: 0.8991\n",
      "Epoch 17/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.2916 - accuracy: 0.9007\n",
      "Epoch 18/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.2828 - accuracy: 0.9041\n",
      "Epoch 19/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2811 - accuracy: 0.9083\n",
      "Epoch 20/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.2745 - accuracy: 0.9043\n",
      "Epoch 21/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2594 - accuracy: 0.9101\n",
      "Epoch 22/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2570 - accuracy: 0.9115\n",
      "Epoch 23/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2653 - accuracy: 0.9119\n",
      "Epoch 24/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2523 - accuracy: 0.9151\n",
      "Epoch 25/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2550 - accuracy: 0.9189\n",
      "Epoch 26/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2520 - accuracy: 0.9189\n",
      "Epoch 27/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2400 - accuracy: 0.9179\n",
      "Epoch 28/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2371 - accuracy: 0.9193\n",
      "Epoch 29/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2180 - accuracy: 0.9247\n",
      "Epoch 30/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2185 - accuracy: 0.9255\n",
      "Epoch 31/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2306 - accuracy: 0.9241\n",
      "Epoch 32/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2255 - accuracy: 0.9229\n",
      "Epoch 33/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2090 - accuracy: 0.9329\n",
      "Epoch 34/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2101 - accuracy: 0.9273\n",
      "Epoch 35/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1977 - accuracy: 0.9325\n",
      "Epoch 36/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.2021 - accuracy: 0.9359\n",
      "Epoch 37/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2003 - accuracy: 0.9315\n",
      "Epoch 38/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1921 - accuracy: 0.9329\n",
      "Epoch 39/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1981 - accuracy: 0.9335\n",
      "Epoch 40/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1884 - accuracy: 0.9351\n",
      "Epoch 41/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1911 - accuracy: 0.9378\n",
      "Epoch 42/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1778 - accuracy: 0.9386\n",
      "Epoch 43/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1901 - accuracy: 0.9335\n",
      "Epoch 44/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1786 - accuracy: 0.9392\n",
      "Epoch 45/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1796 - accuracy: 0.9404\n",
      "Epoch 46/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1758 - accuracy: 0.9396\n",
      "Epoch 47/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1789 - accuracy: 0.9412\n",
      "Epoch 48/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1795 - accuracy: 0.9418\n",
      "Epoch 49/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1666 - accuracy: 0.9394\n",
      "Epoch 50/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1658 - accuracy: 0.9464\n",
      "Epoch 51/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1714 - accuracy: 0.9400\n",
      "Epoch 52/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1689 - accuracy: 0.9448\n",
      "Epoch 53/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1652 - accuracy: 0.9458\n",
      "Epoch 54/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1635 - accuracy: 0.9432\n",
      "Epoch 55/1024\n",
      "4996/4996 [==============================] - 0s 76us/step - loss: 0.1617 - accuracy: 0.9468\n",
      "Epoch 56/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1622 - accuracy: 0.9446\n",
      "Epoch 57/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1602 - accuracy: 0.9486\n",
      "Epoch 58/1024\n",
      "4996/4996 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.94 - 0s 69us/step - loss: 0.1611 - accuracy: 0.9432\n",
      "Epoch 59/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.1503 - accuracy: 0.9508\n",
      "Epoch 60/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1475 - accuracy: 0.9498\n",
      "Epoch 61/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1540 - accuracy: 0.9454\n",
      "Epoch 62/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1447 - accuracy: 0.9528\n",
      "Epoch 63/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1514 - accuracy: 0.9488\n",
      "Epoch 64/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1519 - accuracy: 0.9490\n",
      "Epoch 65/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1616 - accuracy: 0.9476\n",
      "Epoch 66/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1416 - accuracy: 0.9544\n",
      "Epoch 67/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1426 - accuracy: 0.9522\n",
      "Epoch 68/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1425 - accuracy: 0.9526\n",
      "Epoch 69/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1399 - accuracy: 0.9558\n",
      "Epoch 70/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1460 - accuracy: 0.9516\n",
      "Epoch 71/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1447 - accuracy: 0.9486\n",
      "Epoch 72/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1408 - accuracy: 0.9540\n",
      "Epoch 73/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1410 - accuracy: 0.9530\n",
      "Epoch 74/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1443 - accuracy: 0.9560\n",
      "Epoch 75/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1432 - accuracy: 0.9526\n",
      "Epoch 76/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1376 - accuracy: 0.9560\n",
      "Epoch 77/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1461 - accuracy: 0.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1385 - accuracy: 0.9494\n",
      "Epoch 79/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1480 - accuracy: 0.9528\n",
      "Epoch 80/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1365 - accuracy: 0.9530\n",
      "Epoch 81/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1360 - accuracy: 0.9546\n",
      "Epoch 82/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1408 - accuracy: 0.9488\n",
      "Epoch 83/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1321 - accuracy: 0.9534\n",
      "Epoch 84/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1339 - accuracy: 0.9560\n",
      "Epoch 85/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1307 - accuracy: 0.9554\n",
      "Epoch 86/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1345 - accuracy: 0.9518\n",
      "Epoch 87/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1426 - accuracy: 0.9498\n",
      "Epoch 88/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1349 - accuracy: 0.9552\n",
      "Epoch 89/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1321 - accuracy: 0.9602\n",
      "Epoch 90/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1284 - accuracy: 0.9570\n",
      "Epoch 91/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1274 - accuracy: 0.9572\n",
      "Epoch 92/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1327 - accuracy: 0.9544\n",
      "Epoch 93/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1221 - accuracy: 0.9578\n",
      "Epoch 94/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1305 - accuracy: 0.9568\n",
      "Epoch 95/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1309 - accuracy: 0.9552\n",
      "Epoch 96/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1260 - accuracy: 0.9572\n",
      "Epoch 97/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1268 - accuracy: 0.9566\n",
      "Epoch 98/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1278 - accuracy: 0.9576\n",
      "Epoch 99/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1230 - accuracy: 0.9564\n",
      "Epoch 100/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1246 - accuracy: 0.9576\n",
      "Epoch 101/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1247 - accuracy: 0.9546\n",
      "Epoch 102/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1392 - accuracy: 0.9536\n",
      "Epoch 103/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1264 - accuracy: 0.9580\n",
      "Epoch 104/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1246 - accuracy: 0.9582\n",
      "Epoch 105/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1214 - accuracy: 0.9560\n",
      "Epoch 106/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1198 - accuracy: 0.9560\n",
      "Epoch 107/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1275 - accuracy: 0.9588\n",
      "Epoch 108/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1126 - accuracy: 0.9608\n",
      "Epoch 109/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1192 - accuracy: 0.9586\n",
      "Epoch 110/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1185 - accuracy: 0.9584\n",
      "Epoch 111/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1204 - accuracy: 0.9546\n",
      "Epoch 112/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1283 - accuracy: 0.9576\n",
      "Epoch 113/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1232 - accuracy: 0.9568\n",
      "Epoch 114/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1262 - accuracy: 0.9574\n",
      "Epoch 115/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.1233 - accuracy: 0.9596\n",
      "Epoch 116/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1151 - accuracy: 0.9588\n",
      "Epoch 117/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.1262 - accuracy: 0.9562\n",
      "Epoch 118/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1136 - accuracy: 0.9592\n",
      "Epoch 119/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.1204 - accuracy: 0.9602\n",
      "Epoch 120/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1210 - accuracy: 0.9574\n",
      "Epoch 121/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1169 - accuracy: 0.9622\n",
      "Epoch 122/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1118 - accuracy: 0.9606\n",
      "Epoch 123/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1147 - accuracy: 0.9570\n",
      "Epoch 124/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1192 - accuracy: 0.9586\n",
      "Epoch 125/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1112 - accuracy: 0.9606\n",
      "Epoch 126/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1081 - accuracy: 0.9600\n",
      "Epoch 127/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1132 - accuracy: 0.9594\n",
      "Epoch 128/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1196 - accuracy: 0.9582\n",
      "Epoch 129/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1099 - accuracy: 0.9624\n",
      "Epoch 130/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1104 - accuracy: 0.9628\n",
      "Epoch 131/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1083 - accuracy: 0.9628\n",
      "Epoch 132/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1092 - accuracy: 0.9612\n",
      "Epoch 133/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1212 - accuracy: 0.9564\n",
      "Epoch 134/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1102 - accuracy: 0.9624\n",
      "Epoch 135/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1148 - accuracy: 0.9590\n",
      "Epoch 136/1024\n",
      "4996/4996 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.96 - 0s 67us/step - loss: 0.1100 - accuracy: 0.9610\n",
      "Epoch 137/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1120 - accuracy: 0.9600\n",
      "Epoch 138/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1135 - accuracy: 0.9622\n",
      "Epoch 139/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1088 - accuracy: 0.9596\n",
      "Epoch 140/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1125 - accuracy: 0.9624\n",
      "Epoch 141/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1213 - accuracy: 0.9596\n",
      "Epoch 142/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1139 - accuracy: 0.9612\n",
      "Epoch 143/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1148 - accuracy: 0.9606\n",
      "Epoch 144/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1070 - accuracy: 0.9640\n",
      "Epoch 145/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1136 - accuracy: 0.9608\n",
      "Epoch 146/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1092 - accuracy: 0.9636\n",
      "Epoch 147/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1167 - accuracy: 0.9594\n",
      "Epoch 148/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1112 - accuracy: 0.9620\n",
      "Epoch 149/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1109 - accuracy: 0.9598\n",
      "Epoch 150/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.1127 - accuracy: 0.9612\n",
      "Epoch 151/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.1075 - accuracy: 0.9614\n",
      "Epoch 152/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1114 - accuracy: 0.9616\n",
      "Epoch 153/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1095 - accuracy: 0.9596\n",
      "Epoch 154/1024\n",
      "4996/4996 [==============================] - 0s 77us/step - loss: 0.1096 - accuracy: 0.9612\n",
      "Epoch 155/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1039 - accuracy: 0.9622\n",
      "Epoch 156/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1154 - accuracy: 0.9590\n",
      "Epoch 157/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.1032 - accuracy: 0.9612\n",
      "Epoch 158/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.1111 - accuracy: 0.9612\n",
      "Epoch 159/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1156 - accuracy: 0.9586\n",
      "Epoch 160/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1109 - accuracy: 0.9594\n",
      "Epoch 161/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1101 - accuracy: 0.9596\n",
      "Epoch 162/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1104 - accuracy: 0.9642\n",
      "Epoch 163/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1152 - accuracy: 0.9596\n",
      "Epoch 164/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1121 - accuracy: 0.9626\n",
      "Epoch 165/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1094 - accuracy: 0.9618\n",
      "Epoch 166/1024\n",
      "4996/4996 [==============================] - 0s 76us/step - loss: 0.1127 - accuracy: 0.9622\n",
      "Epoch 167/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1024 - accuracy: 0.9658\n",
      "Epoch 168/1024\n",
      "4996/4996 [==============================] - 0s 79us/step - loss: 0.1121 - accuracy: 0.9588\n",
      "Epoch 169/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1168 - accuracy: 0.9604\n",
      "Epoch 170/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1084 - accuracy: 0.9640\n",
      "Epoch 171/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1009 - accuracy: 0.9666\n",
      "Epoch 172/1024\n",
      "4996/4996 [==============================] - 0s 80us/step - loss: 0.1057 - accuracy: 0.9628\n",
      "Epoch 173/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1073 - accuracy: 0.9610\n",
      "Epoch 174/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.0961 - accuracy: 0.9674\n",
      "Epoch 175/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1015 - accuracy: 0.9634\n",
      "Epoch 176/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1155 - accuracy: 0.9580\n",
      "Epoch 177/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1111 - accuracy: 0.9606\n",
      "Epoch 178/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1029 - accuracy: 0.9626\n",
      "Epoch 179/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1090 - accuracy: 0.9600\n",
      "Epoch 180/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1013 - accuracy: 0.9630\n",
      "Epoch 181/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1045 - accuracy: 0.9644\n",
      "Epoch 182/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1115 - accuracy: 0.9612\n",
      "Epoch 183/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0928 - accuracy: 0.9652\n",
      "Epoch 184/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0972 - accuracy: 0.9664\n",
      "Epoch 185/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1004 - accuracy: 0.9652\n",
      "Epoch 186/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1079 - accuracy: 0.9618\n",
      "Epoch 187/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0956 - accuracy: 0.9674\n",
      "Epoch 188/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1131 - accuracy: 0.9606\n",
      "Epoch 189/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1005 - accuracy: 0.9626\n",
      "Epoch 190/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1154 - accuracy: 0.9626\n",
      "Epoch 191/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1025 - accuracy: 0.9630\n",
      "Epoch 192/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1009 - accuracy: 0.9648\n",
      "Epoch 193/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1011 - accuracy: 0.9650\n",
      "Epoch 194/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0998 - accuracy: 0.9644\n",
      "Epoch 195/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.0991 - accuracy: 0.9660\n",
      "Epoch 196/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0932 - accuracy: 0.9650\n",
      "Epoch 197/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1091 - accuracy: 0.9626\n",
      "Epoch 198/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0990 - accuracy: 0.9650\n",
      "Epoch 199/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1038 - accuracy: 0.9614\n",
      "Epoch 200/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0982 - accuracy: 0.9632\n",
      "Epoch 201/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1065 - accuracy: 0.9598\n",
      "Epoch 202/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1032 - accuracy: 0.9618\n",
      "Epoch 203/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1046 - accuracy: 0.9636\n",
      "Epoch 204/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.0995 - accuracy: 0.9622\n",
      "Epoch 205/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1052 - accuracy: 0.9618\n",
      "Epoch 206/1024\n",
      "4996/4996 [==============================] - 0s 79us/step - loss: 0.1076 - accuracy: 0.9624\n",
      "Epoch 207/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1187 - accuracy: 0.9612\n",
      "Epoch 208/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1023 - accuracy: 0.9646\n",
      "Epoch 209/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1016 - accuracy: 0.9656\n",
      "Epoch 210/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0959 - accuracy: 0.9668\n",
      "Epoch 211/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1008 - accuracy: 0.9662\n",
      "Epoch 212/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1086 - accuracy: 0.9614\n",
      "Epoch 213/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0961 - accuracy: 0.9630\n",
      "Epoch 214/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1005 - accuracy: 0.9638\n",
      "Epoch 215/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0975 - accuracy: 0.9656\n",
      "Epoch 216/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1120 - accuracy: 0.9610\n",
      "Epoch 217/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1043 - accuracy: 0.9618\n",
      "Epoch 218/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0989 - accuracy: 0.9638\n",
      "Epoch 219/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1032 - accuracy: 0.9624\n",
      "Epoch 220/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1014 - accuracy: 0.9622\n",
      "Epoch 221/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0905 - accuracy: 0.9680\n",
      "Epoch 222/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1114 - accuracy: 0.9628\n",
      "Epoch 223/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1022 - accuracy: 0.9634\n",
      "Epoch 224/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1051 - accuracy: 0.9604\n",
      "Epoch 225/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.1064 - accuracy: 0.9624\n",
      "Epoch 226/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0965 - accuracy: 0.9620\n",
      "Epoch 227/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0996 - accuracy: 0.9648\n",
      "Epoch 228/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1086 - accuracy: 0.9624\n",
      "Epoch 229/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.0971 - accuracy: 0.9652\n",
      "Epoch 230/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1021 - accuracy: 0.9644\n",
      "Epoch 231/1024\n",
      "4996/4996 [==============================] - 0s 74us/step - loss: 0.0928 - accuracy: 0.9676\n",
      "Epoch 232/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0996 - accuracy: 0.9662\n",
      "Epoch 233/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0985 - accuracy: 0.9654\n",
      "Epoch 234/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0971 - accuracy: 0.9648\n",
      "Epoch 235/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1081 - accuracy: 0.9632\n",
      "Epoch 236/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0922 - accuracy: 0.9660\n",
      "Epoch 237/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1018 - accuracy: 0.9646\n",
      "Epoch 238/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1016 - accuracy: 0.9604\n",
      "Epoch 239/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1024 - accuracy: 0.9634\n",
      "Epoch 240/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1043 - accuracy: 0.9638\n",
      "Epoch 241/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1048 - accuracy: 0.9650\n",
      "Epoch 242/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0998 - accuracy: 0.9630\n",
      "Epoch 243/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0927 - accuracy: 0.9684\n",
      "Epoch 244/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0941 - accuracy: 0.9668\n",
      "Epoch 245/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1008 - accuracy: 0.9666\n",
      "Epoch 246/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0949 - accuracy: 0.9678\n",
      "Epoch 247/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0896 - accuracy: 0.9672\n",
      "Epoch 248/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1030 - accuracy: 0.9664\n",
      "Epoch 249/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1006 - accuracy: 0.9626\n",
      "Epoch 250/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0947 - accuracy: 0.9698\n",
      "Epoch 251/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0988 - accuracy: 0.9648\n",
      "Epoch 252/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0972 - accuracy: 0.9648\n",
      "Epoch 253/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0898 - accuracy: 0.9676\n",
      "Epoch 254/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1021 - accuracy: 0.9624\n",
      "Epoch 255/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0952 - accuracy: 0.9698\n",
      "Epoch 256/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0944 - accuracy: 0.9656\n",
      "Epoch 257/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0941 - accuracy: 0.9660\n",
      "Epoch 258/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0962 - accuracy: 0.9656\n",
      "Epoch 259/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0919 - accuracy: 0.9652\n",
      "Epoch 260/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1012 - accuracy: 0.9652\n",
      "Epoch 261/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1022 - accuracy: 0.9634\n",
      "Epoch 262/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0992 - accuracy: 0.9644\n",
      "Epoch 263/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0918 - accuracy: 0.9650\n",
      "Epoch 264/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1064 - accuracy: 0.9654\n",
      "Epoch 265/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0958 - accuracy: 0.9656\n",
      "Epoch 266/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0929 - accuracy: 0.9674\n",
      "Epoch 267/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0884 - accuracy: 0.9672\n",
      "Epoch 268/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0964 - accuracy: 0.9632\n",
      "Epoch 269/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0993 - accuracy: 0.9644\n",
      "Epoch 270/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0893 - accuracy: 0.9682\n",
      "Epoch 271/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0916 - accuracy: 0.9664\n",
      "Epoch 272/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1045 - accuracy: 0.9646\n",
      "Epoch 273/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0912 - accuracy: 0.9682\n",
      "Epoch 274/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1067 - accuracy: 0.9592\n",
      "Epoch 275/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0943 - accuracy: 0.9664\n",
      "Epoch 276/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0980 - accuracy: 0.9644\n",
      "Epoch 277/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0874 - accuracy: 0.9650\n",
      "Epoch 278/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1003 - accuracy: 0.9656\n",
      "Epoch 279/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0919 - accuracy: 0.9676\n",
      "Epoch 280/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0954 - accuracy: 0.9640\n",
      "Epoch 281/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0916 - accuracy: 0.9660\n",
      "Epoch 282/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0938 - accuracy: 0.9676\n",
      "Epoch 283/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0948 - accuracy: 0.9672\n",
      "Epoch 284/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1010 - accuracy: 0.9670\n",
      "Epoch 285/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0933 - accuracy: 0.9682\n",
      "Epoch 286/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0920 - accuracy: 0.9688\n",
      "Epoch 287/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0947 - accuracy: 0.9678\n",
      "Epoch 288/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0871 - accuracy: 0.9656\n",
      "Epoch 289/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1021 - accuracy: 0.9654\n",
      "Epoch 290/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0897 - accuracy: 0.9656\n",
      "Epoch 291/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0885 - accuracy: 0.9682\n",
      "Epoch 292/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0937 - accuracy: 0.9672\n",
      "Epoch 293/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1004 - accuracy: 0.9662\n",
      "Epoch 294/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0931 - accuracy: 0.9668\n",
      "Epoch 295/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0900 - accuracy: 0.9684\n",
      "Epoch 296/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0972 - accuracy: 0.9670\n",
      "Epoch 297/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0877 - accuracy: 0.9684\n",
      "Epoch 298/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0962 - accuracy: 0.9668\n",
      "Epoch 299/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0878 - accuracy: 0.9678\n",
      "Epoch 300/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0940 - accuracy: 0.9658\n",
      "Epoch 301/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0993 - accuracy: 0.9640\n",
      "Epoch 302/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0861 - accuracy: 0.9680\n",
      "Epoch 303/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0921 - accuracy: 0.9648\n",
      "Epoch 304/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1007 - accuracy: 0.9636\n",
      "Epoch 305/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0942 - accuracy: 0.9670\n",
      "Epoch 306/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1085 - accuracy: 0.9654\n",
      "Epoch 307/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0846 - accuracy: 0.9684\n",
      "Epoch 308/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1050 - accuracy: 0.9650\n",
      "Epoch 309/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0900 - accuracy: 0.9714\n",
      "Epoch 310/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0948 - accuracy: 0.9662\n",
      "Epoch 311/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0918 - accuracy: 0.9656\n",
      "Epoch 312/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0952 - accuracy: 0.9678\n",
      "Epoch 313/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0922 - accuracy: 0.9648\n",
      "Epoch 314/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0967 - accuracy: 0.9668\n",
      "Epoch 315/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0996 - accuracy: 0.9634\n",
      "Epoch 316/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0853 - accuracy: 0.9710\n",
      "Epoch 317/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0894 - accuracy: 0.9674\n",
      "Epoch 318/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0948 - accuracy: 0.9690\n",
      "Epoch 319/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0920 - accuracy: 0.9654\n",
      "Epoch 320/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0982 - accuracy: 0.9662\n",
      "Epoch 321/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0989 - accuracy: 0.9658\n",
      "Epoch 322/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0872 - accuracy: 0.9688\n",
      "Epoch 323/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1056 - accuracy: 0.9658\n",
      "Epoch 324/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0921 - accuracy: 0.9670\n",
      "Epoch 325/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0906 - accuracy: 0.9646\n",
      "Epoch 326/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1008 - accuracy: 0.9628\n",
      "Epoch 327/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0901 - accuracy: 0.9648\n",
      "Epoch 328/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0971 - accuracy: 0.9634\n",
      "Epoch 329/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0945 - accuracy: 0.9664\n",
      "Epoch 330/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0970 - accuracy: 0.9642\n",
      "Epoch 331/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0905 - accuracy: 0.9674\n",
      "Epoch 332/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0840 - accuracy: 0.9690\n",
      "Epoch 333/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0947 - accuracy: 0.9662\n",
      "Epoch 334/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1000 - accuracy: 0.9652\n",
      "Epoch 335/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0913 - accuracy: 0.9658\n",
      "Epoch 336/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0882 - accuracy: 0.9678\n",
      "Epoch 337/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0837 - accuracy: 0.9710\n",
      "Epoch 338/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0930 - accuracy: 0.9666\n",
      "Epoch 339/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0862 - accuracy: 0.9684\n",
      "Epoch 340/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0964 - accuracy: 0.9672\n",
      "Epoch 341/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1001 - accuracy: 0.9628\n",
      "Epoch 342/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0972 - accuracy: 0.9664\n",
      "Epoch 343/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0958 - accuracy: 0.9650\n",
      "Epoch 344/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0955 - accuracy: 0.9660\n",
      "Epoch 345/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1061 - accuracy: 0.9628\n",
      "Epoch 346/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0860 - accuracy: 0.9700\n",
      "Epoch 347/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0968 - accuracy: 0.9654\n",
      "Epoch 348/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1023 - accuracy: 0.9660\n",
      "Epoch 349/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0959 - accuracy: 0.9652\n",
      "Epoch 350/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0927 - accuracy: 0.9660\n",
      "Epoch 351/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0972 - accuracy: 0.9650\n",
      "Epoch 352/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0889 - accuracy: 0.9678\n",
      "Epoch 353/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0792 - accuracy: 0.9690\n",
      "Epoch 354/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0970 - accuracy: 0.9676\n",
      "Epoch 355/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1009 - accuracy: 0.9658\n",
      "Epoch 356/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0920 - accuracy: 0.9662\n",
      "Epoch 357/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0893 - accuracy: 0.9702\n",
      "Epoch 358/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0868 - accuracy: 0.9700\n",
      "Epoch 359/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0961 - accuracy: 0.9636\n",
      "Epoch 360/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0831 - accuracy: 0.9682\n",
      "Epoch 361/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0894 - accuracy: 0.9680\n",
      "Epoch 362/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0877 - accuracy: 0.9670\n",
      "Epoch 363/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0919 - accuracy: 0.9688\n",
      "Epoch 364/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0868 - accuracy: 0.9654\n",
      "Epoch 365/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0918 - accuracy: 0.9676\n",
      "Epoch 366/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0865 - accuracy: 0.9680\n",
      "Epoch 367/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0924 - accuracy: 0.9666\n",
      "Epoch 368/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1000 - accuracy: 0.9652\n",
      "Epoch 369/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0954 - accuracy: 0.9662\n",
      "Epoch 370/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0910 - accuracy: 0.9676\n",
      "Epoch 371/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0914 - accuracy: 0.9684\n",
      "Epoch 372/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0889 - accuracy: 0.9654\n",
      "Epoch 373/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0899 - accuracy: 0.9682\n",
      "Epoch 374/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0922 - accuracy: 0.9654\n",
      "Epoch 375/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0871 - accuracy: 0.9686\n",
      "Epoch 376/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0954 - accuracy: 0.9662\n",
      "Epoch 377/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0804 - accuracy: 0.9694\n",
      "Epoch 378/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0943 - accuracy: 0.9658\n",
      "Epoch 379/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0901 - accuracy: 0.9670\n",
      "Epoch 380/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0929 - accuracy: 0.9656\n",
      "Epoch 381/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9664\n",
      "Epoch 382/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0934 - accuracy: 0.9660\n",
      "Epoch 383/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0962 - accuracy: 0.9652\n",
      "Epoch 384/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0915 - accuracy: 0.9716\n",
      "Epoch 385/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0956 - accuracy: 0.9672\n",
      "Epoch 386/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1035 - accuracy: 0.9650\n",
      "Epoch 387/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0841 - accuracy: 0.9680\n",
      "Epoch 388/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0995 - accuracy: 0.9654\n",
      "Epoch 389/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0844 - accuracy: 0.9690\n",
      "Epoch 390/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0917 - accuracy: 0.9634\n",
      "Epoch 391/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0956 - accuracy: 0.9650\n",
      "Epoch 392/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0990 - accuracy: 0.9638\n",
      "Epoch 393/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0861 - accuracy: 0.9682\n",
      "Epoch 394/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1002 - accuracy: 0.9632\n",
      "Epoch 395/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0934 - accuracy: 0.9666\n",
      "Epoch 396/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0821 - accuracy: 0.9686\n",
      "Epoch 397/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0937 - accuracy: 0.9694\n",
      "Epoch 398/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0832 - accuracy: 0.9664\n",
      "Epoch 399/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0915 - accuracy: 0.9684\n",
      "Epoch 400/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0846 - accuracy: 0.9680\n",
      "Epoch 401/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0777 - accuracy: 0.9708\n",
      "Epoch 402/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0855 - accuracy: 0.9682\n",
      "Epoch 403/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0927 - accuracy: 0.9690\n",
      "Epoch 404/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0834 - accuracy: 0.9704\n",
      "Epoch 405/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0923 - accuracy: 0.9666\n",
      "Epoch 406/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0951 - accuracy: 0.9678\n",
      "Epoch 407/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0882 - accuracy: 0.9676\n",
      "Epoch 408/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0893 - accuracy: 0.9702\n",
      "Epoch 409/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0900 - accuracy: 0.9698\n",
      "Epoch 410/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0898 - accuracy: 0.9664\n",
      "Epoch 411/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0954 - accuracy: 0.9672\n",
      "Epoch 412/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0958 - accuracy: 0.9676\n",
      "Epoch 413/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0894 - accuracy: 0.9684\n",
      "Epoch 414/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0902 - accuracy: 0.9660\n",
      "Epoch 415/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0823 - accuracy: 0.9716\n",
      "Epoch 416/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0954 - accuracy: 0.9682\n",
      "Epoch 417/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0965 - accuracy: 0.9664\n",
      "Epoch 418/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0918 - accuracy: 0.9674\n",
      "Epoch 419/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0883 - accuracy: 0.9690\n",
      "Epoch 420/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0842 - accuracy: 0.9702\n",
      "Epoch 421/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0898 - accuracy: 0.9660\n",
      "Epoch 422/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0859 - accuracy: 0.9692\n",
      "Epoch 423/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1003 - accuracy: 0.9642\n",
      "Epoch 424/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0881 - accuracy: 0.9696\n",
      "Epoch 425/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0867 - accuracy: 0.9694\n",
      "Epoch 426/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0898 - accuracy: 0.9706\n",
      "Epoch 427/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9682\n",
      "Epoch 428/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0876 - accuracy: 0.9670\n",
      "Epoch 429/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0954 - accuracy: 0.9680\n",
      "Epoch 430/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0998 - accuracy: 0.9640\n",
      "Epoch 431/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0872 - accuracy: 0.9690\n",
      "Epoch 432/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0883 - accuracy: 0.9650\n",
      "Epoch 433/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0828 - accuracy: 0.9670\n",
      "Epoch 434/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0864 - accuracy: 0.9692\n",
      "Epoch 435/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.0911 - accuracy: 0.9690\n",
      "Epoch 436/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0820 - accuracy: 0.9700\n",
      "Epoch 437/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0865 - accuracy: 0.9680\n",
      "Epoch 438/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0965 - accuracy: 0.9642\n",
      "Epoch 439/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0825 - accuracy: 0.9680\n",
      "Epoch 440/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0909 - accuracy: 0.9690\n",
      "Epoch 441/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0841 - accuracy: 0.9704\n",
      "Epoch 442/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0800 - accuracy: 0.9698\n",
      "Epoch 443/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0956 - accuracy: 0.9672\n",
      "Epoch 444/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0833 - accuracy: 0.9682\n",
      "Epoch 445/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0960 - accuracy: 0.9646\n",
      "Epoch 446/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0891 - accuracy: 0.9662\n",
      "Epoch 447/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0997 - accuracy: 0.9614\n",
      "Epoch 448/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0835 - accuracy: 0.9708\n",
      "Epoch 449/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0948 - accuracy: 0.9654\n",
      "Epoch 450/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9676\n",
      "Epoch 451/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0912 - accuracy: 0.9706\n",
      "Epoch 452/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0836 - accuracy: 0.9690\n",
      "Epoch 453/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0804 - accuracy: 0.9740\n",
      "Epoch 454/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0924 - accuracy: 0.9680\n",
      "Epoch 455/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0949 - accuracy: 0.9650\n",
      "Epoch 456/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0926 - accuracy: 0.9658\n",
      "Epoch 457/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0853 - accuracy: 0.9708\n",
      "Epoch 458/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0774 - accuracy: 0.9684\n",
      "Epoch 459/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0780 - accuracy: 0.9704\n",
      "Epoch 460/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0926 - accuracy: 0.9662\n",
      "Epoch 461/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0859 - accuracy: 0.9712\n",
      "Epoch 462/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0971 - accuracy: 0.9636\n",
      "Epoch 463/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0783 - accuracy: 0.9724\n",
      "Epoch 464/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0854 - accuracy: 0.9700\n",
      "Epoch 465/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0822 - accuracy: 0.9694\n",
      "Epoch 466/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0912 - accuracy: 0.9664\n",
      "Epoch 467/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0792 - accuracy: 0.9712\n",
      "Epoch 468/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0905 - accuracy: 0.9672\n",
      "Epoch 469/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0954 - accuracy: 0.9672\n",
      "Epoch 470/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0957 - accuracy: 0.9670\n",
      "Epoch 471/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0834 - accuracy: 0.9712\n",
      "Epoch 472/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0898 - accuracy: 0.9674\n",
      "Epoch 473/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0882 - accuracy: 0.9690\n",
      "Epoch 474/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0875 - accuracy: 0.9690\n",
      "Epoch 475/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0800 - accuracy: 0.9712\n",
      "Epoch 476/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0918 - accuracy: 0.9672\n",
      "Epoch 477/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0887 - accuracy: 0.9686\n",
      "Epoch 478/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0815 - accuracy: 0.9702\n",
      "Epoch 479/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0890 - accuracy: 0.9682\n",
      "Epoch 480/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0806 - accuracy: 0.9724\n",
      "Epoch 481/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0842 - accuracy: 0.9702\n",
      "Epoch 482/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0906 - accuracy: 0.9684\n",
      "Epoch 483/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0877 - accuracy: 0.9648\n",
      "Epoch 484/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0837 - accuracy: 0.9688\n",
      "Epoch 485/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0960 - accuracy: 0.9656\n",
      "Epoch 486/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0848 - accuracy: 0.9680\n",
      "Epoch 487/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0831 - accuracy: 0.9698\n",
      "Epoch 488/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0847 - accuracy: 0.9694\n",
      "Epoch 489/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0886 - accuracy: 0.9688\n",
      "Epoch 490/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1005 - accuracy: 0.9634\n",
      "Epoch 491/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0785 - accuracy: 0.9708\n",
      "Epoch 492/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0865 - accuracy: 0.9710\n",
      "Epoch 493/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0812 - accuracy: 0.9732\n",
      "Epoch 494/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0791 - accuracy: 0.9722\n",
      "Epoch 495/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0891 - accuracy: 0.9662\n",
      "Epoch 496/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1003 - accuracy: 0.9640\n",
      "Epoch 497/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0862 - accuracy: 0.9694\n",
      "Epoch 498/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0899 - accuracy: 0.9706\n",
      "Epoch 499/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0849 - accuracy: 0.9712\n",
      "Epoch 500/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0814 - accuracy: 0.9686\n",
      "Epoch 501/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0843 - accuracy: 0.9686\n",
      "Epoch 502/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0863 - accuracy: 0.9696\n",
      "Epoch 503/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0888 - accuracy: 0.9684\n",
      "Epoch 504/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0883 - accuracy: 0.9676\n",
      "Epoch 505/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0977 - accuracy: 0.9680\n",
      "Epoch 506/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0794 - accuracy: 0.9686\n",
      "Epoch 507/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0966 - accuracy: 0.9650\n",
      "Epoch 508/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0899 - accuracy: 0.9698\n",
      "Epoch 509/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0847 - accuracy: 0.9726\n",
      "Epoch 510/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0964 - accuracy: 0.9646\n",
      "Epoch 511/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1068 - accuracy: 0.9668\n",
      "Epoch 512/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0797 - accuracy: 0.9704\n",
      "Epoch 513/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0926 - accuracy: 0.9682\n",
      "Epoch 514/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0745 - accuracy: 0.9714\n",
      "Epoch 515/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0771 - accuracy: 0.9706\n",
      "Epoch 516/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0860 - accuracy: 0.9688\n",
      "Epoch 517/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0949 - accuracy: 0.9672\n",
      "Epoch 518/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0836 - accuracy: 0.9682\n",
      "Epoch 519/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0824 - accuracy: 0.9704\n",
      "Epoch 520/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0831 - accuracy: 0.9700\n",
      "Epoch 521/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0946 - accuracy: 0.9690\n",
      "Epoch 522/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0873 - accuracy: 0.9692\n",
      "Epoch 523/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0811 - accuracy: 0.9682\n",
      "Epoch 524/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0821 - accuracy: 0.9688\n",
      "Epoch 525/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0848 - accuracy: 0.9682\n",
      "Epoch 526/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0984 - accuracy: 0.9672\n",
      "Epoch 527/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0896 - accuracy: 0.9692\n",
      "Epoch 528/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0866 - accuracy: 0.9676\n",
      "Epoch 529/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0756 - accuracy: 0.9720\n",
      "Epoch 530/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0830 - accuracy: 0.9692\n",
      "Epoch 531/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0952 - accuracy: 0.9686\n",
      "Epoch 532/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0821 - accuracy: 0.9688\n",
      "Epoch 533/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0892 - accuracy: 0.9666\n",
      "Epoch 534/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0766 - accuracy: 0.9734\n",
      "Epoch 535/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0878 - accuracy: 0.9680\n",
      "Epoch 536/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0881 - accuracy: 0.9706\n",
      "Epoch 537/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0921 - accuracy: 0.9682\n",
      "Epoch 538/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0924 - accuracy: 0.9684\n",
      "Epoch 539/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0903 - accuracy: 0.9700\n",
      "Epoch 540/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0957 - accuracy: 0.9708\n",
      "Epoch 541/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0860 - accuracy: 0.9688\n",
      "Epoch 542/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0844 - accuracy: 0.9694\n",
      "Epoch 543/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0904 - accuracy: 0.9664\n",
      "Epoch 544/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0911 - accuracy: 0.9670\n",
      "Epoch 545/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0865 - accuracy: 0.9686\n",
      "Epoch 546/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0867 - accuracy: 0.9680\n",
      "Epoch 547/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0828 - accuracy: 0.9682\n",
      "Epoch 548/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0812 - accuracy: 0.9696\n",
      "Epoch 549/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0882 - accuracy: 0.9690\n",
      "Epoch 550/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0771 - accuracy: 0.9710\n",
      "Epoch 551/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0822 - accuracy: 0.9690\n",
      "Epoch 552/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0880 - accuracy: 0.9700\n",
      "Epoch 553/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0782 - accuracy: 0.9704\n",
      "Epoch 554/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0793 - accuracy: 0.9716\n",
      "Epoch 555/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0905 - accuracy: 0.9710\n",
      "Epoch 556/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0736 - accuracy: 0.9732\n",
      "Epoch 557/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0855 - accuracy: 0.9696\n",
      "Epoch 558/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0829 - accuracy: 0.9730\n",
      "Epoch 559/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0811 - accuracy: 0.9706\n",
      "Epoch 560/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0945 - accuracy: 0.9678\n",
      "Epoch 561/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0812 - accuracy: 0.9722\n",
      "Epoch 562/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0861 - accuracy: 0.9670\n",
      "Epoch 563/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0853 - accuracy: 0.9684\n",
      "Epoch 564/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0886 - accuracy: 0.9686\n",
      "Epoch 565/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0834 - accuracy: 0.9718\n",
      "Epoch 566/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0878 - accuracy: 0.9684\n",
      "Epoch 567/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0879 - accuracy: 0.9698\n",
      "Epoch 568/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0857 - accuracy: 0.9686\n",
      "Epoch 569/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0890 - accuracy: 0.9684\n",
      "Epoch 570/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0858 - accuracy: 0.9690\n",
      "Epoch 571/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0859 - accuracy: 0.9692\n",
      "Epoch 572/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0834 - accuracy: 0.9692\n",
      "Epoch 573/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0916 - accuracy: 0.9686\n",
      "Epoch 574/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0887 - accuracy: 0.9674\n",
      "Epoch 575/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0900 - accuracy: 0.9678\n",
      "Epoch 576/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0911 - accuracy: 0.9690\n",
      "Epoch 577/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0845 - accuracy: 0.9712\n",
      "Epoch 578/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0940 - accuracy: 0.9694\n",
      "Epoch 579/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0862 - accuracy: 0.9692\n",
      "Epoch 580/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0833 - accuracy: 0.9716\n",
      "Epoch 581/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0849 - accuracy: 0.9714 0s - loss: 0.0853 - accura\n",
      "Epoch 582/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0772 - accuracy: 0.9730\n",
      "Epoch 583/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0857 - accuracy: 0.9700\n",
      "Epoch 584/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0816 - accuracy: 0.9690\n",
      "Epoch 585/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9706\n",
      "Epoch 586/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0836 - accuracy: 0.9712\n",
      "Epoch 587/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0891 - accuracy: 0.9684\n",
      "Epoch 588/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0864 - accuracy: 0.9694\n",
      "Epoch 589/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9714\n",
      "Epoch 590/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0770 - accuracy: 0.9720\n",
      "Epoch 591/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0906 - accuracy: 0.9684\n",
      "Epoch 592/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0881 - accuracy: 0.9652\n",
      "Epoch 593/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0866 - accuracy: 0.9674\n",
      "Epoch 594/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0840 - accuracy: 0.9700\n",
      "Epoch 595/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0809 - accuracy: 0.9702\n",
      "Epoch 596/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9698\n",
      "Epoch 597/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0962 - accuracy: 0.9698\n",
      "Epoch 598/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0858 - accuracy: 0.9702\n",
      "Epoch 599/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0791 - accuracy: 0.9712\n",
      "Epoch 600/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0970 - accuracy: 0.9670\n",
      "Epoch 601/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0938 - accuracy: 0.9674\n",
      "Epoch 602/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0947 - accuracy: 0.9668\n",
      "Epoch 603/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0775 - accuracy: 0.9702\n",
      "Epoch 604/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0873 - accuracy: 0.9698\n",
      "Epoch 605/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0836 - accuracy: 0.9732\n",
      "Epoch 606/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0820 - accuracy: 0.9700\n",
      "Epoch 607/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0791 - accuracy: 0.9694\n",
      "Epoch 608/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0933 - accuracy: 0.9698\n",
      "Epoch 609/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0813 - accuracy: 0.9720\n",
      "Epoch 610/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0865 - accuracy: 0.9680\n",
      "Epoch 611/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9716\n",
      "Epoch 612/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0915 - accuracy: 0.9658\n",
      "Epoch 613/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0788 - accuracy: 0.9714\n",
      "Epoch 614/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0850 - accuracy: 0.9722\n",
      "Epoch 615/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0779 - accuracy: 0.9714\n",
      "Epoch 616/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0851 - accuracy: 0.9674\n",
      "Epoch 617/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0890 - accuracy: 0.9672\n",
      "Epoch 618/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0810 - accuracy: 0.9720\n",
      "Epoch 619/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0757 - accuracy: 0.9722\n",
      "Epoch 620/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0860 - accuracy: 0.9708\n",
      "Epoch 621/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0802 - accuracy: 0.9706\n",
      "Epoch 622/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0767 - accuracy: 0.9726\n",
      "Epoch 623/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0790 - accuracy: 0.9694\n",
      "Epoch 624/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0902 - accuracy: 0.9674\n",
      "Epoch 625/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0810 - accuracy: 0.9700\n",
      "Epoch 626/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0848 - accuracy: 0.9682\n",
      "Epoch 627/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0821 - accuracy: 0.9712\n",
      "Epoch 628/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0837 - accuracy: 0.9712\n",
      "Epoch 629/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0867 - accuracy: 0.9678\n",
      "Epoch 630/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0804 - accuracy: 0.9714\n",
      "Epoch 631/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0820 - accuracy: 0.9716\n",
      "Epoch 632/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0807 - accuracy: 0.9700\n",
      "Epoch 633/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0865 - accuracy: 0.9706\n",
      "Epoch 634/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0860 - accuracy: 0.9712\n",
      "Epoch 635/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0823 - accuracy: 0.9738\n",
      "Epoch 636/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0826 - accuracy: 0.9734\n",
      "Epoch 637/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0833 - accuracy: 0.9726\n",
      "Epoch 638/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0858 - accuracy: 0.9698\n",
      "Epoch 639/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0781 - accuracy: 0.9718\n",
      "Epoch 640/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0919 - accuracy: 0.9656\n",
      "Epoch 641/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0873 - accuracy: 0.9680\n",
      "Epoch 642/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0772 - accuracy: 0.9728\n",
      "Epoch 643/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0807 - accuracy: 0.9712\n",
      "Epoch 644/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0842 - accuracy: 0.9736\n",
      "Epoch 645/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0825 - accuracy: 0.9732\n",
      "Epoch 646/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0877 - accuracy: 0.9698\n",
      "Epoch 647/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9706\n",
      "Epoch 648/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0779 - accuracy: 0.9712\n",
      "Epoch 649/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0899 - accuracy: 0.9692\n",
      "Epoch 650/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0739 - accuracy: 0.9720\n",
      "Epoch 651/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0843 - accuracy: 0.9698\n",
      "Epoch 652/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0841 - accuracy: 0.9698\n",
      "Epoch 653/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0872 - accuracy: 0.9672\n",
      "Epoch 654/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0834 - accuracy: 0.9702\n",
      "Epoch 655/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0882 - accuracy: 0.9682\n",
      "Epoch 656/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0780 - accuracy: 0.9694\n",
      "Epoch 657/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0866 - accuracy: 0.9728\n",
      "Epoch 658/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0925 - accuracy: 0.9686\n",
      "Epoch 659/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0829 - accuracy: 0.9692\n",
      "Epoch 660/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0800 - accuracy: 0.9718\n",
      "Epoch 661/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1072 - accuracy: 0.9680\n",
      "Epoch 662/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0766 - accuracy: 0.9714\n",
      "Epoch 663/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0871 - accuracy: 0.9710\n",
      "Epoch 664/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0783 - accuracy: 0.9684\n",
      "Epoch 665/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0727 - accuracy: 0.9726\n",
      "Epoch 666/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0815 - accuracy: 0.9712\n",
      "Epoch 667/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0786 - accuracy: 0.9692\n",
      "Epoch 668/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0858 - accuracy: 0.9662\n",
      "Epoch 669/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0884 - accuracy: 0.9674\n",
      "Epoch 670/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9690\n",
      "Epoch 671/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0874 - accuracy: 0.9680\n",
      "Epoch 672/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0860 - accuracy: 0.9680\n",
      "Epoch 673/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0721 - accuracy: 0.9720\n",
      "Epoch 674/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0858 - accuracy: 0.9734\n",
      "Epoch 675/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0740 - accuracy: 0.9736\n",
      "Epoch 676/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0805 - accuracy: 0.9702\n",
      "Epoch 677/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0905 - accuracy: 0.9678\n",
      "Epoch 678/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0860 - accuracy: 0.9746\n",
      "Epoch 679/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0881 - accuracy: 0.9688\n",
      "Epoch 680/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0986 - accuracy: 0.9688\n",
      "Epoch 681/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9686\n",
      "Epoch 682/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0914 - accuracy: 0.9710\n",
      "Epoch 683/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0797 - accuracy: 0.9718\n",
      "Epoch 684/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0791 - accuracy: 0.9684\n",
      "Epoch 685/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9692\n",
      "Epoch 686/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0818 - accuracy: 0.9726\n",
      "Epoch 687/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0820 - accuracy: 0.9716\n",
      "Epoch 688/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0759 - accuracy: 0.9724\n",
      "Epoch 689/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0861 - accuracy: 0.9698\n",
      "Epoch 690/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0788 - accuracy: 0.9680\n",
      "Epoch 691/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0834 - accuracy: 0.9680\n",
      "Epoch 692/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0808 - accuracy: 0.9714\n",
      "Epoch 693/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0712 - accuracy: 0.9738\n",
      "Epoch 694/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0878 - accuracy: 0.9708\n",
      "Epoch 695/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0819 - accuracy: 0.9692\n",
      "Epoch 696/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0854 - accuracy: 0.9680\n",
      "Epoch 697/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0768 - accuracy: 0.9706\n",
      "Epoch 698/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0813 - accuracy: 0.9706\n",
      "Epoch 699/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0861 - accuracy: 0.9666\n",
      "Epoch 700/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0782 - accuracy: 0.9704\n",
      "Epoch 701/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0821 - accuracy: 0.9696\n",
      "Epoch 702/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0813 - accuracy: 0.9702\n",
      "Epoch 703/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0889 - accuracy: 0.9686\n",
      "Epoch 704/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0844 - accuracy: 0.9714\n",
      "Epoch 705/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0866 - accuracy: 0.9720\n",
      "Epoch 706/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0830 - accuracy: 0.9688\n",
      "Epoch 707/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0772 - accuracy: 0.9690\n",
      "Epoch 708/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0793 - accuracy: 0.9726\n",
      "Epoch 709/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0760 - accuracy: 0.9702\n",
      "Epoch 710/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0947 - accuracy: 0.9664\n",
      "Epoch 711/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0939 - accuracy: 0.9696\n",
      "Epoch 712/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0912 - accuracy: 0.9684\n",
      "Epoch 713/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0782 - accuracy: 0.9728\n",
      "Epoch 714/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0861 - accuracy: 0.9702\n",
      "Epoch 715/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0731 - accuracy: 0.9748\n",
      "Epoch 716/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0782 - accuracy: 0.9712\n",
      "Epoch 717/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0778 - accuracy: 0.9720\n",
      "Epoch 718/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0896 - accuracy: 0.9670\n",
      "Epoch 719/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0886 - accuracy: 0.9690\n",
      "Epoch 720/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0759 - accuracy: 0.9706\n",
      "Epoch 721/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0889 - accuracy: 0.9660\n",
      "Epoch 722/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0838 - accuracy: 0.9700\n",
      "Epoch 723/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0848 - accuracy: 0.9706\n",
      "Epoch 724/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0821 - accuracy: 0.9684\n",
      "Epoch 725/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0897 - accuracy: 0.9694\n",
      "Epoch 726/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0797 - accuracy: 0.9704\n",
      "Epoch 727/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0804 - accuracy: 0.9702\n",
      "Epoch 728/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0848 - accuracy: 0.9692\n",
      "Epoch 729/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0768 - accuracy: 0.9720\n",
      "Epoch 730/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0737 - accuracy: 0.9714\n",
      "Epoch 731/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0901 - accuracy: 0.9694\n",
      "Epoch 732/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0903 - accuracy: 0.9666\n",
      "Epoch 733/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0817 - accuracy: 0.9704\n",
      "Epoch 734/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0818 - accuracy: 0.9696\n",
      "Epoch 735/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0831 - accuracy: 0.9696\n",
      "Epoch 736/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0915 - accuracy: 0.9704\n",
      "Epoch 737/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0895 - accuracy: 0.9708\n",
      "Epoch 738/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0807 - accuracy: 0.9686\n",
      "Epoch 739/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0733 - accuracy: 0.9730\n",
      "Epoch 740/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0812 - accuracy: 0.9728\n",
      "Epoch 741/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0839 - accuracy: 0.9714\n",
      "Epoch 742/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0794 - accuracy: 0.9698\n",
      "Epoch 743/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1014 - accuracy: 0.9664\n",
      "Epoch 744/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0870 - accuracy: 0.9688\n",
      "Epoch 745/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0814 - accuracy: 0.9710\n",
      "Epoch 746/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0764 - accuracy: 0.9700\n",
      "Epoch 747/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0793 - accuracy: 0.9714\n",
      "Epoch 748/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0850 - accuracy: 0.9708\n",
      "Epoch 749/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0876 - accuracy: 0.9670\n",
      "Epoch 750/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0782 - accuracy: 0.9704\n",
      "Epoch 751/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0880 - accuracy: 0.9700\n",
      "Epoch 752/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0889 - accuracy: 0.9672\n",
      "Epoch 753/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0777 - accuracy: 0.9702\n",
      "Epoch 754/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0768 - accuracy: 0.9724\n",
      "Epoch 755/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0813 - accuracy: 0.9712\n",
      "Epoch 756/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0877 - accuracy: 0.9718\n",
      "Epoch 757/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0741 - accuracy: 0.9716\n",
      "Epoch 758/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0906 - accuracy: 0.9660\n",
      "Epoch 759/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0787 - accuracy: 0.9722\n",
      "Epoch 760/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0785 - accuracy: 0.9718\n",
      "Epoch 761/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0743 - accuracy: 0.9736\n",
      "Epoch 762/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0872 - accuracy: 0.9702\n",
      "Epoch 763/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0819 - accuracy: 0.9690\n",
      "Epoch 764/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0721 - accuracy: 0.9708\n",
      "Epoch 765/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0961 - accuracy: 0.9680\n",
      "Epoch 766/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0874 - accuracy: 0.9672\n",
      "Epoch 767/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0778 - accuracy: 0.9696\n",
      "Epoch 768/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0877 - accuracy: 0.9700\n",
      "Epoch 769/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0822 - accuracy: 0.9694\n",
      "Epoch 770/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0736 - accuracy: 0.9706\n",
      "Epoch 771/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0786 - accuracy: 0.9730\n",
      "Epoch 772/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0770 - accuracy: 0.9708\n",
      "Epoch 773/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0940 - accuracy: 0.9702\n",
      "Epoch 774/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0760 - accuracy: 0.9694\n",
      "Epoch 775/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0808 - accuracy: 0.9700\n",
      "Epoch 776/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0865 - accuracy: 0.9688\n",
      "Epoch 777/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0793 - accuracy: 0.9718\n",
      "Epoch 778/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0837 - accuracy: 0.9682\n",
      "Epoch 779/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0871 - accuracy: 0.9686\n",
      "Epoch 780/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0812 - accuracy: 0.9686\n",
      "Epoch 781/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9720\n",
      "Epoch 782/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0744 - accuracy: 0.9710\n",
      "Epoch 783/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0828 - accuracy: 0.9722\n",
      "Epoch 784/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0783 - accuracy: 0.9718\n",
      "Epoch 785/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0788 - accuracy: 0.9720\n",
      "Epoch 786/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0759 - accuracy: 0.9728\n",
      "Epoch 787/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0900 - accuracy: 0.9698\n",
      "Epoch 788/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0866 - accuracy: 0.9678\n",
      "Epoch 789/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0877 - accuracy: 0.9686\n",
      "Epoch 790/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0826 - accuracy: 0.9708\n",
      "Epoch 791/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0819 - accuracy: 0.9680\n",
      "Epoch 792/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0851 - accuracy: 0.9734\n",
      "Epoch 793/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0846 - accuracy: 0.9696\n",
      "Epoch 794/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0873 - accuracy: 0.9672\n",
      "Epoch 795/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9718\n",
      "Epoch 796/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0896 - accuracy: 0.9684\n",
      "Epoch 797/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0751 - accuracy: 0.9724\n",
      "Epoch 798/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0977 - accuracy: 0.9672\n",
      "Epoch 799/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0864 - accuracy: 0.9688\n",
      "Epoch 800/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0778 - accuracy: 0.9702\n",
      "Epoch 801/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0947 - accuracy: 0.9694\n",
      "Epoch 802/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0767 - accuracy: 0.9694\n",
      "Epoch 803/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0895 - accuracy: 0.9694\n",
      "Epoch 804/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0799 - accuracy: 0.9712\n",
      "Epoch 805/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0829 - accuracy: 0.9710\n",
      "Epoch 806/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0800 - accuracy: 0.9736\n",
      "Epoch 807/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0897 - accuracy: 0.9674\n",
      "Epoch 808/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0723 - accuracy: 0.9722\n",
      "Epoch 809/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0835 - accuracy: 0.9700\n",
      "Epoch 810/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0751 - accuracy: 0.9710\n",
      "Epoch 811/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0839 - accuracy: 0.9704\n",
      "Epoch 812/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0724 - accuracy: 0.9732\n",
      "Epoch 813/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0797 - accuracy: 0.9716\n",
      "Epoch 814/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0762 - accuracy: 0.9702\n",
      "Epoch 815/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0712 - accuracy: 0.9730\n",
      "Epoch 816/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0811 - accuracy: 0.9712\n",
      "Epoch 817/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0796 - accuracy: 0.9698\n",
      "Epoch 818/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0880 - accuracy: 0.9700\n",
      "Epoch 819/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0715 - accuracy: 0.9740\n",
      "Epoch 820/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0831 - accuracy: 0.9710\n",
      "Epoch 821/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0780 - accuracy: 0.9702\n",
      "Epoch 822/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0803 - accuracy: 0.9730\n",
      "Epoch 823/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0727 - accuracy: 0.9734\n",
      "Epoch 824/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0831 - accuracy: 0.9714\n",
      "Epoch 825/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0831 - accuracy: 0.9724\n",
      "Epoch 826/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0772 - accuracy: 0.9718\n",
      "Epoch 827/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0800 - accuracy: 0.9694\n",
      "Epoch 828/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0799 - accuracy: 0.9710\n",
      "Epoch 829/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0781 - accuracy: 0.9722\n",
      "Epoch 830/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0775 - accuracy: 0.9702\n",
      "Epoch 831/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0761 - accuracy: 0.9718\n",
      "Epoch 832/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0799 - accuracy: 0.9718\n",
      "Epoch 833/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0816 - accuracy: 0.9706\n",
      "Epoch 834/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0854 - accuracy: 0.9692\n",
      "Epoch 835/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0705 - accuracy: 0.9740\n",
      "Epoch 836/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0765 - accuracy: 0.9720\n",
      "Epoch 837/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0787 - accuracy: 0.9710\n",
      "Epoch 838/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0823 - accuracy: 0.9682\n",
      "Epoch 839/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0840 - accuracy: 0.9704\n",
      "Epoch 840/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0778 - accuracy: 0.9734\n",
      "Epoch 841/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0899 - accuracy: 0.9660\n",
      "Epoch 842/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0677 - accuracy: 0.9740\n",
      "Epoch 843/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0882 - accuracy: 0.9700\n",
      "Epoch 844/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0862 - accuracy: 0.9726\n",
      "Epoch 845/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0804 - accuracy: 0.9692\n",
      "Epoch 846/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0826 - accuracy: 0.9684\n",
      "Epoch 847/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0798 - accuracy: 0.9722\n",
      "Epoch 848/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0842 - accuracy: 0.9688\n",
      "Epoch 849/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0904 - accuracy: 0.9700\n",
      "Epoch 850/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0754 - accuracy: 0.9716\n",
      "Epoch 851/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0808 - accuracy: 0.9714\n",
      "Epoch 852/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0858 - accuracy: 0.9724\n",
      "Epoch 853/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0780 - accuracy: 0.9734\n",
      "Epoch 854/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0749 - accuracy: 0.9740\n",
      "Epoch 855/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0854 - accuracy: 0.9708\n",
      "Epoch 856/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0779 - accuracy: 0.9720\n",
      "Epoch 857/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0779 - accuracy: 0.9714\n",
      "Epoch 858/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0881 - accuracy: 0.9722\n",
      "Epoch 859/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0854 - accuracy: 0.9678\n",
      "Epoch 860/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0857 - accuracy: 0.9698\n",
      "Epoch 861/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0797 - accuracy: 0.9674\n",
      "Epoch 862/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0807 - accuracy: 0.9736\n",
      "Epoch 863/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0894 - accuracy: 0.9716\n",
      "Epoch 864/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0734 - accuracy: 0.9728\n",
      "Epoch 865/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0858 - accuracy: 0.9670\n",
      "Epoch 866/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0810 - accuracy: 0.9720\n",
      "Epoch 867/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0868 - accuracy: 0.9682\n",
      "Epoch 868/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0784 - accuracy: 0.9710\n",
      "Epoch 869/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0822 - accuracy: 0.9718\n",
      "Epoch 870/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0836 - accuracy: 0.9714\n",
      "Epoch 871/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0880 - accuracy: 0.9694\n",
      "Epoch 872/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0751 - accuracy: 0.9718\n",
      "Epoch 873/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0909 - accuracy: 0.9698\n",
      "Epoch 874/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0765 - accuracy: 0.9722\n",
      "Epoch 875/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0769 - accuracy: 0.9700\n",
      "Epoch 876/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0782 - accuracy: 0.9718\n",
      "Epoch 877/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0891 - accuracy: 0.9706\n",
      "Epoch 878/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0746 - accuracy: 0.9718\n",
      "Epoch 879/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0806 - accuracy: 0.9708\n",
      "Epoch 880/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0820 - accuracy: 0.9704\n",
      "Epoch 881/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0779 - accuracy: 0.9702\n",
      "Epoch 882/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0847 - accuracy: 0.9684\n",
      "Epoch 883/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0792 - accuracy: 0.9692\n",
      "Epoch 884/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0839 - accuracy: 0.9682\n",
      "Epoch 885/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0757 - accuracy: 0.9708\n",
      "Epoch 886/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0763 - accuracy: 0.9738\n",
      "Epoch 887/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0916 - accuracy: 0.9712\n",
      "Epoch 888/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0880 - accuracy: 0.9698\n",
      "Epoch 889/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0772 - accuracy: 0.9726\n",
      "Epoch 890/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0848 - accuracy: 0.9674\n",
      "Epoch 891/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0875 - accuracy: 0.9680\n",
      "Epoch 892/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0835 - accuracy: 0.9686\n",
      "Epoch 893/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0814 - accuracy: 0.9706\n",
      "Epoch 894/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0775 - accuracy: 0.9714\n",
      "Epoch 895/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0857 - accuracy: 0.9710\n",
      "Epoch 896/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0937 - accuracy: 0.9682\n",
      "Epoch 897/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0730 - accuracy: 0.9710\n",
      "Epoch 898/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0906 - accuracy: 0.9684\n",
      "Epoch 899/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0830 - accuracy: 0.9698\n",
      "Epoch 900/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0809 - accuracy: 0.9700\n",
      "Epoch 901/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0741 - accuracy: 0.9728\n",
      "Epoch 902/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9726\n",
      "Epoch 903/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0772 - accuracy: 0.9708\n",
      "Epoch 904/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.0759 - accuracy: 0.9748\n",
      "Epoch 905/1024\n",
      "4996/4996 [==============================] - 0s 84us/step - loss: 0.0797 - accuracy: 0.9714\n",
      "Epoch 906/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0813 - accuracy: 0.9732\n",
      "Epoch 907/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0837 - accuracy: 0.9704\n",
      "Epoch 908/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0794 - accuracy: 0.9728\n",
      "Epoch 909/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0827 - accuracy: 0.9710\n",
      "Epoch 910/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0892 - accuracy: 0.9662\n",
      "Epoch 911/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0861 - accuracy: 0.9690\n",
      "Epoch 912/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0847 - accuracy: 0.9706\n",
      "Epoch 913/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0721 - accuracy: 0.9712\n",
      "Epoch 914/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0810 - accuracy: 0.9726\n",
      "Epoch 915/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0738 - accuracy: 0.9728\n",
      "Epoch 916/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0827 - accuracy: 0.9706\n",
      "Epoch 917/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0763 - accuracy: 0.9692\n",
      "Epoch 918/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0876 - accuracy: 0.9672\n",
      "Epoch 919/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0882 - accuracy: 0.9706\n",
      "Epoch 920/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0922 - accuracy: 0.9698 0s - loss: 0.0689 - accu\n",
      "Epoch 921/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0785 - accuracy: 0.9704\n",
      "Epoch 922/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0882 - accuracy: 0.9714\n",
      "Epoch 923/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0869 - accuracy: 0.9682\n",
      "Epoch 924/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0942 - accuracy: 0.9696\n",
      "Epoch 925/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0820 - accuracy: 0.9726\n",
      "Epoch 926/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0755 - accuracy: 0.9712\n",
      "Epoch 927/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0758 - accuracy: 0.9700\n",
      "Epoch 928/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0727 - accuracy: 0.9760\n",
      "Epoch 929/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0765 - accuracy: 0.9718\n",
      "Epoch 930/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0829 - accuracy: 0.9702\n",
      "Epoch 931/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0876 - accuracy: 0.9692\n",
      "Epoch 932/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0854 - accuracy: 0.9720\n",
      "Epoch 933/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0793 - accuracy: 0.9724\n",
      "Epoch 934/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0877 - accuracy: 0.9676\n",
      "Epoch 935/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0754 - accuracy: 0.9722\n",
      "Epoch 936/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0867 - accuracy: 0.9680\n",
      "Epoch 937/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0928 - accuracy: 0.9722\n",
      "Epoch 938/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0745 - accuracy: 0.9736\n",
      "Epoch 939/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0775 - accuracy: 0.9718\n",
      "Epoch 940/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0771 - accuracy: 0.9720\n",
      "Epoch 941/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0803 - accuracy: 0.9696\n",
      "Epoch 942/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0831 - accuracy: 0.9722\n",
      "Epoch 943/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0729 - accuracy: 0.9742\n",
      "Epoch 944/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0731 - accuracy: 0.9734\n",
      "Epoch 945/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0847 - accuracy: 0.9710\n",
      "Epoch 946/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0856 - accuracy: 0.9704\n",
      "Epoch 947/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0740 - accuracy: 0.9750\n",
      "Epoch 948/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0750 - accuracy: 0.9728\n",
      "Epoch 949/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0703 - accuracy: 0.9756\n",
      "Epoch 950/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0814 - accuracy: 0.9740\n",
      "Epoch 951/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0742 - accuracy: 0.9734\n",
      "Epoch 952/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0789 - accuracy: 0.9714\n",
      "Epoch 953/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0730 - accuracy: 0.9734\n",
      "Epoch 954/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0852 - accuracy: 0.9690\n",
      "Epoch 955/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0753 - accuracy: 0.9716\n",
      "Epoch 956/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0776 - accuracy: 0.9708\n",
      "Epoch 957/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0801 - accuracy: 0.9710\n",
      "Epoch 958/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0819 - accuracy: 0.9722\n",
      "Epoch 959/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0915 - accuracy: 0.9688\n",
      "Epoch 960/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0804 - accuracy: 0.9674\n",
      "Epoch 961/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0746 - accuracy: 0.9700\n",
      "Epoch 962/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0903 - accuracy: 0.9688\n",
      "Epoch 963/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0834 - accuracy: 0.9720\n",
      "Epoch 964/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0712 - accuracy: 0.9736\n",
      "Epoch 965/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9710\n",
      "Epoch 966/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0721 - accuracy: 0.9726\n",
      "Epoch 967/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0751 - accuracy: 0.9726\n",
      "Epoch 968/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0799 - accuracy: 0.9718\n",
      "Epoch 969/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0862 - accuracy: 0.9684\n",
      "Epoch 970/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0840 - accuracy: 0.9702\n",
      "Epoch 971/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0772 - accuracy: 0.9730\n",
      "Epoch 972/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0730 - accuracy: 0.9734\n",
      "Epoch 973/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0823 - accuracy: 0.9700\n",
      "Epoch 974/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0813 - accuracy: 0.9692\n",
      "Epoch 975/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0712 - accuracy: 0.9722\n",
      "Epoch 976/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0723 - accuracy: 0.9724\n",
      "Epoch 977/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0711 - accuracy: 0.9734\n",
      "Epoch 978/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0889 - accuracy: 0.9696\n",
      "Epoch 979/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0848 - accuracy: 0.9706\n",
      "Epoch 980/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0811 - accuracy: 0.9704\n",
      "Epoch 981/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0784 - accuracy: 0.9706\n",
      "Epoch 982/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0785 - accuracy: 0.9728\n",
      "Epoch 983/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0831 - accuracy: 0.9708\n",
      "Epoch 984/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0794 - accuracy: 0.9678\n",
      "Epoch 985/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0902 - accuracy: 0.9696\n",
      "Epoch 986/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0795 - accuracy: 0.9730\n",
      "Epoch 987/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0805 - accuracy: 0.9738\n",
      "Epoch 988/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0818 - accuracy: 0.9718\n",
      "Epoch 989/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0819 - accuracy: 0.9714\n",
      "Epoch 990/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0799 - accuracy: 0.9712\n",
      "Epoch 991/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0882 - accuracy: 0.9692\n",
      "Epoch 992/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0825 - accuracy: 0.9710\n",
      "Epoch 993/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0800 - accuracy: 0.9730\n",
      "Epoch 994/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0657 - accuracy: 0.9746\n",
      "Epoch 995/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0746 - accuracy: 0.9740\n",
      "Epoch 996/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0772 - accuracy: 0.9712\n",
      "Epoch 997/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0675 - accuracy: 0.9750\n",
      "Epoch 998/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0922 - accuracy: 0.9690\n",
      "Epoch 999/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0753 - accuracy: 0.9738\n",
      "Epoch 1000/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0796 - accuracy: 0.9710\n",
      "Epoch 1001/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0809 - accuracy: 0.9698\n",
      "Epoch 1002/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0843 - accuracy: 0.9692\n",
      "Epoch 1003/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0818 - accuracy: 0.9702\n",
      "Epoch 1004/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0810 - accuracy: 0.9736\n",
      "Epoch 1005/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0745 - accuracy: 0.9746\n",
      "Epoch 1006/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0791 - accuracy: 0.9706\n",
      "Epoch 1007/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0731 - accuracy: 0.9736\n",
      "Epoch 1008/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0792 - accuracy: 0.9722\n",
      "Epoch 1009/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0812 - accuracy: 0.9720\n",
      "Epoch 1010/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0920 - accuracy: 0.9670\n",
      "Epoch 1011/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0847 - accuracy: 0.9704\n",
      "Epoch 1012/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0764 - accuracy: 0.9704\n",
      "Epoch 1013/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0826 - accuracy: 0.9680\n",
      "Epoch 1014/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0780 - accuracy: 0.9714\n",
      "Epoch 1015/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0748 - accuracy: 0.9712\n",
      "Epoch 1016/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0757 - accuracy: 0.9714\n",
      "Epoch 1017/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0816 - accuracy: 0.9718\n",
      "Epoch 1018/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0770 - accuracy: 0.9684\n",
      "Epoch 1019/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0823 - accuracy: 0.9700\n",
      "Epoch 1020/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0797 - accuracy: 0.9676\n",
      "Epoch 1021/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0865 - accuracy: 0.9672\n",
      "Epoch 1022/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0760 - accuracy: 0.9724\n",
      "Epoch 1023/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0874 - accuracy: 0.9704\n",
      "Epoch 1024/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0904 - accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(256, activation='relu', kernel_initializer='random_normal', input_dim=1600, ))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='Adadelta',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "history = classifier.fit(X_train,y_train, batch_size=32, epochs=1024, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('../Figures/FNN_AdaDelta.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "4996/4996 [==============================] - 0s 98us/step - loss: 0.5964 - accuracy: 0.7026\n",
      "Epoch 2/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.4360 - accuracy: 0.8449\n",
      "Epoch 3/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.4090 - accuracy: 0.8621\n",
      "Epoch 4/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3910 - accuracy: 0.8697\n",
      "Epoch 5/1024\n",
      "4996/4996 [==============================] - 0s 75us/step - loss: 0.3889 - accuracy: 0.8765\n",
      "Epoch 6/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.3757 - accuracy: 0.8817\n",
      "Epoch 7/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.3425 - accuracy: 0.8921\n",
      "Epoch 8/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.3414 - accuracy: 0.8933\n",
      "Epoch 9/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3184 - accuracy: 0.8963\n",
      "Epoch 10/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.3101 - accuracy: 0.9023\n",
      "Epoch 11/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.3016 - accuracy: 0.9015\n",
      "Epoch 12/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.2901 - accuracy: 0.9115\n",
      "Epoch 13/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.2866 - accuracy: 0.9175\n",
      "Epoch 14/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2813 - accuracy: 0.9091\n",
      "Epoch 15/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2543 - accuracy: 0.9243\n",
      "Epoch 16/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2461 - accuracy: 0.9205\n",
      "Epoch 17/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2401 - accuracy: 0.9219\n",
      "Epoch 18/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.2373 - accuracy: 0.9241\n",
      "Epoch 19/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2325 - accuracy: 0.9231\n",
      "Epoch 20/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.2199 - accuracy: 0.9313\n",
      "Epoch 21/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2258 - accuracy: 0.9241\n",
      "Epoch 22/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2118 - accuracy: 0.9267\n",
      "Epoch 23/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2041 - accuracy: 0.9341\n",
      "Epoch 24/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2066 - accuracy: 0.9396\n",
      "Epoch 25/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.2042 - accuracy: 0.9321\n",
      "Epoch 26/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1884 - accuracy: 0.9420\n",
      "Epoch 27/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1937 - accuracy: 0.9371\n",
      "Epoch 28/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1896 - accuracy: 0.9376\n",
      "Epoch 29/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1900 - accuracy: 0.9414\n",
      "Epoch 30/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1898 - accuracy: 0.9367\n",
      "Epoch 31/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1772 - accuracy: 0.9410\n",
      "Epoch 32/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1791 - accuracy: 0.9386\n",
      "Epoch 33/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1776 - accuracy: 0.9404\n",
      "Epoch 34/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1726 - accuracy: 0.9402\n",
      "Epoch 35/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1694 - accuracy: 0.9454\n",
      "Epoch 36/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1660 - accuracy: 0.9450\n",
      "Epoch 37/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1651 - accuracy: 0.9444\n",
      "Epoch 38/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1761 - accuracy: 0.9430\n",
      "Epoch 39/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1645 - accuracy: 0.9448\n",
      "Epoch 40/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1710 - accuracy: 0.9392\n",
      "Epoch 41/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1583 - accuracy: 0.9464\n",
      "Epoch 42/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1647 - accuracy: 0.9480\n",
      "Epoch 43/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1628 - accuracy: 0.9428\n",
      "Epoch 44/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1498 - accuracy: 0.9484\n",
      "Epoch 45/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1622 - accuracy: 0.9474\n",
      "Epoch 46/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1561 - accuracy: 0.9450\n",
      "Epoch 47/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1535 - accuracy: 0.9512\n",
      "Epoch 48/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1415 - accuracy: 0.9486\n",
      "Epoch 49/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1456 - accuracy: 0.9492\n",
      "Epoch 50/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1494 - accuracy: 0.9490\n",
      "Epoch 51/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1563 - accuracy: 0.9450\n",
      "Epoch 52/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1477 - accuracy: 0.9462\n",
      "Epoch 53/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1484 - accuracy: 0.9494\n",
      "Epoch 54/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1408 - accuracy: 0.9542\n",
      "Epoch 55/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1454 - accuracy: 0.9484\n",
      "Epoch 56/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1486 - accuracy: 0.9478\n",
      "Epoch 57/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1396 - accuracy: 0.9548\n",
      "Epoch 58/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1355 - accuracy: 0.9532\n",
      "Epoch 59/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1494 - accuracy: 0.9480\n",
      "Epoch 60/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1392 - accuracy: 0.9536\n",
      "Epoch 61/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1473 - accuracy: 0.9466\n",
      "Epoch 62/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1493 - accuracy: 0.9498\n",
      "Epoch 63/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1390 - accuracy: 0.9494\n",
      "Epoch 64/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1369 - accuracy: 0.9526\n",
      "Epoch 65/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1441 - accuracy: 0.9510\n",
      "Epoch 66/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1414 - accuracy: 0.9518\n",
      "Epoch 67/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1448 - accuracy: 0.9502\n",
      "Epoch 68/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1420 - accuracy: 0.9530\n",
      "Epoch 69/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1354 - accuracy: 0.9552\n",
      "Epoch 70/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1267 - accuracy: 0.9566\n",
      "Epoch 71/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1299 - accuracy: 0.9554\n",
      "Epoch 72/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1417 - accuracy: 0.9482\n",
      "Epoch 73/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1297 - accuracy: 0.9550\n",
      "Epoch 74/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1275 - accuracy: 0.9584\n",
      "Epoch 75/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1332 - accuracy: 0.9548\n",
      "Epoch 76/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1319 - accuracy: 0.9546\n",
      "Epoch 77/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1292 - accuracy: 0.9514\n",
      "Epoch 78/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1352 - accuracy: 0.9516\n",
      "Epoch 79/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1293 - accuracy: 0.9580\n",
      "Epoch 80/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1222 - accuracy: 0.9558\n",
      "Epoch 81/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1273 - accuracy: 0.9572\n",
      "Epoch 82/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1323 - accuracy: 0.9554\n",
      "Epoch 83/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1396 - accuracy: 0.9524\n",
      "Epoch 84/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1261 - accuracy: 0.9564\n",
      "Epoch 85/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1308 - accuracy: 0.9550\n",
      "Epoch 86/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1226 - accuracy: 0.9554\n",
      "Epoch 87/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1280 - accuracy: 0.9576\n",
      "Epoch 88/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1286 - accuracy: 0.9524\n",
      "Epoch 89/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1193 - accuracy: 0.9564\n",
      "Epoch 90/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1253 - accuracy: 0.9550\n",
      "Epoch 91/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1201 - accuracy: 0.9602\n",
      "Epoch 92/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1176 - accuracy: 0.9566\n",
      "Epoch 93/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1344 - accuracy: 0.9538\n",
      "Epoch 94/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1176 - accuracy: 0.9598\n",
      "Epoch 95/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1209 - accuracy: 0.9602\n",
      "Epoch 96/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1186 - accuracy: 0.9576\n",
      "Epoch 97/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1203 - accuracy: 0.9566\n",
      "Epoch 98/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1243 - accuracy: 0.9568\n",
      "Epoch 99/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1134 - accuracy: 0.9594\n",
      "Epoch 100/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1232 - accuracy: 0.9576\n",
      "Epoch 101/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1203 - accuracy: 0.9582\n",
      "Epoch 102/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1271 - accuracy: 0.9572\n",
      "Epoch 103/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1213 - accuracy: 0.9540\n",
      "Epoch 104/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1274 - accuracy: 0.9546\n",
      "Epoch 105/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1242 - accuracy: 0.9556\n",
      "Epoch 106/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.1120 - accuracy: 0.9578\n",
      "Epoch 107/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1138 - accuracy: 0.9590\n",
      "Epoch 108/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1213 - accuracy: 0.9570\n",
      "Epoch 109/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1116 - accuracy: 0.9604\n",
      "Epoch 110/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1153 - accuracy: 0.9568 0s - loss: 0.1024 - accura\n",
      "Epoch 111/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1177 - accuracy: 0.9588\n",
      "Epoch 112/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1217 - accuracy: 0.9542\n",
      "Epoch 113/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1138 - accuracy: 0.9572\n",
      "Epoch 114/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1053 - accuracy: 0.9622\n",
      "Epoch 115/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1094 - accuracy: 0.9610\n",
      "Epoch 116/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1201 - accuracy: 0.9598\n",
      "Epoch 117/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1159 - accuracy: 0.9544\n",
      "Epoch 118/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1089 - accuracy: 0.9608\n",
      "Epoch 119/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1140 - accuracy: 0.9600\n",
      "Epoch 120/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1129 - accuracy: 0.9608\n",
      "Epoch 121/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1092 - accuracy: 0.9610\n",
      "Epoch 122/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1017 - accuracy: 0.9602\n",
      "Epoch 123/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1290 - accuracy: 0.9536\n",
      "Epoch 124/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1204 - accuracy: 0.9572\n",
      "Epoch 125/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1122 - accuracy: 0.9564\n",
      "Epoch 126/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1018 - accuracy: 0.9640\n",
      "Epoch 127/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1046 - accuracy: 0.9632\n",
      "Epoch 128/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1122 - accuracy: 0.9574\n",
      "Epoch 129/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1127 - accuracy: 0.9590\n",
      "Epoch 130/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1194 - accuracy: 0.9580\n",
      "Epoch 131/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1173 - accuracy: 0.9568\n",
      "Epoch 132/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1091 - accuracy: 0.9612\n",
      "Epoch 133/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1143 - accuracy: 0.9584\n",
      "Epoch 134/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1175 - accuracy: 0.9580\n",
      "Epoch 135/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1081 - accuracy: 0.9636\n",
      "Epoch 136/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1184 - accuracy: 0.9578\n",
      "Epoch 137/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1190 - accuracy: 0.9608\n",
      "Epoch 138/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1043 - accuracy: 0.9614\n",
      "Epoch 139/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1130 - accuracy: 0.9582\n",
      "Epoch 140/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1094 - accuracy: 0.9626\n",
      "Epoch 141/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1229 - accuracy: 0.9548\n",
      "Epoch 142/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1131 - accuracy: 0.9574\n",
      "Epoch 143/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1056 - accuracy: 0.9616\n",
      "Epoch 144/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1102 - accuracy: 0.9628\n",
      "Epoch 145/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1147 - accuracy: 0.9580\n",
      "Epoch 146/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1065 - accuracy: 0.9606\n",
      "Epoch 147/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1140 - accuracy: 0.9598\n",
      "Epoch 148/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1087 - accuracy: 0.9614\n",
      "Epoch 149/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1022 - accuracy: 0.9638\n",
      "Epoch 150/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1195 - accuracy: 0.9582\n",
      "Epoch 151/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1045 - accuracy: 0.9628\n",
      "Epoch 152/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0946 - accuracy: 0.9656\n",
      "Epoch 153/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1064 - accuracy: 0.9610\n",
      "Epoch 154/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0983 - accuracy: 0.9652\n",
      "Epoch 155/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.1175 - accuracy: 0.9584\n",
      "Epoch 156/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0997 - accuracy: 0.9622\n",
      "Epoch 157/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1046 - accuracy: 0.9602\n",
      "Epoch 158/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1055 - accuracy: 0.9612\n",
      "Epoch 159/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1155 - accuracy: 0.9596\n",
      "Epoch 160/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1036 - accuracy: 0.9608\n",
      "Epoch 161/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1040 - accuracy: 0.9618\n",
      "Epoch 162/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1158 - accuracy: 0.9614\n",
      "Epoch 163/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1067 - accuracy: 0.9610\n",
      "Epoch 164/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1142 - accuracy: 0.9590\n",
      "Epoch 165/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1074 - accuracy: 0.9588\n",
      "Epoch 166/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1027 - accuracy: 0.9618\n",
      "Epoch 167/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0960 - accuracy: 0.9664\n",
      "Epoch 168/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1039 - accuracy: 0.9630\n",
      "Epoch 169/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1019 - accuracy: 0.9614\n",
      "Epoch 170/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1141 - accuracy: 0.9576\n",
      "Epoch 171/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0943 - accuracy: 0.9666\n",
      "Epoch 172/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0948 - accuracy: 0.9656\n",
      "Epoch 173/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1093 - accuracy: 0.9604\n",
      "Epoch 174/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0918 - accuracy: 0.9660\n",
      "Epoch 175/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0965 - accuracy: 0.9666\n",
      "Epoch 176/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1105 - accuracy: 0.9590\n",
      "Epoch 177/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1060 - accuracy: 0.9604\n",
      "Epoch 178/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1114 - accuracy: 0.9610\n",
      "Epoch 179/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1176 - accuracy: 0.9598\n",
      "Epoch 180/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1070 - accuracy: 0.9612\n",
      "Epoch 181/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1048 - accuracy: 0.9612\n",
      "Epoch 182/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1019 - accuracy: 0.9634\n",
      "Epoch 183/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0929 - accuracy: 0.9662\n",
      "Epoch 184/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0965 - accuracy: 0.9630\n",
      "Epoch 185/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0972 - accuracy: 0.9644\n",
      "Epoch 186/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1009 - accuracy: 0.9628\n",
      "Epoch 187/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1002 - accuracy: 0.9620\n",
      "Epoch 188/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1060 - accuracy: 0.9644\n",
      "Epoch 189/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0986 - accuracy: 0.9660\n",
      "Epoch 190/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1100 - accuracy: 0.9546\n",
      "Epoch 191/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0985 - accuracy: 0.9658\n",
      "Epoch 192/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1001 - accuracy: 0.9650\n",
      "Epoch 193/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1088 - accuracy: 0.9628\n",
      "Epoch 194/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0963 - accuracy: 0.9638\n",
      "Epoch 195/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1153 - accuracy: 0.9576\n",
      "Epoch 196/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0998 - accuracy: 0.9628\n",
      "Epoch 197/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0989 - accuracy: 0.9620\n",
      "Epoch 198/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1000 - accuracy: 0.9646\n",
      "Epoch 199/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1032 - accuracy: 0.9632\n",
      "Epoch 200/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0953 - accuracy: 0.9630\n",
      "Epoch 201/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1046 - accuracy: 0.9632\n",
      "Epoch 202/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0967 - accuracy: 0.9632\n",
      "Epoch 203/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1033 - accuracy: 0.9608\n",
      "Epoch 204/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0996 - accuracy: 0.9602\n",
      "Epoch 205/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0997 - accuracy: 0.9636\n",
      "Epoch 206/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0974 - accuracy: 0.9658\n",
      "Epoch 207/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1049 - accuracy: 0.9616\n",
      "Epoch 208/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0950 - accuracy: 0.9632\n",
      "Epoch 209/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1002 - accuracy: 0.9604\n",
      "Epoch 210/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0846 - accuracy: 0.9664\n",
      "Epoch 211/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0996 - accuracy: 0.9624\n",
      "Epoch 212/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1007 - accuracy: 0.9630\n",
      "Epoch 213/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0997 - accuracy: 0.9656\n",
      "Epoch 214/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1076 - accuracy: 0.9620\n",
      "Epoch 215/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1000 - accuracy: 0.9644\n",
      "Epoch 216/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1014 - accuracy: 0.9594\n",
      "Epoch 217/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0954 - accuracy: 0.9656\n",
      "Epoch 218/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0985 - accuracy: 0.9646\n",
      "Epoch 219/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0927 - accuracy: 0.9620\n",
      "Epoch 220/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0930 - accuracy: 0.9650\n",
      "Epoch 221/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1027 - accuracy: 0.9620\n",
      "Epoch 222/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1105 - accuracy: 0.9604\n",
      "Epoch 223/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0857 - accuracy: 0.9694\n",
      "Epoch 224/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0894 - accuracy: 0.9656\n",
      "Epoch 225/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1072 - accuracy: 0.9626\n",
      "Epoch 226/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0892 - accuracy: 0.9644\n",
      "Epoch 227/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0949 - accuracy: 0.9614\n",
      "Epoch 228/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0999 - accuracy: 0.9618\n",
      "Epoch 229/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0985 - accuracy: 0.9632\n",
      "Epoch 230/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1002 - accuracy: 0.9626\n",
      "Epoch 231/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0905 - accuracy: 0.9654\n",
      "Epoch 232/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1075 - accuracy: 0.9594\n",
      "Epoch 233/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0964 - accuracy: 0.9638\n",
      "Epoch 234/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0830 - accuracy: 0.9686\n",
      "Epoch 235/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0989 - accuracy: 0.9628\n",
      "Epoch 236/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0980 - accuracy: 0.9630\n",
      "Epoch 237/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0979 - accuracy: 0.9646\n",
      "Epoch 238/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0866 - accuracy: 0.9672\n",
      "Epoch 239/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1042 - accuracy: 0.9632\n",
      "Epoch 240/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0869 - accuracy: 0.9666\n",
      "Epoch 241/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0923 - accuracy: 0.9632\n",
      "Epoch 242/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0913 - accuracy: 0.9662\n",
      "Epoch 243/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0928 - accuracy: 0.9654\n",
      "Epoch 244/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0960 - accuracy: 0.9648\n",
      "Epoch 245/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0939 - accuracy: 0.9650\n",
      "Epoch 246/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0981 - accuracy: 0.9638\n",
      "Epoch 247/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0907 - accuracy: 0.9638\n",
      "Epoch 248/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0921 - accuracy: 0.9632\n",
      "Epoch 249/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0998 - accuracy: 0.9632\n",
      "Epoch 250/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1012 - accuracy: 0.9630\n",
      "Epoch 251/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0940 - accuracy: 0.9658\n",
      "Epoch 252/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0966 - accuracy: 0.9652\n",
      "Epoch 253/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0992 - accuracy: 0.9640\n",
      "Epoch 254/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1235 - accuracy: 0.9554\n",
      "Epoch 255/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0913 - accuracy: 0.9628 0s - loss: 0.0926 - accuracy\n",
      "Epoch 256/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0841 - accuracy: 0.9702\n",
      "Epoch 257/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1002 - accuracy: 0.9654\n",
      "Epoch 258/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0956 - accuracy: 0.9672\n",
      "Epoch 259/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0946 - accuracy: 0.9648\n",
      "Epoch 260/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0872 - accuracy: 0.9686\n",
      "Epoch 261/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0970 - accuracy: 0.9658\n",
      "Epoch 262/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1042 - accuracy: 0.9622\n",
      "Epoch 263/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0944 - accuracy: 0.9630\n",
      "Epoch 264/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0941 - accuracy: 0.9618\n",
      "Epoch 265/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0936 - accuracy: 0.9634\n",
      "Epoch 266/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0858 - accuracy: 0.9688\n",
      "Epoch 267/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0935 - accuracy: 0.9662\n",
      "Epoch 268/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0939 - accuracy: 0.9650\n",
      "Epoch 269/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0771 - accuracy: 0.9712\n",
      "Epoch 270/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0924 - accuracy: 0.9670\n",
      "Epoch 271/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0930 - accuracy: 0.9630\n",
      "Epoch 272/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0963 - accuracy: 0.9620\n",
      "Epoch 273/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0892 - accuracy: 0.9686\n",
      "Epoch 274/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0898 - accuracy: 0.9668\n",
      "Epoch 275/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1068 - accuracy: 0.9618\n",
      "Epoch 276/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1025 - accuracy: 0.9604\n",
      "Epoch 277/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0937 - accuracy: 0.9658\n",
      "Epoch 278/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1020 - accuracy: 0.9646\n",
      "Epoch 279/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1013 - accuracy: 0.9660\n",
      "Epoch 280/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0928 - accuracy: 0.9656\n",
      "Epoch 281/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0946 - accuracy: 0.9644\n",
      "Epoch 282/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0904 - accuracy: 0.9648\n",
      "Epoch 283/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0885 - accuracy: 0.9640\n",
      "Epoch 284/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0819 - accuracy: 0.9718\n",
      "Epoch 285/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0834 - accuracy: 0.9694\n",
      "Epoch 286/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0963 - accuracy: 0.9646\n",
      "Epoch 287/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0885 - accuracy: 0.9650\n",
      "Epoch 288/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0976 - accuracy: 0.9678\n",
      "Epoch 289/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1017 - accuracy: 0.9642\n",
      "Epoch 290/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0962 - accuracy: 0.9602\n",
      "Epoch 291/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0886 - accuracy: 0.9672\n",
      "Epoch 292/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.1027 - accuracy: 0.9610\n",
      "Epoch 293/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0987 - accuracy: 0.9616\n",
      "Epoch 294/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1003 - accuracy: 0.9604\n",
      "Epoch 295/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0905 - accuracy: 0.9672\n",
      "Epoch 296/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0799 - accuracy: 0.9698\n",
      "Epoch 297/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0938 - accuracy: 0.9638\n",
      "Epoch 298/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0924 - accuracy: 0.9670\n",
      "Epoch 299/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0895 - accuracy: 0.9646\n",
      "Epoch 300/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0940 - accuracy: 0.9670\n",
      "Epoch 301/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0920 - accuracy: 0.9672\n",
      "Epoch 302/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0878 - accuracy: 0.9648\n",
      "Epoch 303/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0931 - accuracy: 0.9626\n",
      "Epoch 304/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0861 - accuracy: 0.9640\n",
      "Epoch 305/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0825 - accuracy: 0.9722\n",
      "Epoch 306/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0787 - accuracy: 0.9690\n",
      "Epoch 307/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.1010 - accuracy: 0.9614\n",
      "Epoch 308/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0893 - accuracy: 0.9672\n",
      "Epoch 309/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0801 - accuracy: 0.9694\n",
      "Epoch 310/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0925 - accuracy: 0.9652\n",
      "Epoch 311/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0930 - accuracy: 0.9640\n",
      "Epoch 312/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0835 - accuracy: 0.9686\n",
      "Epoch 313/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.1026 - accuracy: 0.9632\n",
      "Epoch 314/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0935 - accuracy: 0.9662\n",
      "Epoch 315/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1002 - accuracy: 0.9628\n",
      "Epoch 316/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0943 - accuracy: 0.9646\n",
      "Epoch 317/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0918 - accuracy: 0.9648\n",
      "Epoch 318/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0832 - accuracy: 0.9690\n",
      "Epoch 319/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0788 - accuracy: 0.9732\n",
      "Epoch 320/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0969 - accuracy: 0.9624\n",
      "Epoch 321/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0942 - accuracy: 0.9678\n",
      "Epoch 322/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0913 - accuracy: 0.9642\n",
      "Epoch 323/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0903 - accuracy: 0.9676\n",
      "Epoch 324/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0817 - accuracy: 0.9704\n",
      "Epoch 325/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0840 - accuracy: 0.9680\n",
      "Epoch 326/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0781 - accuracy: 0.9686\n",
      "Epoch 327/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0847 - accuracy: 0.9672\n",
      "Epoch 328/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0841 - accuracy: 0.9672\n",
      "Epoch 329/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0920 - accuracy: 0.9652\n",
      "Epoch 330/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0868 - accuracy: 0.9674\n",
      "Epoch 331/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0842 - accuracy: 0.9686\n",
      "Epoch 332/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0899 - accuracy: 0.9638\n",
      "Epoch 333/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0836 - accuracy: 0.9664\n",
      "Epoch 334/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0872 - accuracy: 0.9686\n",
      "Epoch 335/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0947 - accuracy: 0.9664\n",
      "Epoch 336/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0911 - accuracy: 0.9650\n",
      "Epoch 337/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0842 - accuracy: 0.9676\n",
      "Epoch 338/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0947 - accuracy: 0.9664\n",
      "Epoch 339/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0842 - accuracy: 0.9688\n",
      "Epoch 340/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0765 - accuracy: 0.9720\n",
      "Epoch 341/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0933 - accuracy: 0.9656\n",
      "Epoch 342/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.1009 - accuracy: 0.9646\n",
      "Epoch 343/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0833 - accuracy: 0.9678\n",
      "Epoch 344/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0915 - accuracy: 0.9618\n",
      "Epoch 345/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0824 - accuracy: 0.9694\n",
      "Epoch 346/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0926 - accuracy: 0.9678\n",
      "Epoch 347/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0873 - accuracy: 0.9628\n",
      "Epoch 348/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0938 - accuracy: 0.9650\n",
      "Epoch 349/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0833 - accuracy: 0.9682\n",
      "Epoch 350/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0861 - accuracy: 0.9632\n",
      "Epoch 351/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0902 - accuracy: 0.9712\n",
      "Epoch 352/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0932 - accuracy: 0.9640\n",
      "Epoch 353/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0990 - accuracy: 0.9640\n",
      "Epoch 354/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0859 - accuracy: 0.9670\n",
      "Epoch 355/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0832 - accuracy: 0.9690\n",
      "Epoch 356/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0788 - accuracy: 0.9694\n",
      "Epoch 357/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0869 - accuracy: 0.9686\n",
      "Epoch 358/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0883 - accuracy: 0.9702\n",
      "Epoch 359/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0819 - accuracy: 0.9668\n",
      "Epoch 360/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0988 - accuracy: 0.9616\n",
      "Epoch 361/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0802 - accuracy: 0.9702\n",
      "Epoch 362/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0972 - accuracy: 0.9674\n",
      "Epoch 363/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0983 - accuracy: 0.9616\n",
      "Epoch 364/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0867 - accuracy: 0.9664\n",
      "Epoch 365/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0786 - accuracy: 0.9710\n",
      "Epoch 366/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0842 - accuracy: 0.9698\n",
      "Epoch 367/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0913 - accuracy: 0.9662\n",
      "Epoch 368/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0788 - accuracy: 0.9696\n",
      "Epoch 369/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0834 - accuracy: 0.9654\n",
      "Epoch 370/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0879 - accuracy: 0.9674\n",
      "Epoch 371/1024\n",
      "4996/4996 [==============================] - 0s 73us/step - loss: 0.0903 - accuracy: 0.9666\n",
      "Epoch 372/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0871 - accuracy: 0.9676\n",
      "Epoch 373/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0907 - accuracy: 0.9648\n",
      "Epoch 374/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0801 - accuracy: 0.9702\n",
      "Epoch 375/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0882 - accuracy: 0.9640\n",
      "Epoch 376/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0767 - accuracy: 0.9708\n",
      "Epoch 377/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0739 - accuracy: 0.9712\n",
      "Epoch 378/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0887 - accuracy: 0.9658\n",
      "Epoch 379/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0819 - accuracy: 0.9702\n",
      "Epoch 380/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0813 - accuracy: 0.9670\n",
      "Epoch 381/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0847 - accuracy: 0.9650\n",
      "Epoch 382/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0820 - accuracy: 0.9674\n",
      "Epoch 383/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0844 - accuracy: 0.9676\n",
      "Epoch 384/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0796 - accuracy: 0.9688\n",
      "Epoch 385/1024\n",
      "4996/4996 [==============================] - 0s 72us/step - loss: 0.0821 - accuracy: 0.9662\n",
      "Epoch 386/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0859 - accuracy: 0.9692\n",
      "Epoch 387/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0837 - accuracy: 0.9674\n",
      "Epoch 388/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0809 - accuracy: 0.9696\n",
      "Epoch 389/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0887 - accuracy: 0.9684\n",
      "Epoch 390/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0842 - accuracy: 0.9684\n",
      "Epoch 391/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0913 - accuracy: 0.9642\n",
      "Epoch 392/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0952 - accuracy: 0.9658\n",
      "Epoch 393/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0946 - accuracy: 0.9648\n",
      "Epoch 394/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0786 - accuracy: 0.9686\n",
      "Epoch 395/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0866 - accuracy: 0.9670\n",
      "Epoch 396/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0734 - accuracy: 0.9722\n",
      "Epoch 397/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0910 - accuracy: 0.9650\n",
      "Epoch 398/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0796 - accuracy: 0.9708\n",
      "Epoch 399/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0902 - accuracy: 0.9672\n",
      "Epoch 400/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0938 - accuracy: 0.9638\n",
      "Epoch 401/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0862 - accuracy: 0.9658\n",
      "Epoch 402/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0964 - accuracy: 0.9640\n",
      "Epoch 403/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0955 - accuracy: 0.9666\n",
      "Epoch 404/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0820 - accuracy: 0.9672\n",
      "Epoch 405/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0813 - accuracy: 0.9676\n",
      "Epoch 406/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0843 - accuracy: 0.9690\n",
      "Epoch 407/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0851 - accuracy: 0.9682\n",
      "Epoch 408/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9662\n",
      "Epoch 409/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0858 - accuracy: 0.9658\n",
      "Epoch 410/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0763 - accuracy: 0.9720\n",
      "Epoch 411/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0887 - accuracy: 0.9682\n",
      "Epoch 412/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0836 - accuracy: 0.9656\n",
      "Epoch 413/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0892 - accuracy: 0.9676\n",
      "Epoch 414/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0820 - accuracy: 0.9700\n",
      "Epoch 415/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0880 - accuracy: 0.9654\n",
      "Epoch 416/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0873 - accuracy: 0.9662\n",
      "Epoch 417/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0807 - accuracy: 0.9656\n",
      "Epoch 418/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0767 - accuracy: 0.9706\n",
      "Epoch 419/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0976 - accuracy: 0.9620\n",
      "Epoch 420/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0859 - accuracy: 0.9656\n",
      "Epoch 421/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0725 - accuracy: 0.9706\n",
      "Epoch 422/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0819 - accuracy: 0.9696\n",
      "Epoch 423/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0810 - accuracy: 0.9684\n",
      "Epoch 424/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0865 - accuracy: 0.9660\n",
      "Epoch 425/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0929 - accuracy: 0.9632\n",
      "Epoch 426/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0830 - accuracy: 0.9692\n",
      "Epoch 427/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0732 - accuracy: 0.9714\n",
      "Epoch 428/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0788 - accuracy: 0.9704\n",
      "Epoch 429/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0838 - accuracy: 0.9668\n",
      "Epoch 430/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0805 - accuracy: 0.9678\n",
      "Epoch 431/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0830 - accuracy: 0.9682\n",
      "Epoch 432/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0785 - accuracy: 0.9678\n",
      "Epoch 433/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0773 - accuracy: 0.9706\n",
      "Epoch 434/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0724 - accuracy: 0.9716\n",
      "Epoch 435/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0883 - accuracy: 0.9630\n",
      "Epoch 436/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0847 - accuracy: 0.9672\n",
      "Epoch 437/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0831 - accuracy: 0.9684\n",
      "Epoch 438/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0813 - accuracy: 0.9682\n",
      "Epoch 439/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0836 - accuracy: 0.9690\n",
      "Epoch 440/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0802 - accuracy: 0.9698\n",
      "Epoch 441/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0871 - accuracy: 0.9684\n",
      "Epoch 442/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0812 - accuracy: 0.9706\n",
      "Epoch 443/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0814 - accuracy: 0.9698\n",
      "Epoch 444/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0774 - accuracy: 0.9716\n",
      "Epoch 445/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0788 - accuracy: 0.9704\n",
      "Epoch 446/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0817 - accuracy: 0.9686\n",
      "Epoch 447/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0829 - accuracy: 0.9674\n",
      "Epoch 448/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0893 - accuracy: 0.9670\n",
      "Epoch 449/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0803 - accuracy: 0.9684\n",
      "Epoch 450/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0751 - accuracy: 0.9724\n",
      "Epoch 451/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0862 - accuracy: 0.9692\n",
      "Epoch 452/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0784 - accuracy: 0.9670\n",
      "Epoch 453/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0818 - accuracy: 0.9686\n",
      "Epoch 454/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0879 - accuracy: 0.9662\n",
      "Epoch 455/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0803 - accuracy: 0.9718\n",
      "Epoch 456/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0901 - accuracy: 0.9662\n",
      "Epoch 457/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0881 - accuracy: 0.9688\n",
      "Epoch 458/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0831 - accuracy: 0.9688\n",
      "Epoch 459/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0804 - accuracy: 0.9688\n",
      "Epoch 460/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0832 - accuracy: 0.9690\n",
      "Epoch 461/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0890 - accuracy: 0.9684\n",
      "Epoch 462/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9704\n",
      "Epoch 463/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0829 - accuracy: 0.9704\n",
      "Epoch 464/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0844 - accuracy: 0.9670\n",
      "Epoch 465/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0822 - accuracy: 0.9692\n",
      "Epoch 466/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0885 - accuracy: 0.9660\n",
      "Epoch 467/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0783 - accuracy: 0.9710\n",
      "Epoch 468/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0843 - accuracy: 0.9664\n",
      "Epoch 469/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9694\n",
      "Epoch 470/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0848 - accuracy: 0.9692\n",
      "Epoch 471/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0808 - accuracy: 0.9684\n",
      "Epoch 472/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0784 - accuracy: 0.9718\n",
      "Epoch 473/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0779 - accuracy: 0.9678\n",
      "Epoch 474/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0709 - accuracy: 0.9736\n",
      "Epoch 475/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0814 - accuracy: 0.9700\n",
      "Epoch 476/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0815 - accuracy: 0.9694\n",
      "Epoch 477/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0896 - accuracy: 0.9646\n",
      "Epoch 478/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0788 - accuracy: 0.9702\n",
      "Epoch 479/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0856 - accuracy: 0.9656\n",
      "Epoch 480/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0861 - accuracy: 0.9684\n",
      "Epoch 481/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0787 - accuracy: 0.9676\n",
      "Epoch 482/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0732 - accuracy: 0.9712\n",
      "Epoch 483/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.1000 - accuracy: 0.9632\n",
      "Epoch 484/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0776 - accuracy: 0.9692\n",
      "Epoch 485/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0769 - accuracy: 0.9720\n",
      "Epoch 486/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0787 - accuracy: 0.9702\n",
      "Epoch 487/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.1056 - accuracy: 0.9648\n",
      "Epoch 488/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0724 - accuracy: 0.9706\n",
      "Epoch 489/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0845 - accuracy: 0.9668\n",
      "Epoch 490/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0741 - accuracy: 0.9696\n",
      "Epoch 491/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0862 - accuracy: 0.9656\n",
      "Epoch 492/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9692\n",
      "Epoch 493/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0777 - accuracy: 0.9692\n",
      "Epoch 494/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0779 - accuracy: 0.9678\n",
      "Epoch 495/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0874 - accuracy: 0.9670\n",
      "Epoch 496/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0744 - accuracy: 0.9714\n",
      "Epoch 497/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0831 - accuracy: 0.9696\n",
      "Epoch 498/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0733 - accuracy: 0.9728\n",
      "Epoch 499/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0752 - accuracy: 0.9702\n",
      "Epoch 500/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0837 - accuracy: 0.9668\n",
      "Epoch 501/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0808 - accuracy: 0.9674\n",
      "Epoch 502/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0759 - accuracy: 0.9706\n",
      "Epoch 503/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0779 - accuracy: 0.9694\n",
      "Epoch 504/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0813 - accuracy: 0.9700\n",
      "Epoch 505/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0829 - accuracy: 0.9670\n",
      "Epoch 506/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0785 - accuracy: 0.9702\n",
      "Epoch 507/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9698\n",
      "Epoch 508/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0785 - accuracy: 0.9698\n",
      "Epoch 509/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0798 - accuracy: 0.9702\n",
      "Epoch 510/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0762 - accuracy: 0.9690\n",
      "Epoch 511/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0774 - accuracy: 0.9718\n",
      "Epoch 512/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0992 - accuracy: 0.9668\n",
      "Epoch 513/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0907 - accuracy: 0.9654\n",
      "Epoch 514/1024\n",
      "4996/4996 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.96 - 0s 69us/step - loss: 0.0890 - accuracy: 0.9672\n",
      "Epoch 515/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0842 - accuracy: 0.9682\n",
      "Epoch 516/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0824 - accuracy: 0.9676\n",
      "Epoch 517/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0714 - accuracy: 0.9708\n",
      "Epoch 518/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0736 - accuracy: 0.9728\n",
      "Epoch 519/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0798 - accuracy: 0.9690\n",
      "Epoch 520/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0767 - accuracy: 0.9710 0s - loss: 0.0896 - accura\n",
      "Epoch 521/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0714 - accuracy: 0.9716\n",
      "Epoch 522/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0807 - accuracy: 0.9662\n",
      "Epoch 523/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9694\n",
      "Epoch 524/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0842 - accuracy: 0.9692\n",
      "Epoch 525/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0725 - accuracy: 0.9702\n",
      "Epoch 526/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0794 - accuracy: 0.9698\n",
      "Epoch 527/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0773 - accuracy: 0.9694\n",
      "Epoch 528/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0806 - accuracy: 0.9692\n",
      "Epoch 529/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0873 - accuracy: 0.9658\n",
      "Epoch 530/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0785 - accuracy: 0.9716\n",
      "Epoch 531/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0747 - accuracy: 0.9698\n",
      "Epoch 532/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0782 - accuracy: 0.9708\n",
      "Epoch 533/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0744 - accuracy: 0.9706\n",
      "Epoch 534/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0779 - accuracy: 0.9700\n",
      "Epoch 535/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0742 - accuracy: 0.9708\n",
      "Epoch 536/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0767 - accuracy: 0.9700\n",
      "Epoch 537/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0831 - accuracy: 0.9670\n",
      "Epoch 538/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0758 - accuracy: 0.9694\n",
      "Epoch 539/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0764 - accuracy: 0.9710\n",
      "Epoch 540/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0797 - accuracy: 0.9686\n",
      "Epoch 541/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0803 - accuracy: 0.9714\n",
      "Epoch 542/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0810 - accuracy: 0.9682\n",
      "Epoch 543/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0802 - accuracy: 0.9678\n",
      "Epoch 544/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0846 - accuracy: 0.9680\n",
      "Epoch 545/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0813 - accuracy: 0.9674\n",
      "Epoch 546/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0784 - accuracy: 0.9696\n",
      "Epoch 547/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0791 - accuracy: 0.9686\n",
      "Epoch 548/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0719 - accuracy: 0.9726\n",
      "Epoch 549/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0764 - accuracy: 0.9716\n",
      "Epoch 550/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0884 - accuracy: 0.9652\n",
      "Epoch 551/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0885 - accuracy: 0.9656\n",
      "Epoch 552/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0860 - accuracy: 0.9668\n",
      "Epoch 553/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0833 - accuracy: 0.9686\n",
      "Epoch 554/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0746 - accuracy: 0.9690\n",
      "Epoch 555/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0847 - accuracy: 0.9678\n",
      "Epoch 556/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0766 - accuracy: 0.9700\n",
      "Epoch 557/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0744 - accuracy: 0.9724\n",
      "Epoch 558/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0731 - accuracy: 0.9726\n",
      "Epoch 559/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0694 - accuracy: 0.9700\n",
      "Epoch 560/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0694 - accuracy: 0.9728\n",
      "Epoch 561/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0839 - accuracy: 0.9690\n",
      "Epoch 562/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0796 - accuracy: 0.9698\n",
      "Epoch 563/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0817 - accuracy: 0.9688\n",
      "Epoch 564/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9696\n",
      "Epoch 565/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0760 - accuracy: 0.9692\n",
      "Epoch 566/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0709 - accuracy: 0.9726\n",
      "Epoch 567/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0752 - accuracy: 0.9712\n",
      "Epoch 568/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0784 - accuracy: 0.9696\n",
      "Epoch 569/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9666\n",
      "Epoch 570/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0810 - accuracy: 0.9694\n",
      "Epoch 571/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0802 - accuracy: 0.9660\n",
      "Epoch 572/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0940 - accuracy: 0.9692\n",
      "Epoch 573/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0691 - accuracy: 0.9738\n",
      "Epoch 574/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0801 - accuracy: 0.9714\n",
      "Epoch 575/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0792 - accuracy: 0.9700\n",
      "Epoch 576/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0879 - accuracy: 0.9634\n",
      "Epoch 577/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0699 - accuracy: 0.9728\n",
      "Epoch 578/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0665 - accuracy: 0.9732\n",
      "Epoch 579/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0720 - accuracy: 0.9730\n",
      "Epoch 580/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0840 - accuracy: 0.9676\n",
      "Epoch 581/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0760 - accuracy: 0.9686\n",
      "Epoch 582/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0705 - accuracy: 0.9710\n",
      "Epoch 583/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0691 - accuracy: 0.9732\n",
      "Epoch 584/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0698 - accuracy: 0.9704\n",
      "Epoch 585/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0767 - accuracy: 0.9702\n",
      "Epoch 586/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0870 - accuracy: 0.9662\n",
      "Epoch 587/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0759 - accuracy: 0.9704\n",
      "Epoch 588/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9734\n",
      "Epoch 589/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0922 - accuracy: 0.9690\n",
      "Epoch 590/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0787 - accuracy: 0.9698\n",
      "Epoch 591/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0794 - accuracy: 0.9698\n",
      "Epoch 592/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0707 - accuracy: 0.9720\n",
      "Epoch 593/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0640 - accuracy: 0.9766\n",
      "Epoch 594/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0700 - accuracy: 0.9730\n",
      "Epoch 595/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0679 - accuracy: 0.9722\n",
      "Epoch 596/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0777 - accuracy: 0.9722\n",
      "Epoch 597/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0888 - accuracy: 0.9646\n",
      "Epoch 598/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0749 - accuracy: 0.9714\n",
      "Epoch 599/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0740 - accuracy: 0.9726\n",
      "Epoch 600/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0833 - accuracy: 0.9652\n",
      "Epoch 601/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0735 - accuracy: 0.9724\n",
      "Epoch 602/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0779 - accuracy: 0.9690\n",
      "Epoch 603/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0739 - accuracy: 0.9704\n",
      "Epoch 604/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0783 - accuracy: 0.9674\n",
      "Epoch 605/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0771 - accuracy: 0.9710\n",
      "Epoch 606/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0759 - accuracy: 0.9708\n",
      "Epoch 607/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0777 - accuracy: 0.9722\n",
      "Epoch 608/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0769 - accuracy: 0.9714\n",
      "Epoch 609/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0802 - accuracy: 0.9710\n",
      "Epoch 610/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0777 - accuracy: 0.9694\n",
      "Epoch 611/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0830 - accuracy: 0.9702\n",
      "Epoch 612/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0805 - accuracy: 0.9694\n",
      "Epoch 613/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0781 - accuracy: 0.9692\n",
      "Epoch 614/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9674\n",
      "Epoch 615/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0706 - accuracy: 0.9736\n",
      "Epoch 616/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0829 - accuracy: 0.9680\n",
      "Epoch 617/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0698 - accuracy: 0.9718\n",
      "Epoch 618/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0771 - accuracy: 0.9684\n",
      "Epoch 619/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0739 - accuracy: 0.9698\n",
      "Epoch 620/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0866 - accuracy: 0.9672\n",
      "Epoch 621/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0795 - accuracy: 0.9720\n",
      "Epoch 622/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0811 - accuracy: 0.9716\n",
      "Epoch 623/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0678 - accuracy: 0.9734\n",
      "Epoch 624/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0797 - accuracy: 0.9688\n",
      "Epoch 625/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0745 - accuracy: 0.9718\n",
      "Epoch 626/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0816 - accuracy: 0.9688\n",
      "Epoch 627/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0819 - accuracy: 0.9714\n",
      "Epoch 628/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0826 - accuracy: 0.9712 0s - loss: 0.0916 - accuracy\n",
      "Epoch 629/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0766 - accuracy: 0.9692\n",
      "Epoch 630/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0840 - accuracy: 0.9680\n",
      "Epoch 631/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0726 - accuracy: 0.9712\n",
      "Epoch 632/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0745 - accuracy: 0.9714\n",
      "Epoch 633/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0774 - accuracy: 0.9698\n",
      "Epoch 634/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0743 - accuracy: 0.9706\n",
      "Epoch 635/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0914 - accuracy: 0.9650\n",
      "Epoch 636/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0763 - accuracy: 0.9686\n",
      "Epoch 637/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0792 - accuracy: 0.9702\n",
      "Epoch 638/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0826 - accuracy: 0.9666\n",
      "Epoch 639/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0712 - accuracy: 0.9716\n",
      "Epoch 640/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0759 - accuracy: 0.9700\n",
      "Epoch 641/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0758 - accuracy: 0.9696\n",
      "Epoch 642/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0677 - accuracy: 0.9744\n",
      "Epoch 643/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0748 - accuracy: 0.9718\n",
      "Epoch 644/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0757 - accuracy: 0.9688\n",
      "Epoch 645/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0763 - accuracy: 0.9704\n",
      "Epoch 646/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0755 - accuracy: 0.9704\n",
      "Epoch 647/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0784 - accuracy: 0.9698\n",
      "Epoch 648/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0726 - accuracy: 0.9742\n",
      "Epoch 649/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0742 - accuracy: 0.9724\n",
      "Epoch 650/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0729 - accuracy: 0.9716\n",
      "Epoch 651/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0734 - accuracy: 0.9718\n",
      "Epoch 652/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0717 - accuracy: 0.9700\n",
      "Epoch 653/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0830 - accuracy: 0.9670\n",
      "Epoch 654/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0750 - accuracy: 0.9718\n",
      "Epoch 655/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0733 - accuracy: 0.9704\n",
      "Epoch 656/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0714 - accuracy: 0.9708\n",
      "Epoch 657/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9712\n",
      "Epoch 658/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0806 - accuracy: 0.9696\n",
      "Epoch 659/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0809 - accuracy: 0.9664\n",
      "Epoch 660/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0824 - accuracy: 0.9682\n",
      "Epoch 661/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0728 - accuracy: 0.9702\n",
      "Epoch 662/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0773 - accuracy: 0.9718\n",
      "Epoch 663/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0785 - accuracy: 0.9680\n",
      "Epoch 664/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0733 - accuracy: 0.9706\n",
      "Epoch 665/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0822 - accuracy: 0.9678\n",
      "Epoch 666/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0846 - accuracy: 0.9692\n",
      "Epoch 667/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9694\n",
      "Epoch 668/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0788 - accuracy: 0.9714\n",
      "Epoch 669/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0710 - accuracy: 0.9732\n",
      "Epoch 670/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0658 - accuracy: 0.9738\n",
      "Epoch 671/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0654 - accuracy: 0.9734\n",
      "Epoch 672/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0731 - accuracy: 0.9714\n",
      "Epoch 673/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0824 - accuracy: 0.9700\n",
      "Epoch 674/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0842 - accuracy: 0.9682\n",
      "Epoch 675/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0751 - accuracy: 0.9716\n",
      "Epoch 676/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0710 - accuracy: 0.9718\n",
      "Epoch 677/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0737 - accuracy: 0.9698\n",
      "Epoch 678/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0756 - accuracy: 0.9682\n",
      "Epoch 679/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0710 - accuracy: 0.9708\n",
      "Epoch 680/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0771 - accuracy: 0.9716\n",
      "Epoch 681/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9720\n",
      "Epoch 682/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0763 - accuracy: 0.9726\n",
      "Epoch 683/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0699 - accuracy: 0.9716\n",
      "Epoch 684/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0687 - accuracy: 0.9722\n",
      "Epoch 685/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0724 - accuracy: 0.9704\n",
      "Epoch 686/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0739 - accuracy: 0.9700\n",
      "Epoch 687/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0831 - accuracy: 0.9692\n",
      "Epoch 688/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9728\n",
      "Epoch 689/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0683 - accuracy: 0.9728\n",
      "Epoch 690/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0743 - accuracy: 0.9746\n",
      "Epoch 691/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0798 - accuracy: 0.9688\n",
      "Epoch 692/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0654 - accuracy: 0.9746\n",
      "Epoch 693/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0832 - accuracy: 0.9696\n",
      "Epoch 694/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0761 - accuracy: 0.9696\n",
      "Epoch 695/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0770 - accuracy: 0.9692\n",
      "Epoch 696/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0791 - accuracy: 0.9676\n",
      "Epoch 697/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0776 - accuracy: 0.9678\n",
      "Epoch 698/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0764 - accuracy: 0.9696\n",
      "Epoch 699/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0689 - accuracy: 0.9712\n",
      "Epoch 700/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0718 - accuracy: 0.9734\n",
      "Epoch 701/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0694 - accuracy: 0.9738\n",
      "Epoch 702/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0698 - accuracy: 0.9728\n",
      "Epoch 703/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0835 - accuracy: 0.9680\n",
      "Epoch 704/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0695 - accuracy: 0.9710\n",
      "Epoch 705/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0689 - accuracy: 0.9726\n",
      "Epoch 706/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0864 - accuracy: 0.9654\n",
      "Epoch 707/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0684 - accuracy: 0.9736\n",
      "Epoch 708/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0742 - accuracy: 0.9712\n",
      "Epoch 709/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0864 - accuracy: 0.9734\n",
      "Epoch 710/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9720\n",
      "Epoch 711/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0665 - accuracy: 0.9740\n",
      "Epoch 712/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0677 - accuracy: 0.9728\n",
      "Epoch 713/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0746 - accuracy: 0.9714\n",
      "Epoch 714/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0804 - accuracy: 0.9690\n",
      "Epoch 715/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0713 - accuracy: 0.9704\n",
      "Epoch 716/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0680 - accuracy: 0.9734\n",
      "Epoch 717/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0681 - accuracy: 0.9722\n",
      "Epoch 718/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0744 - accuracy: 0.9688\n",
      "Epoch 719/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0785 - accuracy: 0.9698\n",
      "Epoch 720/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0710 - accuracy: 0.9726\n",
      "Epoch 721/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0770 - accuracy: 0.9706\n",
      "Epoch 722/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0725 - accuracy: 0.9714\n",
      "Epoch 723/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0746 - accuracy: 0.9696\n",
      "Epoch 724/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0734 - accuracy: 0.9712\n",
      "Epoch 725/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0768 - accuracy: 0.9708\n",
      "Epoch 726/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0705 - accuracy: 0.9738\n",
      "Epoch 727/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0828 - accuracy: 0.9674\n",
      "Epoch 728/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0915 - accuracy: 0.9704\n",
      "Epoch 729/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0697 - accuracy: 0.9712\n",
      "Epoch 730/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0782 - accuracy: 0.9704\n",
      "Epoch 731/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0725 - accuracy: 0.9706\n",
      "Epoch 732/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0822 - accuracy: 0.9716\n",
      "Epoch 733/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0673 - accuracy: 0.9728\n",
      "Epoch 734/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0693 - accuracy: 0.9730\n",
      "Epoch 735/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0660 - accuracy: 0.9734\n",
      "Epoch 736/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0850 - accuracy: 0.9696\n",
      "Epoch 737/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0672 - accuracy: 0.9736\n",
      "Epoch 738/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0694 - accuracy: 0.9752\n",
      "Epoch 739/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0724 - accuracy: 0.9712\n",
      "Epoch 740/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0820 - accuracy: 0.9700\n",
      "Epoch 741/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0772 - accuracy: 0.9704\n",
      "Epoch 742/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0764 - accuracy: 0.9692\n",
      "Epoch 743/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0656 - accuracy: 0.9740\n",
      "Epoch 744/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0717 - accuracy: 0.9714\n",
      "Epoch 745/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0781 - accuracy: 0.9696\n",
      "Epoch 746/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0721 - accuracy: 0.9726\n",
      "Epoch 747/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0725 - accuracy: 0.9710\n",
      "Epoch 748/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0717 - accuracy: 0.9734\n",
      "Epoch 749/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0669 - accuracy: 0.9740\n",
      "Epoch 750/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0625 - accuracy: 0.9760\n",
      "Epoch 751/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0666 - accuracy: 0.9754\n",
      "Epoch 752/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0792 - accuracy: 0.9702\n",
      "Epoch 753/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0698 - accuracy: 0.9718\n",
      "Epoch 754/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0691 - accuracy: 0.9704\n",
      "Epoch 755/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0778 - accuracy: 0.9696\n",
      "Epoch 756/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0816 - accuracy: 0.9722\n",
      "Epoch 757/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0671 - accuracy: 0.9720\n",
      "Epoch 758/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0716 - accuracy: 0.9714\n",
      "Epoch 759/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0721 - accuracy: 0.9690\n",
      "Epoch 760/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0733 - accuracy: 0.9736\n",
      "Epoch 761/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0663 - accuracy: 0.9754\n",
      "Epoch 762/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0726 - accuracy: 0.9720\n",
      "Epoch 763/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0789 - accuracy: 0.9690\n",
      "Epoch 764/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0779 - accuracy: 0.9688\n",
      "Epoch 765/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0661 - accuracy: 0.9714\n",
      "Epoch 766/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0757 - accuracy: 0.9724\n",
      "Epoch 767/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0709 - accuracy: 0.9720\n",
      "Epoch 768/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0710 - accuracy: 0.9722\n",
      "Epoch 769/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0837 - accuracy: 0.9660\n",
      "Epoch 770/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0738 - accuracy: 0.9716\n",
      "Epoch 771/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0706 - accuracy: 0.9718\n",
      "Epoch 772/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0680 - accuracy: 0.9732\n",
      "Epoch 773/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0690 - accuracy: 0.9752\n",
      "Epoch 774/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0826 - accuracy: 0.9696\n",
      "Epoch 775/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0781 - accuracy: 0.9710\n",
      "Epoch 776/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0720 - accuracy: 0.9708\n",
      "Epoch 777/1024\n",
      "4996/4996 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.96 - 0s 69us/step - loss: 0.0809 - accuracy: 0.9650\n",
      "Epoch 778/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0731 - accuracy: 0.9742\n",
      "Epoch 779/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0667 - accuracy: 0.9740\n",
      "Epoch 780/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0708 - accuracy: 0.9706\n",
      "Epoch 781/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0636 - accuracy: 0.9730\n",
      "Epoch 782/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0647 - accuracy: 0.9738\n",
      "Epoch 783/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0672 - accuracy: 0.9736\n",
      "Epoch 784/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0748 - accuracy: 0.9710\n",
      "Epoch 785/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0860 - accuracy: 0.9698\n",
      "Epoch 786/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0880 - accuracy: 0.9676\n",
      "Epoch 787/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0695 - accuracy: 0.9728\n",
      "Epoch 788/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0720 - accuracy: 0.9698\n",
      "Epoch 789/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0651 - accuracy: 0.9736\n",
      "Epoch 790/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0707 - accuracy: 0.9712\n",
      "Epoch 791/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0684 - accuracy: 0.9748\n",
      "Epoch 792/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0688 - accuracy: 0.9728\n",
      "Epoch 793/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0667 - accuracy: 0.9716\n",
      "Epoch 794/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0680 - accuracy: 0.9734\n",
      "Epoch 795/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0743 - accuracy: 0.9690\n",
      "Epoch 796/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9706\n",
      "Epoch 797/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0719 - accuracy: 0.9690\n",
      "Epoch 798/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0723 - accuracy: 0.9706\n",
      "Epoch 799/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0749 - accuracy: 0.9698\n",
      "Epoch 800/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0722 - accuracy: 0.9744\n",
      "Epoch 801/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0819 - accuracy: 0.9704\n",
      "Epoch 802/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0714 - accuracy: 0.9722\n",
      "Epoch 803/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0700 - accuracy: 0.9716\n",
      "Epoch 804/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0690 - accuracy: 0.9748\n",
      "Epoch 805/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0707 - accuracy: 0.9688\n",
      "Epoch 806/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0694 - accuracy: 0.9716\n",
      "Epoch 807/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0741 - accuracy: 0.9704\n",
      "Epoch 808/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0707 - accuracy: 0.9720\n",
      "Epoch 809/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0799 - accuracy: 0.9682\n",
      "Epoch 810/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0782 - accuracy: 0.9708\n",
      "Epoch 811/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0790 - accuracy: 0.9726\n",
      "Epoch 812/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0780 - accuracy: 0.9678\n",
      "Epoch 813/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0803 - accuracy: 0.9690\n",
      "Epoch 814/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0647 - accuracy: 0.9736\n",
      "Epoch 815/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0661 - accuracy: 0.9740\n",
      "Epoch 816/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0806 - accuracy: 0.9684\n",
      "Epoch 817/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0680 - accuracy: 0.9734\n",
      "Epoch 818/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0730 - accuracy: 0.9716\n",
      "Epoch 819/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0674 - accuracy: 0.9728\n",
      "Epoch 820/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0632 - accuracy: 0.9752\n",
      "Epoch 821/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0618 - accuracy: 0.9754\n",
      "Epoch 822/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0780 - accuracy: 0.9702\n",
      "Epoch 823/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0734 - accuracy: 0.9708\n",
      "Epoch 824/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0687 - accuracy: 0.9716\n",
      "Epoch 825/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0748 - accuracy: 0.9716\n",
      "Epoch 826/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0658 - accuracy: 0.9714\n",
      "Epoch 827/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0706 - accuracy: 0.9706\n",
      "Epoch 828/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0733 - accuracy: 0.9694\n",
      "Epoch 829/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0690 - accuracy: 0.9736\n",
      "Epoch 830/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0788 - accuracy: 0.9736\n",
      "Epoch 831/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0722 - accuracy: 0.9728\n",
      "Epoch 832/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0662 - accuracy: 0.9724\n",
      "Epoch 833/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0643 - accuracy: 0.9750\n",
      "Epoch 834/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0733 - accuracy: 0.9698\n",
      "Epoch 835/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0773 - accuracy: 0.9706\n",
      "Epoch 836/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0774 - accuracy: 0.9694\n",
      "Epoch 837/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0821 - accuracy: 0.9676\n",
      "Epoch 838/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0737 - accuracy: 0.9714\n",
      "Epoch 839/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0777 - accuracy: 0.9688\n",
      "Epoch 840/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0904 - accuracy: 0.9690\n",
      "Epoch 841/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9716\n",
      "Epoch 842/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0685 - accuracy: 0.9740\n",
      "Epoch 843/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0710 - accuracy: 0.9704\n",
      "Epoch 844/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0673 - accuracy: 0.9722\n",
      "Epoch 845/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0688 - accuracy: 0.9738\n",
      "Epoch 846/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0659 - accuracy: 0.9752\n",
      "Epoch 847/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0733 - accuracy: 0.9752\n",
      "Epoch 848/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0693 - accuracy: 0.9716\n",
      "Epoch 849/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0776 - accuracy: 0.9690\n",
      "Epoch 850/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0715 - accuracy: 0.9704\n",
      "Epoch 851/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0681 - accuracy: 0.9718\n",
      "Epoch 852/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0777 - accuracy: 0.9706\n",
      "Epoch 853/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0697 - accuracy: 0.9724\n",
      "Epoch 854/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0641 - accuracy: 0.9754\n",
      "Epoch 855/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0722 - accuracy: 0.9728\n",
      "Epoch 856/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0747 - accuracy: 0.9684\n",
      "Epoch 857/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0689 - accuracy: 0.9712\n",
      "Epoch 858/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0698 - accuracy: 0.9716\n",
      "Epoch 859/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0641 - accuracy: 0.9732\n",
      "Epoch 860/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0653 - accuracy: 0.9732\n",
      "Epoch 861/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0631 - accuracy: 0.9752\n",
      "Epoch 862/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0596 - accuracy: 0.9760\n",
      "Epoch 863/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0657 - accuracy: 0.9742\n",
      "Epoch 864/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0764 - accuracy: 0.9710\n",
      "Epoch 865/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0718 - accuracy: 0.9718\n",
      "Epoch 866/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0676 - accuracy: 0.9734\n",
      "Epoch 867/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0842 - accuracy: 0.9678\n",
      "Epoch 868/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0700 - accuracy: 0.9714\n",
      "Epoch 869/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0651 - accuracy: 0.9738\n",
      "Epoch 870/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0687 - accuracy: 0.9732\n",
      "Epoch 871/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0732 - accuracy: 0.9706\n",
      "Epoch 872/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0616 - accuracy: 0.9740\n",
      "Epoch 873/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0715 - accuracy: 0.9694\n",
      "Epoch 874/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0803 - accuracy: 0.9646\n",
      "Epoch 875/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0715 - accuracy: 0.9712\n",
      "Epoch 876/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0660 - accuracy: 0.9742\n",
      "Epoch 877/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0697 - accuracy: 0.9708\n",
      "Epoch 878/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0611 - accuracy: 0.9744\n",
      "Epoch 879/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0749 - accuracy: 0.9698\n",
      "Epoch 880/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0762 - accuracy: 0.9668\n",
      "Epoch 881/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0619 - accuracy: 0.9774\n",
      "Epoch 882/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0762 - accuracy: 0.9718\n",
      "Epoch 883/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0701 - accuracy: 0.9714\n",
      "Epoch 884/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0704 - accuracy: 0.9744\n",
      "Epoch 885/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0656 - accuracy: 0.9740\n",
      "Epoch 886/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0637 - accuracy: 0.9742\n",
      "Epoch 887/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0683 - accuracy: 0.9734\n",
      "Epoch 888/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0687 - accuracy: 0.9732\n",
      "Epoch 889/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0701 - accuracy: 0.9716\n",
      "Epoch 890/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0689 - accuracy: 0.9718\n",
      "Epoch 891/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0673 - accuracy: 0.9728\n",
      "Epoch 892/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0688 - accuracy: 0.9706\n",
      "Epoch 893/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0705 - accuracy: 0.9718\n",
      "Epoch 894/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0731 - accuracy: 0.9714\n",
      "Epoch 895/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0716 - accuracy: 0.9732\n",
      "Epoch 896/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0761 - accuracy: 0.9706\n",
      "Epoch 897/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0766 - accuracy: 0.9708\n",
      "Epoch 898/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0677 - accuracy: 0.9724\n",
      "Epoch 899/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0616 - accuracy: 0.9734\n",
      "Epoch 900/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0616 - accuracy: 0.9756\n",
      "Epoch 901/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0701 - accuracy: 0.9716\n",
      "Epoch 902/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0640 - accuracy: 0.9746\n",
      "Epoch 903/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0667 - accuracy: 0.9740\n",
      "Epoch 904/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0660 - accuracy: 0.9732\n",
      "Epoch 905/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0725 - accuracy: 0.9706\n",
      "Epoch 906/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0701 - accuracy: 0.9744\n",
      "Epoch 907/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0715 - accuracy: 0.9724\n",
      "Epoch 908/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0720 - accuracy: 0.9756\n",
      "Epoch 909/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0644 - accuracy: 0.9732\n",
      "Epoch 910/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0736 - accuracy: 0.9696\n",
      "Epoch 911/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0717 - accuracy: 0.9710\n",
      "Epoch 912/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0668 - accuracy: 0.9738\n",
      "Epoch 913/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0770 - accuracy: 0.9682\n",
      "Epoch 914/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0680 - accuracy: 0.9732\n",
      "Epoch 915/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0633 - accuracy: 0.9754\n",
      "Epoch 916/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0663 - accuracy: 0.9750\n",
      "Epoch 917/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0659 - accuracy: 0.9720\n",
      "Epoch 918/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0751 - accuracy: 0.9730\n",
      "Epoch 919/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0647 - accuracy: 0.9764\n",
      "Epoch 920/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0678 - accuracy: 0.9736\n",
      "Epoch 921/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0696 - accuracy: 0.9736\n",
      "Epoch 922/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0664 - accuracy: 0.9730\n",
      "Epoch 923/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0663 - accuracy: 0.9742\n",
      "Epoch 924/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0765 - accuracy: 0.9704\n",
      "Epoch 925/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0792 - accuracy: 0.9706\n",
      "Epoch 926/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0724 - accuracy: 0.9696\n",
      "Epoch 927/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0719 - accuracy: 0.9724\n",
      "Epoch 928/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0705 - accuracy: 0.9718\n",
      "Epoch 929/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0639 - accuracy: 0.9744\n",
      "Epoch 930/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0668 - accuracy: 0.9732\n",
      "Epoch 931/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0637 - accuracy: 0.9752\n",
      "Epoch 932/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0643 - accuracy: 0.9742\n",
      "Epoch 933/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0748 - accuracy: 0.9706\n",
      "Epoch 934/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0816 - accuracy: 0.9682\n",
      "Epoch 935/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9712\n",
      "Epoch 936/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0695 - accuracy: 0.9728\n",
      "Epoch 937/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0628 - accuracy: 0.9732\n",
      "Epoch 938/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0715 - accuracy: 0.9718\n",
      "Epoch 939/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0713 - accuracy: 0.9728\n",
      "Epoch 940/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0795 - accuracy: 0.9682\n",
      "Epoch 941/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0725 - accuracy: 0.9706\n",
      "Epoch 942/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0682 - accuracy: 0.9740\n",
      "Epoch 943/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0731 - accuracy: 0.9700\n",
      "Epoch 944/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0718 - accuracy: 0.9718\n",
      "Epoch 945/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0704 - accuracy: 0.9726\n",
      "Epoch 946/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0646 - accuracy: 0.9754\n",
      "Epoch 947/1024\n",
      "4996/4996 [==============================] - 0s 71us/step - loss: 0.0652 - accuracy: 0.9766\n",
      "Epoch 948/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0741 - accuracy: 0.9724\n",
      "Epoch 949/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0640 - accuracy: 0.9742\n",
      "Epoch 950/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0635 - accuracy: 0.9752\n",
      "Epoch 951/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0630 - accuracy: 0.9746\n",
      "Epoch 952/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0784 - accuracy: 0.9678\n",
      "Epoch 953/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0893 - accuracy: 0.9694\n",
      "Epoch 954/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0770 - accuracy: 0.9698\n",
      "Epoch 955/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0736 - accuracy: 0.9716\n",
      "Epoch 956/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0612 - accuracy: 0.9770\n",
      "Epoch 957/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0777 - accuracy: 0.9694\n",
      "Epoch 958/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0662 - accuracy: 0.9740\n",
      "Epoch 959/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0657 - accuracy: 0.9716\n",
      "Epoch 960/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0746 - accuracy: 0.9698\n",
      "Epoch 961/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0718 - accuracy: 0.9720\n",
      "Epoch 962/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0726 - accuracy: 0.9716\n",
      "Epoch 963/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0638 - accuracy: 0.9728\n",
      "Epoch 964/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0717 - accuracy: 0.9722\n",
      "Epoch 965/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0671 - accuracy: 0.9732\n",
      "Epoch 966/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0717 - accuracy: 0.9740\n",
      "Epoch 967/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0727 - accuracy: 0.9696\n",
      "Epoch 968/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0719 - accuracy: 0.9722\n",
      "Epoch 969/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0686 - accuracy: 0.9730\n",
      "Epoch 970/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0752 - accuracy: 0.9720\n",
      "Epoch 971/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0749 - accuracy: 0.9742\n",
      "Epoch 972/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0656 - accuracy: 0.9742\n",
      "Epoch 973/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0640 - accuracy: 0.9750\n",
      "Epoch 974/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0612 - accuracy: 0.9748\n",
      "Epoch 975/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0641 - accuracy: 0.9740\n",
      "Epoch 976/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0676 - accuracy: 0.9756\n",
      "Epoch 977/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0641 - accuracy: 0.9742\n",
      "Epoch 978/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0624 - accuracy: 0.9762\n",
      "Epoch 979/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0741 - accuracy: 0.9704\n",
      "Epoch 980/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0680 - accuracy: 0.9706\n",
      "Epoch 981/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0653 - accuracy: 0.9750\n",
      "Epoch 982/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0610 - accuracy: 0.9758\n",
      "Epoch 983/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0599 - accuracy: 0.9742\n",
      "Epoch 984/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0645 - accuracy: 0.9732\n",
      "Epoch 985/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0651 - accuracy: 0.9750\n",
      "Epoch 986/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0804 - accuracy: 0.9668\n",
      "Epoch 987/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0656 - accuracy: 0.9766\n",
      "Epoch 988/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0771 - accuracy: 0.9678\n",
      "Epoch 989/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0755 - accuracy: 0.9706\n",
      "Epoch 990/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0674 - accuracy: 0.9734\n",
      "Epoch 991/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0676 - accuracy: 0.9742\n",
      "Epoch 992/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0687 - accuracy: 0.9726\n",
      "Epoch 993/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0659 - accuracy: 0.9738\n",
      "Epoch 994/1024\n",
      "4996/4996 [==============================] - 0s 70us/step - loss: 0.0690 - accuracy: 0.9732\n",
      "Epoch 995/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0668 - accuracy: 0.9732\n",
      "Epoch 996/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0678 - accuracy: 0.9728\n",
      "Epoch 997/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0690 - accuracy: 0.9726\n",
      "Epoch 998/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0663 - accuracy: 0.9728\n",
      "Epoch 999/1024\n",
      "4996/4996 [==============================] - 1s 285us/step - loss: 0.0661 - accuracy: 0.9732\n",
      "Epoch 1000/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0675 - accuracy: 0.9718\n",
      "Epoch 1001/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0700 - accuracy: 0.9734\n",
      "Epoch 1002/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0706 - accuracy: 0.9714\n",
      "Epoch 1003/1024\n",
      "4996/4996 [==============================] - 0s 65us/step - loss: 0.0646 - accuracy: 0.9734\n",
      "Epoch 1004/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0650 - accuracy: 0.9746\n",
      "Epoch 1005/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0587 - accuracy: 0.9774\n",
      "Epoch 1006/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0633 - accuracy: 0.9740\n",
      "Epoch 1007/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0684 - accuracy: 0.9708\n",
      "Epoch 1008/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0799 - accuracy: 0.9702\n",
      "Epoch 1009/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0731 - accuracy: 0.9726\n",
      "Epoch 1010/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0705 - accuracy: 0.9718\n",
      "Epoch 1011/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0707 - accuracy: 0.9730\n",
      "Epoch 1012/1024\n",
      "4996/4996 [==============================] - 0s 66us/step - loss: 0.0752 - accuracy: 0.9712\n",
      "Epoch 1013/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0594 - accuracy: 0.9758\n",
      "Epoch 1014/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0656 - accuracy: 0.9756\n",
      "Epoch 1015/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0671 - accuracy: 0.9740\n",
      "Epoch 1016/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0784 - accuracy: 0.9668\n",
      "Epoch 1017/1024\n",
      "4996/4996 [==============================] - 0s 69us/step - loss: 0.0664 - accuracy: 0.9726\n",
      "Epoch 1018/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0661 - accuracy: 0.9720\n",
      "Epoch 1019/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0668 - accuracy: 0.9732\n",
      "Epoch 1020/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0691 - accuracy: 0.9716\n",
      "Epoch 1021/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0708 - accuracy: 0.9730\n",
      "Epoch 1022/1024\n",
      "4996/4996 [==============================] - 0s 67us/step - loss: 0.0679 - accuracy: 0.9716\n",
      "Epoch 1023/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0698 - accuracy: 0.9710\n",
      "Epoch 1024/1024\n",
      "4996/4996 [==============================] - 0s 68us/step - loss: 0.0618 - accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(256, activation='relu', kernel_initializer='random_normal', input_dim=1600, ))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='Adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "history = classifier.fit(X_train,y_train, batch_size=32, epochs=1024, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('../Figures/FNN_Adam.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_19_input to have 2 dimensions, but got array with shape (4996, 40, 40, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-76aa21037bad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#Fitting the data to the training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_19_input to have 2 dimensions, but got array with shape (4996, 40, 40, 1)"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(256, activation='relu', kernel_initializer='random_normal', input_dim=1600, ))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(0.5))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer =optimizers.Adam(amsgrad=True),loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "history = classifier.fit(X_train,y_train, batch_size=32, epochs=1024, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('../Figures/FNN_Adam_AMSGrad.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-911a6cfffd11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../Figures/FNN_model_self.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='../Figures/FNN_model_self.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 426,833\n",
      "Trainable params: 426,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[540  87]\n",
      " [ 91 532]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, matthews_corrcoef\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "MCC = matthews_corrcoef(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate:14.240%\n",
      "Accuracy:85.760%\n",
      "Sensitivity:86.124%\n",
      "Specificity :85.393%\n",
      "Precision:85.578%\n",
      "False Positive Rate:14.607%\n",
      "Matthews Correlation Coefficient:71.521%\n",
      "F1 Score:85.668%\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate:\"+'{:.3%}'.format((cm[0,1]+cm[1,0])/np.sum(cm)))\n",
    "print(\"Accuracy:\"+'{:.3%}'.format((cm[0,0]+cm[1,1])/np.sum(cm)))\n",
    "print(\"Sensitivity:\"+'{:.3%}'.format((cm[0,0])/np.sum(cm[0,:])))\n",
    "print(\"Specificity :\"+'{:.3%}'.format((cm[1,1])/np.sum(cm[1,:])))\n",
    "print(\"Precision:\"+'{:.3%}'.format((cm[0,0])/np.sum(cm[:,0])))\n",
    "print(\"False Positive Rate:\"+'{:.3%}'.format(1-((cm[1,1])/np.sum(cm[1,:]))))\n",
    "print(\"Matthews Correlation Coefficient:\"+'{:.3%}'.format(MCC))\n",
    "print(\"F1 Score:\"+'{:.3%}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC(matrix):\n",
    "    '''\n",
    "    Calcualtes the Matthews Correlation Coefficient from a confusion matrix\n",
    "    '''\n",
    "    return ((matrix[0,0]*matrix[1,1])-(matrix[1,0]*matrix[0,1]))/np.sqrt((cm[0,0]+cm[1,0])*(cm[0,0]+cm[0,1])*(cm[1,1]+cm[1,0])*(cm[1,1]+cm[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3123\n"
     ]
    }
   ],
   "source": [
    "galaxy = np.zeros((40,40))\n",
    "for filepath in glob.iglob('../Data/cutouts/galaxyfits/*fits', recursive=True):\n",
    "    fp = Path(filepath)\n",
    "    hdulist = fits.open(fp)\n",
    "    scidata = hdulist[0].data\n",
    "    galaxy = np.dstack((galaxy,scidata))\n",
    "galaxy = galaxy[:,:,1:]\n",
    "print(galaxy.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 3123)\n"
     ]
    }
   ],
   "source": [
    "star = np.zeros((40,40))\n",
    "count = 0\n",
    "for filepath in glob.iglob('../Data/cutouts/starfits/*fits', recursive=True):\n",
    "    fp = Path(filepath)\n",
    "    hdulist = fits.open(fp)\n",
    "    scidata = hdulist[0].data\n",
    "    scidata = scidata\n",
    "    star = np.dstack((star,scidata))\n",
    "    count += 1\n",
    "    if count == galaxy.shape[2]:\n",
    "        break\n",
    "star = star[:,:,1:]\n",
    "print(star.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 6246)\n"
     ]
    }
   ],
   "source": [
    "X = np.dstack((galaxy,star))\n",
    "y = np.dstack((np.ones((1,1,galaxy.shape[2])),np.zeros((1,1,galaxy.shape[2]))))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.moveaxis(X, -1, 0)\n",
    "y = np.moveaxis(y, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6246, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train),40,40,1)\n",
    "X_test = X_test.reshape(len(X_test),40,40,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4996/4996 [==============================] - 9s 2ms/step - loss: 43.7648 - accuracy: 0.6789\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(16, kernel_size=5, activation='relu', input_shape=(40,40,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='random_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "model.compile(optimizer =optimizers.Adam(amsgrad=True),loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "history = model.fit(X_train,y_train, batch_size=32, epochs=1, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('../Figures/CNN_self.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 46us/step\n",
      "[[583  54]\n",
      " [ 49 564]]\n"
     ]
    }
   ],
   "source": [
    "eval_model=model.evaluate(X_train, y_train)\n",
    "eval_model\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred =(y_pred>0.5)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "MCC = matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate:8.240%\n",
      "Accuracy:91.760%\n",
      "Sensitivity:91.523%\n",
      "Specificity :92.007%\n",
      "Precision:92.247%\n",
      "False Positive Rate:7.993%\n",
      "Matthews Correlation Coefficient:83.519%\n",
      "F1:91.633%\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate:\"+'{:.3%}'.format((cm[0,1]+cm[1,0])/np.sum(cm)))\n",
    "print(\"Accuracy:\"+'{:.3%}'.format((cm[0,0]+cm[1,1])/np.sum(cm)))\n",
    "print(\"Sensitivity:\"+'{:.3%}'.format((cm[0,0])/np.sum(cm[0,:])))\n",
    "print(\"Specificity :\"+'{:.3%}'.format((cm[1,1])/np.sum(cm[1,:])))\n",
    "print(\"Precision:\"+'{:.3%}'.format((cm[0,0])/np.sum(cm[:,0])))\n",
    "print(\"False Positive Rate:\"+'{:.3%}'.format(1-((cm[1,1])/np.sum(cm[1,:]))))\n",
    "print(\"Matthews Correlation Coefficient:\"+'{:.3%}'.format(MCC))\n",
    "print(\"F1:\"+'{:.3%}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='../Figures/CNN_model_self.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "4996/4996 [==============================] - 1s 229us/step - loss: 9.3859 - accuracy: 0.6121\n",
      "Epoch 2/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.6424 - accuracy: 0.6723\n",
      "Epoch 3/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.5741 - accuracy: 0.7292\n",
      "Epoch 4/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.4816 - accuracy: 0.7902\n",
      "Epoch 5/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.4242 - accuracy: 0.8267\n",
      "Epoch 6/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.3910 - accuracy: 0.8375\n",
      "Epoch 7/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.4162 - accuracy: 0.8261\n",
      "Epoch 8/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.3834 - accuracy: 0.8351\n",
      "Epoch 9/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.3634 - accuracy: 0.8513\n",
      "Epoch 10/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.3482 - accuracy: 0.8583\n",
      "Epoch 11/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.3656 - accuracy: 0.8485\n",
      "Epoch 12/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.3530 - accuracy: 0.8539\n",
      "Epoch 13/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.3221 - accuracy: 0.8741\n",
      "Epoch 14/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.3147 - accuracy: 0.8771\n",
      "Epoch 15/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.3094 - accuracy: 0.8793\n",
      "Epoch 16/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.3042 - accuracy: 0.8815\n",
      "Epoch 17/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2825 - accuracy: 0.8919\n",
      "Epoch 18/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.3101 - accuracy: 0.8755\n",
      "Epoch 19/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2924 - accuracy: 0.8875\n",
      "Epoch 20/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2815 - accuracy: 0.8931\n",
      "Epoch 21/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2915 - accuracy: 0.8781\n",
      "Epoch 22/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2910 - accuracy: 0.8867\n",
      "Epoch 23/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2567 - accuracy: 0.9009\n",
      "Epoch 24/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2597 - accuracy: 0.9053\n",
      "Epoch 25/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2520 - accuracy: 0.9071\n",
      "Epoch 26/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2646 - accuracy: 0.8991\n",
      "Epoch 27/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2509 - accuracy: 0.9029\n",
      "Epoch 28/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2462 - accuracy: 0.9115\n",
      "Epoch 29/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2626 - accuracy: 0.8955\n",
      "Epoch 30/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2423 - accuracy: 0.9083\n",
      "Epoch 31/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2438 - accuracy: 0.9079\n",
      "Epoch 32/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.2258 - accuracy: 0.9161\n",
      "Epoch 33/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2215 - accuracy: 0.9207\n",
      "Epoch 34/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.2268 - accuracy: 0.9179\n",
      "Epoch 35/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.2289 - accuracy: 0.9115\n",
      "Epoch 36/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.2125 - accuracy: 0.9205\n",
      "Epoch 37/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.2038 - accuracy: 0.9269\n",
      "Epoch 38/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1995 - accuracy: 0.9265\n",
      "Epoch 39/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2106 - accuracy: 0.9189\n",
      "Epoch 40/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2074 - accuracy: 0.9243\n",
      "Epoch 41/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.2018 - accuracy: 0.9273\n",
      "Epoch 42/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1996 - accuracy: 0.9247\n",
      "Epoch 43/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1835 - accuracy: 0.9319\n",
      "Epoch 44/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1880 - accuracy: 0.9321\n",
      "Epoch 45/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.1962 - accuracy: 0.9293\n",
      "Epoch 46/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1879 - accuracy: 0.9309\n",
      "Epoch 47/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1829 - accuracy: 0.9343\n",
      "Epoch 48/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1857 - accuracy: 0.9317\n",
      "Epoch 49/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1865 - accuracy: 0.9329\n",
      "Epoch 50/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1897 - accuracy: 0.9309\n",
      "Epoch 51/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1908 - accuracy: 0.9297\n",
      "Epoch 52/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1863 - accuracy: 0.9319\n",
      "Epoch 53/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1702 - accuracy: 0.9382\n",
      "Epoch 54/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1665 - accuracy: 0.9400\n",
      "Epoch 55/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1724 - accuracy: 0.9357\n",
      "Epoch 56/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1922 - accuracy: 0.9299\n",
      "Epoch 57/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1714 - accuracy: 0.9373\n",
      "Epoch 58/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.1870 - accuracy: 0.9315\n",
      "Epoch 59/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1924 - accuracy: 0.9275\n",
      "Epoch 60/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1673 - accuracy: 0.9345\n",
      "Epoch 61/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1753 - accuracy: 0.9382\n",
      "Epoch 62/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1694 - accuracy: 0.9402\n",
      "Epoch 63/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.1603 - accuracy: 0.9412\n",
      "Epoch 64/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1638 - accuracy: 0.9390\n",
      "Epoch 65/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.1665 - accuracy: 0.9367\n",
      "Epoch 66/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1642 - accuracy: 0.9416\n",
      "Epoch 67/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.1568 - accuracy: 0.9434\n",
      "Epoch 68/1024\n",
      "4996/4996 [==============================] - 1s 168us/step - loss: 0.1886 - accuracy: 0.9327\n",
      "Epoch 69/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1687 - accuracy: 0.9373\n",
      "Epoch 70/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.1657 - accuracy: 0.9378\n",
      "Epoch 71/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.1527 - accuracy: 0.9448\n",
      "Epoch 72/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.1780 - accuracy: 0.9361\n",
      "Epoch 73/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.1652 - accuracy: 0.9382\n",
      "Epoch 74/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1831 - accuracy: 0.9325\n",
      "Epoch 75/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.1749 - accuracy: 0.9343\n",
      "Epoch 76/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.1612 - accuracy: 0.9408\n",
      "Epoch 77/1024\n",
      "4996/4996 [==============================] - 1s 168us/step - loss: 0.1515 - accuracy: 0.9438\n",
      "Epoch 78/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1563 - accuracy: 0.9418\n",
      "Epoch 79/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.1510 - accuracy: 0.9438\n",
      "Epoch 80/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1490 - accuracy: 0.9488\n",
      "Epoch 81/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.1408 - accuracy: 0.9472\n",
      "Epoch 82/1024\n",
      "4996/4996 [==============================] - 1s 213us/step - loss: 0.1383 - accuracy: 0.9500\n",
      "Epoch 83/1024\n",
      "4996/4996 [==============================] - 1s 220us/step - loss: 0.1382 - accuracy: 0.9468\n",
      "Epoch 84/1024\n",
      "4996/4996 [==============================] - 1s 218us/step - loss: 0.1366 - accuracy: 0.9478\n",
      "Epoch 85/1024\n",
      "4996/4996 [==============================] - 1s 219us/step - loss: 0.1593 - accuracy: 0.9400\n",
      "Epoch 86/1024\n",
      "4996/4996 [==============================] - 1s 218us/step - loss: 0.1396 - accuracy: 0.9468\n",
      "Epoch 87/1024\n",
      "4996/4996 [==============================] - 1s 221us/step - loss: 0.1460 - accuracy: 0.9422\n",
      "Epoch 88/1024\n",
      "4996/4996 [==============================] - 1s 206us/step - loss: 0.1412 - accuracy: 0.9462\n",
      "Epoch 89/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.1360 - accuracy: 0.9484\n",
      "Epoch 90/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1328 - accuracy: 0.9496\n",
      "Epoch 91/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1535 - accuracy: 0.9448\n",
      "Epoch 92/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.1325 - accuracy: 0.9502\n",
      "Epoch 93/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1358 - accuracy: 0.9474\n",
      "Epoch 94/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1283 - accuracy: 0.9510\n",
      "Epoch 95/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.1287 - accuracy: 0.9536\n",
      "Epoch 96/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1309 - accuracy: 0.9508\n",
      "Epoch 97/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.1276 - accuracy: 0.9492\n",
      "Epoch 98/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1503 - accuracy: 0.9442\n",
      "Epoch 99/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1334 - accuracy: 0.9492\n",
      "Epoch 100/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.1345 - accuracy: 0.9520\n",
      "Epoch 101/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.1241 - accuracy: 0.9508\n",
      "Epoch 102/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1286 - accuracy: 0.9508\n",
      "Epoch 103/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.1284 - accuracy: 0.9494\n",
      "Epoch 104/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1225 - accuracy: 0.9540\n",
      "Epoch 105/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1209 - accuracy: 0.9540\n",
      "Epoch 106/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.1243 - accuracy: 0.9530\n",
      "Epoch 107/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.1237 - accuracy: 0.9492\n",
      "Epoch 108/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1290 - accuracy: 0.9536\n",
      "Epoch 109/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1307 - accuracy: 0.9536\n",
      "Epoch 110/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.1307 - accuracy: 0.9508\n",
      "Epoch 111/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1277 - accuracy: 0.9508\n",
      "Epoch 112/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.1187 - accuracy: 0.9534\n",
      "Epoch 113/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.1132 - accuracy: 0.9580\n",
      "Epoch 114/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.1270 - accuracy: 0.9520\n",
      "Epoch 115/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.1194 - accuracy: 0.9554\n",
      "Epoch 116/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1160 - accuracy: 0.9546\n",
      "Epoch 117/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1068 - accuracy: 0.9576\n",
      "Epoch 118/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.1117 - accuracy: 0.9560\n",
      "Epoch 119/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.1198 - accuracy: 0.9544\n",
      "Epoch 120/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1163 - accuracy: 0.9566\n",
      "Epoch 121/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1056 - accuracy: 0.9574\n",
      "Epoch 122/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.1107 - accuracy: 0.9574\n",
      "Epoch 123/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1069 - accuracy: 0.9562\n",
      "Epoch 124/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0997 - accuracy: 0.9614\n",
      "Epoch 125/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.1046 - accuracy: 0.9582\n",
      "Epoch 126/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.1049 - accuracy: 0.9584\n",
      "Epoch 127/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1067 - accuracy: 0.9622\n",
      "Epoch 128/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.1004 - accuracy: 0.9602\n",
      "Epoch 129/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1037 - accuracy: 0.9614\n",
      "Epoch 130/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0999 - accuracy: 0.9598\n",
      "Epoch 131/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.1118 - accuracy: 0.9602\n",
      "Epoch 132/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1065 - accuracy: 0.9606\n",
      "Epoch 133/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1016 - accuracy: 0.9598\n",
      "Epoch 134/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1054 - accuracy: 0.9604\n",
      "Epoch 135/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1117 - accuracy: 0.9578\n",
      "Epoch 136/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1074 - accuracy: 0.9604\n",
      "Epoch 137/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.1344 - accuracy: 0.9498\n",
      "Epoch 138/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1062 - accuracy: 0.9594\n",
      "Epoch 139/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.1100 - accuracy: 0.9570\n",
      "Epoch 140/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0968 - accuracy: 0.9626\n",
      "Epoch 141/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1048 - accuracy: 0.9606\n",
      "Epoch 142/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0970 - accuracy: 0.9604\n",
      "Epoch 143/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.1046 - accuracy: 0.9600\n",
      "Epoch 144/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1117 - accuracy: 0.9592\n",
      "Epoch 145/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.1028 - accuracy: 0.9602\n",
      "Epoch 146/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0980 - accuracy: 0.9612\n",
      "Epoch 147/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0980 - accuracy: 0.9626\n",
      "Epoch 148/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0911 - accuracy: 0.9660\n",
      "Epoch 149/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1176 - accuracy: 0.9588\n",
      "Epoch 150/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.1106 - accuracy: 0.9558\n",
      "Epoch 151/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0929 - accuracy: 0.9640\n",
      "Epoch 152/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0911 - accuracy: 0.9654\n",
      "Epoch 153/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0854 - accuracy: 0.9644\n",
      "Epoch 154/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0931 - accuracy: 0.9676\n",
      "Epoch 155/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0855 - accuracy: 0.9648\n",
      "Epoch 156/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0837 - accuracy: 0.9684\n",
      "Epoch 157/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0874 - accuracy: 0.9650\n",
      "Epoch 158/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0884 - accuracy: 0.9664\n",
      "Epoch 159/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0967 - accuracy: 0.9612\n",
      "Epoch 160/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0895 - accuracy: 0.9630\n",
      "Epoch 161/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0900 - accuracy: 0.9622\n",
      "Epoch 162/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0835 - accuracy: 0.9672\n",
      "Epoch 163/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0823 - accuracy: 0.9672\n",
      "Epoch 164/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0854 - accuracy: 0.9636\n",
      "Epoch 165/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0810 - accuracy: 0.9702\n",
      "Epoch 166/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.1022 - accuracy: 0.9620\n",
      "Epoch 167/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0901 - accuracy: 0.9662\n",
      "Epoch 168/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0863 - accuracy: 0.9648\n",
      "Epoch 169/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0849 - accuracy: 0.9658\n",
      "Epoch 170/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0781 - accuracy: 0.9676\n",
      "Epoch 171/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1054 - accuracy: 0.9612\n",
      "Epoch 172/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0954 - accuracy: 0.9644\n",
      "Epoch 173/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0755 - accuracy: 0.9694\n",
      "Epoch 174/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0828 - accuracy: 0.9654\n",
      "Epoch 175/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0763 - accuracy: 0.9690\n",
      "Epoch 176/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0702 - accuracy: 0.9724\n",
      "Epoch 177/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0775 - accuracy: 0.9690\n",
      "Epoch 178/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0741 - accuracy: 0.9692\n",
      "Epoch 179/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0746 - accuracy: 0.9686\n",
      "Epoch 180/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0806 - accuracy: 0.9652\n",
      "Epoch 181/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0684 - accuracy: 0.9744\n",
      "Epoch 182/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0789 - accuracy: 0.9696\n",
      "Epoch 183/1024\n",
      "4996/4996 [==============================] - 1s 168us/step - loss: 0.0763 - accuracy: 0.9680\n",
      "Epoch 184/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0740 - accuracy: 0.9716\n",
      "Epoch 185/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0702 - accuracy: 0.9712\n",
      "Epoch 186/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0731 - accuracy: 0.9702\n",
      "Epoch 187/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0728 - accuracy: 0.9726\n",
      "Epoch 188/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0675 - accuracy: 0.9716\n",
      "Epoch 189/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0748 - accuracy: 0.9706\n",
      "Epoch 190/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0945 - accuracy: 0.9652\n",
      "Epoch 191/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0835 - accuracy: 0.9668\n",
      "Epoch 192/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0821 - accuracy: 0.9656\n",
      "Epoch 193/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0687 - accuracy: 0.9724\n",
      "Epoch 194/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0761 - accuracy: 0.9704\n",
      "Epoch 195/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0761 - accuracy: 0.9684\n",
      "Epoch 196/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0805 - accuracy: 0.9712\n",
      "Epoch 197/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0850 - accuracy: 0.9680\n",
      "Epoch 198/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0699 - accuracy: 0.9718\n",
      "Epoch 199/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0773 - accuracy: 0.9662\n",
      "Epoch 200/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0778 - accuracy: 0.9704\n",
      "Epoch 201/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0764 - accuracy: 0.9694\n",
      "Epoch 202/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0681 - accuracy: 0.9716\n",
      "Epoch 203/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0635 - accuracy: 0.9726\n",
      "Epoch 204/1024\n",
      "4996/4996 [==============================] - 1s 168us/step - loss: 0.0667 - accuracy: 0.9714\n",
      "Epoch 205/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0655 - accuracy: 0.9718\n",
      "Epoch 206/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0653 - accuracy: 0.9738\n",
      "Epoch 207/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0732 - accuracy: 0.9688\n",
      "Epoch 208/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0723 - accuracy: 0.9680\n",
      "Epoch 209/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0705 - accuracy: 0.9708\n",
      "Epoch 210/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0696 - accuracy: 0.9730\n",
      "Epoch 211/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0677 - accuracy: 0.9716\n",
      "Epoch 212/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0733 - accuracy: 0.9700\n",
      "Epoch 213/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0578 - accuracy: 0.9748\n",
      "Epoch 214/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0635 - accuracy: 0.9748\n",
      "Epoch 215/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0653 - accuracy: 0.9726\n",
      "Epoch 216/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0578 - accuracy: 0.9742\n",
      "Epoch 217/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0572 - accuracy: 0.9748\n",
      "Epoch 218/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0586 - accuracy: 0.9752\n",
      "Epoch 219/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0595 - accuracy: 0.9722\n",
      "Epoch 220/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0599 - accuracy: 0.9748\n",
      "Epoch 221/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0580 - accuracy: 0.9764\n",
      "Epoch 222/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0561 - accuracy: 0.9758\n",
      "Epoch 223/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0584 - accuracy: 0.9748\n",
      "Epoch 224/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0619 - accuracy: 0.9748\n",
      "Epoch 225/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0525 - accuracy: 0.9778\n",
      "Epoch 226/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0561 - accuracy: 0.9780\n",
      "Epoch 227/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0507 - accuracy: 0.9772\n",
      "Epoch 228/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0568 - accuracy: 0.9730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0646 - accuracy: 0.9738\n",
      "Epoch 230/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0733 - accuracy: 0.9698\n",
      "Epoch 231/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0623 - accuracy: 0.9720\n",
      "Epoch 232/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0621 - accuracy: 0.9716\n",
      "Epoch 233/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0604 - accuracy: 0.9738\n",
      "Epoch 234/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0662 - accuracy: 0.9710\n",
      "Epoch 235/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0601 - accuracy: 0.9760\n",
      "Epoch 236/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0643 - accuracy: 0.9732\n",
      "Epoch 237/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0655 - accuracy: 0.9740\n",
      "Epoch 238/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0686 - accuracy: 0.9738\n",
      "Epoch 239/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0564 - accuracy: 0.9748\n",
      "Epoch 240/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0607 - accuracy: 0.9754\n",
      "Epoch 241/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0707 - accuracy: 0.9712\n",
      "Epoch 242/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0638 - accuracy: 0.9748\n",
      "Epoch 243/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0589 - accuracy: 0.9750\n",
      "Epoch 244/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0574 - accuracy: 0.9762\n",
      "Epoch 245/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0627 - accuracy: 0.9750\n",
      "Epoch 246/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 247/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0552 - accuracy: 0.9756\n",
      "Epoch 248/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0520 - accuracy: 0.9772\n",
      "Epoch 249/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0587 - accuracy: 0.9744\n",
      "Epoch 250/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0566 - accuracy: 0.9772\n",
      "Epoch 251/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0568 - accuracy: 0.9750\n",
      "Epoch 252/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0563 - accuracy: 0.9754\n",
      "Epoch 253/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0601 - accuracy: 0.9752\n",
      "Epoch 254/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0611 - accuracy: 0.9710\n",
      "Epoch 255/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0512 - accuracy: 0.9800\n",
      "Epoch 256/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0543 - accuracy: 0.9762\n",
      "Epoch 257/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0536 - accuracy: 0.9768\n",
      "Epoch 258/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0592 - accuracy: 0.9736\n",
      "Epoch 259/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0744 - accuracy: 0.9706\n",
      "Epoch 260/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0627 - accuracy: 0.9732\n",
      "Epoch 261/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0626 - accuracy: 0.9722\n",
      "Epoch 262/1024\n",
      "4996/4996 [==============================] - 1s 171us/step - loss: 0.0486 - accuracy: 0.9768\n",
      "Epoch 263/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0626 - accuracy: 0.9722\n",
      "Epoch 264/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0616 - accuracy: 0.9730\n",
      "Epoch 265/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0598 - accuracy: 0.9722\n",
      "Epoch 266/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0567 - accuracy: 0.9744\n",
      "Epoch 267/1024\n",
      "4996/4996 [==============================] - 1s 169us/step - loss: 0.0559 - accuracy: 0.9744\n",
      "Epoch 268/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0698 - accuracy: 0.9700\n",
      "Epoch 269/1024\n",
      "4996/4996 [==============================] - 1s 170us/step - loss: 0.0649 - accuracy: 0.9738\n",
      "Epoch 270/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0678 - accuracy: 0.9708\n",
      "Epoch 271/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0610 - accuracy: 0.9754\n",
      "Epoch 272/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0573 - accuracy: 0.9740\n",
      "Epoch 273/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0562 - accuracy: 0.9754\n",
      "Epoch 274/1024\n",
      "4996/4996 [==============================] - 1s 199us/step - loss: 0.0584 - accuracy: 0.9738\n",
      "Epoch 275/1024\n",
      "4996/4996 [==============================] - 1s 187us/step - loss: 0.0662 - accuracy: 0.9724\n",
      "Epoch 276/1024\n",
      "4996/4996 [==============================] - 1s 194us/step - loss: 0.0549 - accuracy: 0.9762\n",
      "Epoch 277/1024\n",
      "4996/4996 [==============================] - 1s 189us/step - loss: 0.0561 - accuracy: 0.9744\n",
      "Epoch 278/1024\n",
      "4996/4996 [==============================] - 1s 190us/step - loss: 0.0598 - accuracy: 0.9734\n",
      "Epoch 279/1024\n",
      "4996/4996 [==============================] - 1s 194us/step - loss: 0.0563 - accuracy: 0.9752\n",
      "Epoch 280/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0559 - accuracy: 0.9770\n",
      "Epoch 281/1024\n",
      "4996/4996 [==============================] - 1s 187us/step - loss: 0.0545 - accuracy: 0.9760\n",
      "Epoch 282/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0499 - accuracy: 0.9782\n",
      "Epoch 283/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0518 - accuracy: 0.9772\n",
      "Epoch 284/1024\n",
      "4996/4996 [==============================] - 1s 192us/step - loss: 0.0544 - accuracy: 0.9790\n",
      "Epoch 285/1024\n",
      "4996/4996 [==============================] - 1s 197us/step - loss: 0.0526 - accuracy: 0.9740\n",
      "Epoch 286/1024\n",
      "4996/4996 [==============================] - 1s 194us/step - loss: 0.0480 - accuracy: 0.9760\n",
      "Epoch 287/1024\n",
      "4996/4996 [==============================] - 1s 189us/step - loss: 0.0478 - accuracy: 0.9802\n",
      "Epoch 288/1024\n",
      "4996/4996 [==============================] - 1s 197us/step - loss: 0.0470 - accuracy: 0.9786\n",
      "Epoch 289/1024\n",
      "4996/4996 [==============================] - 1s 198us/step - loss: 0.0537 - accuracy: 0.9776\n",
      "Epoch 290/1024\n",
      "4996/4996 [==============================] - 1s 193us/step - loss: 0.0462 - accuracy: 0.9774\n",
      "Epoch 291/1024\n",
      "4996/4996 [==============================] - 1s 191us/step - loss: 0.0458 - accuracy: 0.9784\n",
      "Epoch 292/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0555 - accuracy: 0.9788\n",
      "Epoch 293/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0481 - accuracy: 0.9768\n",
      "Epoch 294/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0462 - accuracy: 0.9772\n",
      "Epoch 295/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0477 - accuracy: 0.9802\n",
      "Epoch 296/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0451 - accuracy: 0.9804\n",
      "Epoch 297/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0474 - accuracy: 0.9794\n",
      "Epoch 298/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0415 - accuracy: 0.9798\n",
      "Epoch 299/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0508 - accuracy: 0.9794\n",
      "Epoch 300/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0491 - accuracy: 0.9778\n",
      "Epoch 301/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0443 - accuracy: 0.9800\n",
      "Epoch 302/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0469 - accuracy: 0.9792\n",
      "Epoch 303/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0498 - accuracy: 0.9776\n",
      "Epoch 304/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0610 - accuracy: 0.9778\n",
      "Epoch 305/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0524 - accuracy: 0.9774\n",
      "Epoch 306/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0487 - accuracy: 0.9778\n",
      "Epoch 307/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0448 - accuracy: 0.9778\n",
      "Epoch 308/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0439 - accuracy: 0.9778\n",
      "Epoch 309/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0496 - accuracy: 0.9774\n",
      "Epoch 310/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0439 - accuracy: 0.9776\n",
      "Epoch 311/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0456 - accuracy: 0.9796\n",
      "Epoch 312/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0450 - accuracy: 0.9796\n",
      "Epoch 313/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0419 - accuracy: 0.9804\n",
      "Epoch 314/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0429 - accuracy: 0.9810\n",
      "Epoch 315/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0528 - accuracy: 0.9780\n",
      "Epoch 316/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0471 - accuracy: 0.9790\n",
      "Epoch 317/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0493 - accuracy: 0.9772\n",
      "Epoch 318/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0442 - accuracy: 0.9808\n",
      "Epoch 319/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0430 - accuracy: 0.9796\n",
      "Epoch 320/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0496 - accuracy: 0.9790\n",
      "Epoch 321/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0540 - accuracy: 0.9780\n",
      "Epoch 322/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0432 - accuracy: 0.9816\n",
      "Epoch 323/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0463 - accuracy: 0.9774\n",
      "Epoch 324/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0602 - accuracy: 0.9778\n",
      "Epoch 325/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.1324 - accuracy: 0.9534\n",
      "Epoch 326/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0809 - accuracy: 0.9696\n",
      "Epoch 327/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0600 - accuracy: 0.9738\n",
      "Epoch 328/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0472 - accuracy: 0.9786\n",
      "Epoch 329/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0463 - accuracy: 0.9800\n",
      "Epoch 330/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0471 - accuracy: 0.9786\n",
      "Epoch 331/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0491 - accuracy: 0.9774\n",
      "Epoch 332/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0419 - accuracy: 0.9822\n",
      "Epoch 333/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0423 - accuracy: 0.9800\n",
      "Epoch 334/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0442 - accuracy: 0.9812\n",
      "Epoch 335/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0467 - accuracy: 0.9774\n",
      "Epoch 336/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0420 - accuracy: 0.9818\n",
      "Epoch 337/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0421 - accuracy: 0.9792\n",
      "Epoch 338/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0368 - accuracy: 0.9820\n",
      "Epoch 339/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0412 - accuracy: 0.9796\n",
      "Epoch 340/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0466 - accuracy: 0.9772\n",
      "Epoch 341/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0466 - accuracy: 0.9768\n",
      "Epoch 342/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0490 - accuracy: 0.9780\n",
      "Epoch 343/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0393 - accuracy: 0.9802\n",
      "Epoch 344/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0388 - accuracy: 0.9810\n",
      "Epoch 345/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0420 - accuracy: 0.9816\n",
      "Epoch 346/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0380 - accuracy: 0.9826\n",
      "Epoch 347/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0407 - accuracy: 0.9810\n",
      "Epoch 348/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0454 - accuracy: 0.9786\n",
      "Epoch 349/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0433 - accuracy: 0.9814\n",
      "Epoch 350/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0532 - accuracy: 0.9762\n",
      "Epoch 351/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0439 - accuracy: 0.9798\n",
      "Epoch 352/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0387 - accuracy: 0.9794\n",
      "Epoch 353/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0409 - accuracy: 0.9810\n",
      "Epoch 354/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0468 - accuracy: 0.9804\n",
      "Epoch 355/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0443 - accuracy: 0.9780\n",
      "Epoch 356/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0368 - accuracy: 0.9844\n",
      "Epoch 357/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0452 - accuracy: 0.9800\n",
      "Epoch 358/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0531 - accuracy: 0.9770\n",
      "Epoch 359/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0457 - accuracy: 0.9808\n",
      "Epoch 360/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0418 - accuracy: 0.9790\n",
      "Epoch 361/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0408 - accuracy: 0.9822\n",
      "Epoch 362/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0628 - accuracy: 0.9734\n",
      "Epoch 363/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0415 - accuracy: 0.9790\n",
      "Epoch 364/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0439 - accuracy: 0.9772\n",
      "Epoch 365/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0410 - accuracy: 0.9812\n",
      "Epoch 366/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0367 - accuracy: 0.9852\n",
      "Epoch 367/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0408 - accuracy: 0.9810\n",
      "Epoch 368/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0415 - accuracy: 0.9808\n",
      "Epoch 369/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0439 - accuracy: 0.9792\n",
      "Epoch 370/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0441 - accuracy: 0.9788\n",
      "Epoch 371/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0444 - accuracy: 0.9794\n",
      "Epoch 372/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0430 - accuracy: 0.9796\n",
      "Epoch 373/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0396 - accuracy: 0.9818\n",
      "Epoch 374/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0434 - accuracy: 0.9776\n",
      "Epoch 375/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0466 - accuracy: 0.9800\n",
      "Epoch 376/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0391 - accuracy: 0.9830\n",
      "Epoch 377/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0437 - accuracy: 0.9806\n",
      "Epoch 378/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0429 - accuracy: 0.9812\n",
      "Epoch 379/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0433 - accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0414 - accuracy: 0.9844\n",
      "Epoch 381/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0359 - accuracy: 0.9826\n",
      "Epoch 382/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0384 - accuracy: 0.9812\n",
      "Epoch 383/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0364 - accuracy: 0.9822\n",
      "Epoch 384/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0379 - accuracy: 0.9828\n",
      "Epoch 385/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0355 - accuracy: 0.9830\n",
      "Epoch 386/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0372 - accuracy: 0.9830\n",
      "Epoch 387/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0393 - accuracy: 0.9800\n",
      "Epoch 388/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0298 - accuracy: 0.9848\n",
      "Epoch 389/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0334 - accuracy: 0.9834\n",
      "Epoch 390/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0338 - accuracy: 0.9828\n",
      "Epoch 391/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0316 - accuracy: 0.9862\n",
      "Epoch 392/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0352 - accuracy: 0.9828\n",
      "Epoch 393/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0368 - accuracy: 0.9830\n",
      "Epoch 394/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0373 - accuracy: 0.9816\n",
      "Epoch 395/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0403 - accuracy: 0.9818\n",
      "Epoch 396/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0340 - accuracy: 0.9844\n",
      "Epoch 397/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0405 - accuracy: 0.9814\n",
      "Epoch 398/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0314 - accuracy: 0.9848\n",
      "Epoch 399/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0412 - accuracy: 0.9828\n",
      "Epoch 400/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0365 - accuracy: 0.9830\n",
      "Epoch 401/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0315 - accuracy: 0.9842\n",
      "Epoch 402/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0298 - accuracy: 0.9830\n",
      "Epoch 403/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0323 - accuracy: 0.9834\n",
      "Epoch 404/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0333 - accuracy: 0.9836\n",
      "Epoch 405/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0366 - accuracy: 0.9810\n",
      "Epoch 406/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0322 - accuracy: 0.9858\n",
      "Epoch 407/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0472 - accuracy: 0.9776\n",
      "Epoch 408/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0432 - accuracy: 0.9806\n",
      "Epoch 409/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0406 - accuracy: 0.9808\n",
      "Epoch 410/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0411 - accuracy: 0.9842\n",
      "Epoch 411/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0302 - accuracy: 0.9858\n",
      "Epoch 412/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0398 - accuracy: 0.9830\n",
      "Epoch 413/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0384 - accuracy: 0.9824\n",
      "Epoch 414/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0332 - accuracy: 0.9846\n",
      "Epoch 415/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0306 - accuracy: 0.9856\n",
      "Epoch 416/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0350 - accuracy: 0.9834\n",
      "Epoch 417/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0323 - accuracy: 0.9840\n",
      "Epoch 418/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0336 - accuracy: 0.9824\n",
      "Epoch 419/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0356 - accuracy: 0.9842\n",
      "Epoch 420/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0357 - accuracy: 0.9830\n",
      "Epoch 421/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0380 - accuracy: 0.9834\n",
      "Epoch 422/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0375 - accuracy: 0.9848\n",
      "Epoch 423/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0292 - accuracy: 0.9862\n",
      "Epoch 424/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0329 - accuracy: 0.9836\n",
      "Epoch 425/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0290 - accuracy: 0.9852\n",
      "Epoch 426/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0282 - accuracy: 0.9866\n",
      "Epoch 427/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0312 - accuracy: 0.9842\n",
      "Epoch 428/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0405 - accuracy: 0.9812\n",
      "Epoch 429/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0354 - accuracy: 0.9836\n",
      "Epoch 430/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0351 - accuracy: 0.9834\n",
      "Epoch 431/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0345 - accuracy: 0.9834\n",
      "Epoch 432/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0409 - accuracy: 0.9810\n",
      "Epoch 433/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0353 - accuracy: 0.9810\n",
      "Epoch 434/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0360 - accuracy: 0.9822\n",
      "Epoch 435/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0335 - accuracy: 0.9846\n",
      "Epoch 436/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0297 - accuracy: 0.9842\n",
      "Epoch 437/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0326 - accuracy: 0.9850\n",
      "Epoch 438/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0307 - accuracy: 0.9862\n",
      "Epoch 439/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0304 - accuracy: 0.9854\n",
      "Epoch 440/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0290 - accuracy: 0.9874\n",
      "Epoch 441/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0285 - accuracy: 0.9856\n",
      "Epoch 442/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0314 - accuracy: 0.9834\n",
      "Epoch 443/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0311 - accuracy: 0.9858\n",
      "Epoch 444/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0326 - accuracy: 0.9876\n",
      "Epoch 445/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0299 - accuracy: 0.9844\n",
      "Epoch 446/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0288 - accuracy: 0.9868\n",
      "Epoch 447/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0286 - accuracy: 0.9860\n",
      "Epoch 448/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0304 - accuracy: 0.9856\n",
      "Epoch 449/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0388 - accuracy: 0.9812\n",
      "Epoch 450/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0279 - accuracy: 0.9876\n",
      "Epoch 451/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0325 - accuracy: 0.9838\n",
      "Epoch 452/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0314 - accuracy: 0.9836\n",
      "Epoch 453/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0269 - accuracy: 0.9866\n",
      "Epoch 454/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0359 - accuracy: 0.9826\n",
      "Epoch 455/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0340 - accuracy: 0.9850\n",
      "Epoch 456/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0366 - accuracy: 0.9822\n",
      "Epoch 457/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0280 - accuracy: 0.9870\n",
      "Epoch 458/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0308 - accuracy: 0.9842\n",
      "Epoch 459/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0274 - accuracy: 0.9854\n",
      "Epoch 460/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0333 - accuracy: 0.9830\n",
      "Epoch 461/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0272 - accuracy: 0.9846\n",
      "Epoch 462/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0279 - accuracy: 0.9858\n",
      "Epoch 463/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0280 - accuracy: 0.9862\n",
      "Epoch 464/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0266 - accuracy: 0.9858\n",
      "Epoch 465/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0361 - accuracy: 0.9836\n",
      "Epoch 466/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0283 - accuracy: 0.9854\n",
      "Epoch 467/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0271 - accuracy: 0.9864\n",
      "Epoch 468/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0263 - accuracy: 0.9876\n",
      "Epoch 469/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0268 - accuracy: 0.9890\n",
      "Epoch 470/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0260 - accuracy: 0.9874\n",
      "Epoch 471/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0298 - accuracy: 0.9856\n",
      "Epoch 472/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0244 - accuracy: 0.9878\n",
      "Epoch 473/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0247 - accuracy: 0.9886\n",
      "Epoch 474/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0380 - accuracy: 0.9836\n",
      "Epoch 475/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0523 - accuracy: 0.9780\n",
      "Epoch 476/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.1000 - accuracy: 0.9706\n",
      "Epoch 477/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0416 - accuracy: 0.9810\n",
      "Epoch 478/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0436 - accuracy: 0.9810\n",
      "Epoch 479/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0382 - accuracy: 0.9820\n",
      "Epoch 480/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0325 - accuracy: 0.9840\n",
      "Epoch 481/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0308 - accuracy: 0.9854\n",
      "Epoch 482/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0307 - accuracy: 0.9834\n",
      "Epoch 483/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0321 - accuracy: 0.9856\n",
      "Epoch 484/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0369 - accuracy: 0.9836\n",
      "Epoch 485/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0315 - accuracy: 0.9850\n",
      "Epoch 486/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0346 - accuracy: 0.9850\n",
      "Epoch 487/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0307 - accuracy: 0.9836\n",
      "Epoch 488/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0632 - accuracy: 0.9748\n",
      "Epoch 489/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0382 - accuracy: 0.9824\n",
      "Epoch 490/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0340 - accuracy: 0.9816\n",
      "Epoch 491/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0343 - accuracy: 0.9832\n",
      "Epoch 492/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0294 - accuracy: 0.9846\n",
      "Epoch 493/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0314 - accuracy: 0.9860\n",
      "Epoch 494/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0288 - accuracy: 0.9862\n",
      "Epoch 495/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0305 - accuracy: 0.9854\n",
      "Epoch 496/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0258 - accuracy: 0.9868\n",
      "Epoch 497/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0270 - accuracy: 0.9862\n",
      "Epoch 498/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0241 - accuracy: 0.9870\n",
      "Epoch 499/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0328 - accuracy: 0.9836\n",
      "Epoch 500/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0260 - accuracy: 0.9854\n",
      "Epoch 501/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0258 - accuracy: 0.9878\n",
      "Epoch 502/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0311 - accuracy: 0.9850\n",
      "Epoch 503/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0337 - accuracy: 0.9844\n",
      "Epoch 504/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0279 - accuracy: 0.9850\n",
      "Epoch 505/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0275 - accuracy: 0.9866\n",
      "Epoch 506/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0283 - accuracy: 0.9840\n",
      "Epoch 507/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0310 - accuracy: 0.9862\n",
      "Epoch 508/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0247 - accuracy: 0.9886\n",
      "Epoch 509/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0248 - accuracy: 0.9882\n",
      "Epoch 510/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0253 - accuracy: 0.9876\n",
      "Epoch 511/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0239 - accuracy: 0.9872\n",
      "Epoch 512/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0352 - accuracy: 0.9854\n",
      "Epoch 513/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0276 - accuracy: 0.9858\n",
      "Epoch 514/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0354 - accuracy: 0.9844\n",
      "Epoch 515/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0355 - accuracy: 0.9848\n",
      "Epoch 516/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0312 - accuracy: 0.9846\n",
      "Epoch 517/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0308 - accuracy: 0.9836\n",
      "Epoch 518/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0309 - accuracy: 0.9854\n",
      "Epoch 519/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0242 - accuracy: 0.9870\n",
      "Epoch 520/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0269 - accuracy: 0.9864\n",
      "Epoch 521/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0270 - accuracy: 0.9866\n",
      "Epoch 522/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0230 - accuracy: 0.9886\n",
      "Epoch 523/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0198 - accuracy: 0.9888\n",
      "Epoch 524/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0271 - accuracy: 0.9856\n",
      "Epoch 525/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0257 - accuracy: 0.9874\n",
      "Epoch 526/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0279 - accuracy: 0.9850\n",
      "Epoch 527/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0250 - accuracy: 0.9864\n",
      "Epoch 528/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0271 - accuracy: 0.9868\n",
      "Epoch 529/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0261 - accuracy: 0.9854\n",
      "Epoch 530/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0260 - accuracy: 0.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0251 - accuracy: 0.9866\n",
      "Epoch 532/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0289 - accuracy: 0.9844\n",
      "Epoch 533/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0245 - accuracy: 0.9884\n",
      "Epoch 534/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0235 - accuracy: 0.9868\n",
      "Epoch 535/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0222 - accuracy: 0.9880\n",
      "Epoch 536/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0251 - accuracy: 0.9864\n",
      "Epoch 537/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0273 - accuracy: 0.9856\n",
      "Epoch 538/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0405 - accuracy: 0.9810\n",
      "Epoch 539/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0265 - accuracy: 0.9878\n",
      "Epoch 540/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0304 - accuracy: 0.9846\n",
      "Epoch 541/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0277 - accuracy: 0.9852\n",
      "Epoch 542/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0338 - accuracy: 0.9846\n",
      "Epoch 543/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0322 - accuracy: 0.9858\n",
      "Epoch 544/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0259 - accuracy: 0.9862\n",
      "Epoch 545/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0603 - accuracy: 0.9776\n",
      "Epoch 546/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0394 - accuracy: 0.9820\n",
      "Epoch 547/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0315 - accuracy: 0.9882\n",
      "Epoch 548/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0287 - accuracy: 0.9858\n",
      "Epoch 549/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0280 - accuracy: 0.9856\n",
      "Epoch 550/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0264 - accuracy: 0.9858\n",
      "Epoch 551/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0273 - accuracy: 0.9852\n",
      "Epoch 552/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0310 - accuracy: 0.9844\n",
      "Epoch 553/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0255 - accuracy: 0.9858\n",
      "Epoch 554/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0274 - accuracy: 0.9846\n",
      "Epoch 555/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0217 - accuracy: 0.9882\n",
      "Epoch 556/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0192 - accuracy: 0.9904\n",
      "Epoch 557/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0211 - accuracy: 0.9884\n",
      "Epoch 558/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0212 - accuracy: 0.9888\n",
      "Epoch 559/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0260 - accuracy: 0.9856\n",
      "Epoch 560/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0216 - accuracy: 0.9884\n",
      "Epoch 561/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0249 - accuracy: 0.9868\n",
      "Epoch 562/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0312 - accuracy: 0.9848\n",
      "Epoch 563/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0217 - accuracy: 0.9892\n",
      "Epoch 564/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0239 - accuracy: 0.9870\n",
      "Epoch 565/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0213 - accuracy: 0.9886\n",
      "Epoch 566/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0265 - accuracy: 0.9866\n",
      "Epoch 567/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0267 - accuracy: 0.9884\n",
      "Epoch 568/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0267 - accuracy: 0.9864\n",
      "Epoch 569/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0199 - accuracy: 0.9896\n",
      "Epoch 570/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0220 - accuracy: 0.9896\n",
      "Epoch 571/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0240 - accuracy: 0.9874\n",
      "Epoch 572/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0244 - accuracy: 0.9862\n",
      "Epoch 573/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0255 - accuracy: 0.9866\n",
      "Epoch 574/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0330 - accuracy: 0.9834\n",
      "Epoch 575/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0485 - accuracy: 0.9832\n",
      "Epoch 576/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0397 - accuracy: 0.9842\n",
      "Epoch 577/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0279 - accuracy: 0.9854\n",
      "Epoch 578/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0281 - accuracy: 0.9860\n",
      "Epoch 579/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0304 - accuracy: 0.9856\n",
      "Epoch 580/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0224 - accuracy: 0.9876\n",
      "Epoch 581/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0212 - accuracy: 0.9878\n",
      "Epoch 582/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0207 - accuracy: 0.9880\n",
      "Epoch 583/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0236 - accuracy: 0.9876\n",
      "Epoch 584/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0209 - accuracy: 0.9884\n",
      "Epoch 585/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0217 - accuracy: 0.9870\n",
      "Epoch 586/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0237 - accuracy: 0.9878\n",
      "Epoch 587/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0232 - accuracy: 0.9874\n",
      "Epoch 588/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0226 - accuracy: 0.9882\n",
      "Epoch 589/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0227 - accuracy: 0.9866\n",
      "Epoch 590/1024\n",
      "4996/4996 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.98 - 1s 175us/step - loss: 0.0205 - accuracy: 0.9874\n",
      "Epoch 591/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0200 - accuracy: 0.9896\n",
      "Epoch 592/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0228 - accuracy: 0.9878\n",
      "Epoch 593/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0237 - accuracy: 0.9868\n",
      "Epoch 594/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0299 - accuracy: 0.9868\n",
      "Epoch 595/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0237 - accuracy: 0.9862\n",
      "Epoch 596/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0226 - accuracy: 0.9864\n",
      "Epoch 597/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0242 - accuracy: 0.9880\n",
      "Epoch 598/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0191 - accuracy: 0.9878\n",
      "Epoch 599/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0222 - accuracy: 0.9872\n",
      "Epoch 600/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0195 - accuracy: 0.9890\n",
      "Epoch 601/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0246 - accuracy: 0.9862\n",
      "Epoch 602/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0211 - accuracy: 0.9896\n",
      "Epoch 603/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0196 - accuracy: 0.9870\n",
      "Epoch 604/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0218 - accuracy: 0.9884\n",
      "Epoch 605/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0229 - accuracy: 0.9856\n",
      "Epoch 606/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0221 - accuracy: 0.9880\n",
      "Epoch 607/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0234 - accuracy: 0.9858\n",
      "Epoch 608/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0241 - accuracy: 0.9876\n",
      "Epoch 609/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0245 - accuracy: 0.9864\n",
      "Epoch 610/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0255 - accuracy: 0.9878\n",
      "Epoch 611/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0205 - accuracy: 0.9890\n",
      "Epoch 612/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0218 - accuracy: 0.9896\n",
      "Epoch 613/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0220 - accuracy: 0.9872\n",
      "Epoch 614/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0391 - accuracy: 0.9836\n",
      "Epoch 615/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0219 - accuracy: 0.9882\n",
      "Epoch 616/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0267 - accuracy: 0.9882\n",
      "Epoch 617/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0243 - accuracy: 0.9874\n",
      "Epoch 618/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0306 - accuracy: 0.9856\n",
      "Epoch 619/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0250 - accuracy: 0.9870\n",
      "Epoch 620/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0215 - accuracy: 0.9874\n",
      "Epoch 621/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0192 - accuracy: 0.9890\n",
      "Epoch 622/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0224 - accuracy: 0.9868\n",
      "Epoch 623/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0218 - accuracy: 0.9892\n",
      "Epoch 624/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0192 - accuracy: 0.9888\n",
      "Epoch 625/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0198 - accuracy: 0.9906\n",
      "Epoch 626/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0200 - accuracy: 0.9894\n",
      "Epoch 627/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0191 - accuracy: 0.9896\n",
      "Epoch 628/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0217 - accuracy: 0.9884\n",
      "Epoch 629/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0210 - accuracy: 0.9868\n",
      "Epoch 630/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0224 - accuracy: 0.9870\n",
      "Epoch 631/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0304 - accuracy: 0.9864\n",
      "Epoch 632/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0283 - accuracy: 0.9876\n",
      "Epoch 633/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0309 - accuracy: 0.9874\n",
      "Epoch 634/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0270 - accuracy: 0.9868\n",
      "Epoch 635/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0420 - accuracy: 0.9824\n",
      "Epoch 636/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0479 - accuracy: 0.9788\n",
      "Epoch 637/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0276 - accuracy: 0.9848\n",
      "Epoch 638/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0278 - accuracy: 0.9854\n",
      "Epoch 639/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0258 - accuracy: 0.9868\n",
      "Epoch 640/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0245 - accuracy: 0.9872\n",
      "Epoch 641/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0252 - accuracy: 0.9872\n",
      "Epoch 642/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0209 - accuracy: 0.9888\n",
      "Epoch 643/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0223 - accuracy: 0.9868\n",
      "Epoch 644/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0261 - accuracy: 0.9856\n",
      "Epoch 645/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0229 - accuracy: 0.9886\n",
      "Epoch 646/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0217 - accuracy: 0.9878\n",
      "Epoch 647/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0208 - accuracy: 0.9882\n",
      "Epoch 648/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0226 - accuracy: 0.9874\n",
      "Epoch 649/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0193 - accuracy: 0.9886\n",
      "Epoch 650/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0261 - accuracy: 0.9864\n",
      "Epoch 651/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0190 - accuracy: 0.9884\n",
      "Epoch 652/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0196 - accuracy: 0.9884\n",
      "Epoch 653/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0200 - accuracy: 0.9888\n",
      "Epoch 654/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0217 - accuracy: 0.9884\n",
      "Epoch 655/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0248 - accuracy: 0.9866\n",
      "Epoch 656/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0328 - accuracy: 0.9836\n",
      "Epoch 657/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0241 - accuracy: 0.9870\n",
      "Epoch 658/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0243 - accuracy: 0.9874\n",
      "Epoch 659/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0250 - accuracy: 0.9866\n",
      "Epoch 660/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0241 - accuracy: 0.9864\n",
      "Epoch 661/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0208 - accuracy: 0.9894\n",
      "Epoch 662/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0223 - accuracy: 0.9878\n",
      "Epoch 663/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0471 - accuracy: 0.9824\n",
      "Epoch 664/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0312 - accuracy: 0.9840\n",
      "Epoch 665/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0272 - accuracy: 0.9858\n",
      "Epoch 666/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0244 - accuracy: 0.9854\n",
      "Epoch 667/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0250 - accuracy: 0.9880\n",
      "Epoch 668/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0249 - accuracy: 0.9872\n",
      "Epoch 669/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0235 - accuracy: 0.9874\n",
      "Epoch 670/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0269 - accuracy: 0.9864\n",
      "Epoch 671/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0264 - accuracy: 0.9872\n",
      "Epoch 672/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0276 - accuracy: 0.9846\n",
      "Epoch 673/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0251 - accuracy: 0.9868\n",
      "Epoch 674/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0258 - accuracy: 0.9878\n",
      "Epoch 675/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0235 - accuracy: 0.9860\n",
      "Epoch 676/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0229 - accuracy: 0.9894\n",
      "Epoch 677/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0245 - accuracy: 0.9870\n",
      "Epoch 678/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0206 - accuracy: 0.9894\n",
      "Epoch 679/1024\n",
      "4996/4996 [==============================] - 1s 190us/step - loss: 0.0240 - accuracy: 0.9864\n",
      "Epoch 680/1024\n",
      "4996/4996 [==============================] - 1s 190us/step - loss: 0.0231 - accuracy: 0.9884\n",
      "Epoch 681/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0198 - accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0204 - accuracy: 0.9888\n",
      "Epoch 683/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0207 - accuracy: 0.9880\n",
      "Epoch 684/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0215 - accuracy: 0.9880\n",
      "Epoch 685/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0314 - accuracy: 0.9864\n",
      "Epoch 686/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0202 - accuracy: 0.9894\n",
      "Epoch 687/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0226 - accuracy: 0.9886\n",
      "Epoch 688/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0250 - accuracy: 0.9872\n",
      "Epoch 689/1024\n",
      "4996/4996 [==============================] - 1s 187us/step - loss: 0.0196 - accuracy: 0.9884\n",
      "Epoch 690/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0222 - accuracy: 0.9866\n",
      "Epoch 691/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0241 - accuracy: 0.9858\n",
      "Epoch 692/1024\n",
      "4996/4996 [==============================] - 1s 194us/step - loss: 0.0269 - accuracy: 0.9870\n",
      "Epoch 693/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0210 - accuracy: 0.9890\n",
      "Epoch 694/1024\n",
      "4996/4996 [==============================] - 1s 193us/step - loss: 0.0240 - accuracy: 0.9874\n",
      "Epoch 695/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0218 - accuracy: 0.9874\n",
      "Epoch 696/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0259 - accuracy: 0.9884\n",
      "Epoch 697/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0211 - accuracy: 0.9884\n",
      "Epoch 698/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0191 - accuracy: 0.9884\n",
      "Epoch 699/1024\n",
      "4996/4996 [==============================] - 1s 187us/step - loss: 0.0246 - accuracy: 0.9858\n",
      "Epoch 700/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0223 - accuracy: 0.9894\n",
      "Epoch 701/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0350 - accuracy: 0.9850\n",
      "Epoch 702/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0198 - accuracy: 0.9882\n",
      "Epoch 703/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0260 - accuracy: 0.9872\n",
      "Epoch 704/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0247 - accuracy: 0.9860\n",
      "Epoch 705/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0206 - accuracy: 0.9874\n",
      "Epoch 706/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0177 - accuracy: 0.9892\n",
      "Epoch 707/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0188 - accuracy: 0.9886\n",
      "Epoch 708/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0189 - accuracy: 0.9894\n",
      "Epoch 709/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0204 - accuracy: 0.9880\n",
      "Epoch 710/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0218 - accuracy: 0.9880\n",
      "Epoch 711/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0185 - accuracy: 0.9904\n",
      "Epoch 712/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0359 - accuracy: 0.9840\n",
      "Epoch 713/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0241 - accuracy: 0.9884\n",
      "Epoch 714/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0219 - accuracy: 0.9896\n",
      "Epoch 715/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0207 - accuracy: 0.9878\n",
      "Epoch 716/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0198 - accuracy: 0.9870\n",
      "Epoch 717/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0210 - accuracy: 0.9866\n",
      "Epoch 718/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0208 - accuracy: 0.9896\n",
      "Epoch 719/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0187 - accuracy: 0.9884\n",
      "Epoch 720/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0190 - accuracy: 0.9892\n",
      "Epoch 721/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0162 - accuracy: 0.9906\n",
      "Epoch 722/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0174 - accuracy: 0.9900\n",
      "Epoch 723/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0202 - accuracy: 0.9908\n",
      "Epoch 724/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0201 - accuracy: 0.9888\n",
      "Epoch 725/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0196 - accuracy: 0.9888\n",
      "Epoch 726/1024\n",
      "4996/4996 [==============================] - 1s 196us/step - loss: 0.0184 - accuracy: 0.9866\n",
      "Epoch 727/1024\n",
      "4996/4996 [==============================] - 1s 191us/step - loss: 0.0207 - accuracy: 0.9892\n",
      "Epoch 728/1024\n",
      "4996/4996 [==============================] - 1s 189us/step - loss: 0.0223 - accuracy: 0.9872\n",
      "Epoch 729/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.1586 - accuracy: 0.9514\n",
      "Epoch 730/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0514 - accuracy: 0.9796\n",
      "Epoch 731/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0374 - accuracy: 0.9836\n",
      "Epoch 732/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0293 - accuracy: 0.9846\n",
      "Epoch 733/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0352 - accuracy: 0.9834\n",
      "Epoch 734/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0412 - accuracy: 0.9818\n",
      "Epoch 735/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0295 - accuracy: 0.9856\n",
      "Epoch 736/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0270 - accuracy: 0.9854\n",
      "Epoch 737/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0240 - accuracy: 0.9878\n",
      "Epoch 738/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0232 - accuracy: 0.9880\n",
      "Epoch 739/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0248 - accuracy: 0.9872\n",
      "Epoch 740/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0260 - accuracy: 0.9870\n",
      "Epoch 741/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0241 - accuracy: 0.9868\n",
      "Epoch 742/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0245 - accuracy: 0.9882\n",
      "Epoch 743/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0211 - accuracy: 0.9870\n",
      "Epoch 744/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0245 - accuracy: 0.9874\n",
      "Epoch 745/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0199 - accuracy: 0.9888\n",
      "Epoch 746/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0249 - accuracy: 0.9872\n",
      "Epoch 747/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0199 - accuracy: 0.9884\n",
      "Epoch 748/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0213 - accuracy: 0.9882\n",
      "Epoch 749/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0192 - accuracy: 0.9890\n",
      "Epoch 750/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0209 - accuracy: 0.9886\n",
      "Epoch 751/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0339 - accuracy: 0.9858\n",
      "Epoch 752/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0271 - accuracy: 0.9864\n",
      "Epoch 753/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0237 - accuracy: 0.9866\n",
      "Epoch 754/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0239 - accuracy: 0.9872\n",
      "Epoch 755/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0203 - accuracy: 0.9896\n",
      "Epoch 756/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0294 - accuracy: 0.9850\n",
      "Epoch 757/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0217 - accuracy: 0.9884\n",
      "Epoch 758/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0255 - accuracy: 0.9866\n",
      "Epoch 759/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0217 - accuracy: 0.9880\n",
      "Epoch 760/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0189 - accuracy: 0.9884\n",
      "Epoch 761/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0212 - accuracy: 0.9896\n",
      "Epoch 762/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0208 - accuracy: 0.9868\n",
      "Epoch 763/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0190 - accuracy: 0.9900\n",
      "Epoch 764/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0219 - accuracy: 0.9882\n",
      "Epoch 765/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0219 - accuracy: 0.9884\n",
      "Epoch 766/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0222 - accuracy: 0.9882\n",
      "Epoch 767/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0171 - accuracy: 0.9882\n",
      "Epoch 768/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0205 - accuracy: 0.9898\n",
      "Epoch 769/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0231 - accuracy: 0.9866\n",
      "Epoch 770/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0203 - accuracy: 0.9884\n",
      "Epoch 771/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0199 - accuracy: 0.9892\n",
      "Epoch 772/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0221 - accuracy: 0.9878\n",
      "Epoch 773/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0226 - accuracy: 0.9886\n",
      "Epoch 774/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0201 - accuracy: 0.9890\n",
      "Epoch 775/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0233 - accuracy: 0.9870\n",
      "Epoch 776/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0204 - accuracy: 0.9880\n",
      "Epoch 777/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0203 - accuracy: 0.9866\n",
      "Epoch 778/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0174 - accuracy: 0.9908\n",
      "Epoch 779/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0177 - accuracy: 0.9894\n",
      "Epoch 780/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0166 - accuracy: 0.9884\n",
      "Epoch 781/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0211 - accuracy: 0.9864\n",
      "Epoch 782/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0188 - accuracy: 0.9882\n",
      "Epoch 783/1024\n",
      "4996/4996 [==============================] - 1s 187us/step - loss: 0.0184 - accuracy: 0.9878\n",
      "Epoch 784/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0551 - accuracy: 0.9800\n",
      "Epoch 785/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0265 - accuracy: 0.9864\n",
      "Epoch 786/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0219 - accuracy: 0.9870\n",
      "Epoch 787/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0200 - accuracy: 0.9878\n",
      "Epoch 788/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0200 - accuracy: 0.9882\n",
      "Epoch 789/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0191 - accuracy: 0.9914\n",
      "Epoch 790/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0166 - accuracy: 0.9904\n",
      "Epoch 791/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0170 - accuracy: 0.9890\n",
      "Epoch 792/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0224 - accuracy: 0.9872\n",
      "Epoch 793/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0184 - accuracy: 0.9896\n",
      "Epoch 794/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0166 - accuracy: 0.9896\n",
      "Epoch 795/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0175 - accuracy: 0.9896\n",
      "Epoch 796/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0187 - accuracy: 0.9878\n",
      "Epoch 797/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0216 - accuracy: 0.9882\n",
      "Epoch 798/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0201 - accuracy: 0.9896\n",
      "Epoch 799/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0221 - accuracy: 0.9888\n",
      "Epoch 800/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0186 - accuracy: 0.9898\n",
      "Epoch 801/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0208 - accuracy: 0.9894\n",
      "Epoch 802/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0178 - accuracy: 0.9878\n",
      "Epoch 803/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0166 - accuracy: 0.9904\n",
      "Epoch 804/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0172 - accuracy: 0.9882\n",
      "Epoch 805/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0204 - accuracy: 0.9892\n",
      "Epoch 806/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0172 - accuracy: 0.9890\n",
      "Epoch 807/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0176 - accuracy: 0.9898\n",
      "Epoch 808/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0182 - accuracy: 0.9890\n",
      "Epoch 809/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0172 - accuracy: 0.9892\n",
      "Epoch 810/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0307 - accuracy: 0.9874\n",
      "Epoch 811/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0441 - accuracy: 0.9824\n",
      "Epoch 812/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0512 - accuracy: 0.9800\n",
      "Epoch 813/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0319 - accuracy: 0.9840\n",
      "Epoch 814/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0273 - accuracy: 0.9856\n",
      "Epoch 815/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0257 - accuracy: 0.9878\n",
      "Epoch 816/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0219 - accuracy: 0.9890\n",
      "Epoch 817/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0258 - accuracy: 0.9872\n",
      "Epoch 818/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0190 - accuracy: 0.9894\n",
      "Epoch 819/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0277 - accuracy: 0.9862\n",
      "Epoch 820/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0219 - accuracy: 0.9886\n",
      "Epoch 821/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0272 - accuracy: 0.9878\n",
      "Epoch 822/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0230 - accuracy: 0.9884\n",
      "Epoch 823/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0201 - accuracy: 0.9886\n",
      "Epoch 824/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0215 - accuracy: 0.9880\n",
      "Epoch 825/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0265 - accuracy: 0.9864\n",
      "Epoch 826/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0181 - accuracy: 0.9890\n",
      "Epoch 827/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0214 - accuracy: 0.9872\n",
      "Epoch 828/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0175 - accuracy: 0.9910\n",
      "Epoch 829/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0192 - accuracy: 0.9886\n",
      "Epoch 830/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0180 - accuracy: 0.9882\n",
      "Epoch 831/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0174 - accuracy: 0.9906\n",
      "Epoch 832/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0251 - accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0209 - accuracy: 0.9898\n",
      "Epoch 834/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0223 - accuracy: 0.9882\n",
      "Epoch 835/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0214 - accuracy: 0.9874\n",
      "Epoch 836/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0194 - accuracy: 0.9872\n",
      "Epoch 837/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0174 - accuracy: 0.9884\n",
      "Epoch 838/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0165 - accuracy: 0.9886\n",
      "Epoch 839/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0187 - accuracy: 0.9888\n",
      "Epoch 840/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0170 - accuracy: 0.9904\n",
      "Epoch 841/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0174 - accuracy: 0.9908\n",
      "Epoch 842/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0210 - accuracy: 0.9878\n",
      "Epoch 843/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0182 - accuracy: 0.9896\n",
      "Epoch 844/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0210 - accuracy: 0.9886\n",
      "Epoch 845/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0181 - accuracy: 0.9880\n",
      "Epoch 846/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0183 - accuracy: 0.9890\n",
      "Epoch 847/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0181 - accuracy: 0.9892\n",
      "Epoch 848/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0166 - accuracy: 0.9894\n",
      "Epoch 849/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0187 - accuracy: 0.9892\n",
      "Epoch 850/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0202 - accuracy: 0.9876\n",
      "Epoch 851/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0178 - accuracy: 0.9902\n",
      "Epoch 852/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0267 - accuracy: 0.9870\n",
      "Epoch 853/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0206 - accuracy: 0.9892\n",
      "Epoch 854/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0169 - accuracy: 0.9884\n",
      "Epoch 855/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0202 - accuracy: 0.9870\n",
      "Epoch 856/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0168 - accuracy: 0.9888\n",
      "Epoch 857/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0190 - accuracy: 0.9906\n",
      "Epoch 858/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0183 - accuracy: 0.9894\n",
      "Epoch 859/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0189 - accuracy: 0.9880\n",
      "Epoch 860/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0191 - accuracy: 0.9894\n",
      "Epoch 861/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0188 - accuracy: 0.9876\n",
      "Epoch 862/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0174 - accuracy: 0.9890\n",
      "Epoch 863/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0193 - accuracy: 0.9882\n",
      "Epoch 864/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0172 - accuracy: 0.9886\n",
      "Epoch 865/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0173 - accuracy: 0.9900\n",
      "Epoch 866/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0188 - accuracy: 0.9888\n",
      "Epoch 867/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0190 - accuracy: 0.9878\n",
      "Epoch 868/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0176 - accuracy: 0.9908\n",
      "Epoch 869/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0166 - accuracy: 0.9892\n",
      "Epoch 870/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0160 - accuracy: 0.9904\n",
      "Epoch 871/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0175 - accuracy: 0.9884\n",
      "Epoch 872/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0170 - accuracy: 0.9902\n",
      "Epoch 873/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0174 - accuracy: 0.9890\n",
      "Epoch 874/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0173 - accuracy: 0.9900\n",
      "Epoch 875/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0199 - accuracy: 0.9892\n",
      "Epoch 876/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0196 - accuracy: 0.9878\n",
      "Epoch 877/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0180 - accuracy: 0.9892\n",
      "Epoch 878/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0168 - accuracy: 0.9902\n",
      "Epoch 879/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0172 - accuracy: 0.9888\n",
      "Epoch 880/1024\n",
      "4996/4996 [==============================] - 1s 195us/step - loss: 0.0151 - accuracy: 0.9900\n",
      "Epoch 881/1024\n",
      "4996/4996 [==============================] - 1s 192us/step - loss: 0.0158 - accuracy: 0.9906\n",
      "Epoch 882/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0180 - accuracy: 0.9888\n",
      "Epoch 883/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0224 - accuracy: 0.9874\n",
      "Epoch 884/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0225 - accuracy: 0.9884\n",
      "Epoch 885/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0206 - accuracy: 0.9892\n",
      "Epoch 886/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0173 - accuracy: 0.9898\n",
      "Epoch 887/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0194 - accuracy: 0.9878\n",
      "Epoch 888/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0174 - accuracy: 0.9890\n",
      "Epoch 889/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0153 - accuracy: 0.9898\n",
      "Epoch 890/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0175 - accuracy: 0.9886\n",
      "Epoch 891/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0165 - accuracy: 0.9882\n",
      "Epoch 892/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0167 - accuracy: 0.9894\n",
      "Epoch 893/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0176 - accuracy: 0.9892\n",
      "Epoch 894/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0170 - accuracy: 0.9892\n",
      "Epoch 895/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0167 - accuracy: 0.9894\n",
      "Epoch 896/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0172 - accuracy: 0.9894\n",
      "Epoch 897/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0163 - accuracy: 0.9902\n",
      "Epoch 898/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0179 - accuracy: 0.9894\n",
      "Epoch 899/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0179 - accuracy: 0.9888\n",
      "Epoch 900/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0169 - accuracy: 0.9886\n",
      "Epoch 901/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0166 - accuracy: 0.9890\n",
      "Epoch 902/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0162 - accuracy: 0.9888\n",
      "Epoch 903/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0216 - accuracy: 0.9870\n",
      "Epoch 904/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0189 - accuracy: 0.9874\n",
      "Epoch 905/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0191 - accuracy: 0.9892\n",
      "Epoch 906/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0202 - accuracy: 0.9896\n",
      "Epoch 907/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0182 - accuracy: 0.9898\n",
      "Epoch 908/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0213 - accuracy: 0.9884\n",
      "Epoch 909/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0195 - accuracy: 0.9884\n",
      "Epoch 910/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0168 - accuracy: 0.9898\n",
      "Epoch 911/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0166 - accuracy: 0.9886\n",
      "Epoch 912/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0164 - accuracy: 0.9886\n",
      "Epoch 913/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0166 - accuracy: 0.9892\n",
      "Epoch 914/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0158 - accuracy: 0.9882\n",
      "Epoch 915/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0190 - accuracy: 0.9878\n",
      "Epoch 916/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0162 - accuracy: 0.9884\n",
      "Epoch 917/1024\n",
      "4996/4996 [==============================] - 1s 172us/step - loss: 0.0153 - accuracy: 0.9900\n",
      "Epoch 918/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0168 - accuracy: 0.9902\n",
      "Epoch 919/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0169 - accuracy: 0.9894\n",
      "Epoch 920/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0189 - accuracy: 0.9896\n",
      "Epoch 921/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0166 - accuracy: 0.9904\n",
      "Epoch 922/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0158 - accuracy: 0.9882\n",
      "Epoch 923/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0162 - accuracy: 0.9898\n",
      "Epoch 924/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0167 - accuracy: 0.9886\n",
      "Epoch 925/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0214 - accuracy: 0.9864\n",
      "Epoch 926/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0172 - accuracy: 0.9906\n",
      "Epoch 927/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0174 - accuracy: 0.9906\n",
      "Epoch 928/1024\n",
      "4996/4996 [==============================] - 1s 190us/step - loss: 0.0193 - accuracy: 0.9888\n",
      "Epoch 929/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0164 - accuracy: 0.9896\n",
      "Epoch 930/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0160 - accuracy: 0.9886\n",
      "Epoch 931/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0171 - accuracy: 0.9900\n",
      "Epoch 932/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0191 - accuracy: 0.9892\n",
      "Epoch 933/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0155 - accuracy: 0.9896\n",
      "Epoch 934/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0180 - accuracy: 0.9894\n",
      "Epoch 935/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0164 - accuracy: 0.9900\n",
      "Epoch 936/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0170 - accuracy: 0.9888\n",
      "Epoch 937/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0189 - accuracy: 0.9898\n",
      "Epoch 938/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0248 - accuracy: 0.9874\n",
      "Epoch 939/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0182 - accuracy: 0.9888\n",
      "Epoch 940/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0165 - accuracy: 0.9896\n",
      "Epoch 941/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0178 - accuracy: 0.9866\n",
      "Epoch 942/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0179 - accuracy: 0.9892\n",
      "Epoch 943/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0165 - accuracy: 0.9900\n",
      "Epoch 944/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0154 - accuracy: 0.9898\n",
      "Epoch 945/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0174 - accuracy: 0.9900\n",
      "Epoch 946/1024\n",
      "4996/4996 [==============================] - 1s 186us/step - loss: 0.0156 - accuracy: 0.9896\n",
      "Epoch 947/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0161 - accuracy: 0.9886\n",
      "Epoch 948/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0171 - accuracy: 0.9898\n",
      "Epoch 949/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0148 - accuracy: 0.9912\n",
      "Epoch 950/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0163 - accuracy: 0.9892\n",
      "Epoch 951/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0174 - accuracy: 0.9904\n",
      "Epoch 952/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0162 - accuracy: 0.9894\n",
      "Epoch 953/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0150 - accuracy: 0.9904\n",
      "Epoch 954/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0167 - accuracy: 0.9888\n",
      "Epoch 955/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0159 - accuracy: 0.9892\n",
      "Epoch 956/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0150 - accuracy: 0.9902\n",
      "Epoch 957/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0169 - accuracy: 0.9888\n",
      "Epoch 958/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0201 - accuracy: 0.9898\n",
      "Epoch 959/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0224 - accuracy: 0.9872\n",
      "Epoch 960/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0196 - accuracy: 0.9892\n",
      "Epoch 961/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0179 - accuracy: 0.9872\n",
      "Epoch 962/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0202 - accuracy: 0.9874\n",
      "Epoch 963/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0170 - accuracy: 0.9890\n",
      "Epoch 964/1024\n",
      "4996/4996 [==============================] - 1s 184us/step - loss: 0.0173 - accuracy: 0.9900\n",
      "Epoch 965/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0181 - accuracy: 0.9906\n",
      "Epoch 966/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0164 - accuracy: 0.9886\n",
      "Epoch 967/1024\n",
      "4996/4996 [==============================] - 1s 191us/step - loss: 0.0167 - accuracy: 0.9888\n",
      "Epoch 968/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0190 - accuracy: 0.9876\n",
      "Epoch 969/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0189 - accuracy: 0.9892\n",
      "Epoch 970/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0161 - accuracy: 0.9916\n",
      "Epoch 971/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0159 - accuracy: 0.9888\n",
      "Epoch 972/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0181 - accuracy: 0.9886\n",
      "Epoch 973/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0195 - accuracy: 0.9892\n",
      "Epoch 974/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0195 - accuracy: 0.9890\n",
      "Epoch 975/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0191 - accuracy: 0.9878\n",
      "Epoch 976/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0181 - accuracy: 0.9890\n",
      "Epoch 977/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0192 - accuracy: 0.9888\n",
      "Epoch 978/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0167 - accuracy: 0.9890\n",
      "Epoch 979/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0181 - accuracy: 0.9882\n",
      "Epoch 980/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0167 - accuracy: 0.9906\n",
      "Epoch 981/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0158 - accuracy: 0.9900\n",
      "Epoch 982/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0169 - accuracy: 0.9892\n",
      "Epoch 983/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0162 - accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0159 - accuracy: 0.9890\n",
      "Epoch 985/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0155 - accuracy: 0.9908\n",
      "Epoch 986/1024\n",
      "4996/4996 [==============================] - 1s 174us/step - loss: 0.0161 - accuracy: 0.9906\n",
      "Epoch 987/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0173 - accuracy: 0.9882\n",
      "Epoch 988/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0168 - accuracy: 0.9880\n",
      "Epoch 989/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0171 - accuracy: 0.9892\n",
      "Epoch 990/1024\n",
      "4996/4996 [==============================] - 1s 173us/step - loss: 0.0160 - accuracy: 0.9892\n",
      "Epoch 991/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0156 - accuracy: 0.9900\n",
      "Epoch 992/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0147 - accuracy: 0.9900\n",
      "Epoch 993/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0229 - accuracy: 0.9874\n",
      "Epoch 994/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0210 - accuracy: 0.9880\n",
      "Epoch 995/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0184 - accuracy: 0.9890\n",
      "Epoch 996/1024\n",
      "4996/4996 [==============================] - 1s 189us/step - loss: 0.0175 - accuracy: 0.9874\n",
      "Epoch 997/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0184 - accuracy: 0.9896\n",
      "Epoch 998/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0207 - accuracy: 0.9878\n",
      "Epoch 999/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0208 - accuracy: 0.9880\n",
      "Epoch 1000/1024\n",
      "4996/4996 [==============================] - 1s 177us/step - loss: 0.0192 - accuracy: 0.9870\n",
      "Epoch 1001/1024\n",
      "4996/4996 [==============================] - 1s 176us/step - loss: 0.0204 - accuracy: 0.9880\n",
      "Epoch 1002/1024\n",
      "4996/4996 [==============================] - 1s 178us/step - loss: 0.0162 - accuracy: 0.9886\n",
      "Epoch 1003/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0166 - accuracy: 0.9892\n",
      "Epoch 1004/1024\n",
      "4996/4996 [==============================] - 1s 179us/step - loss: 0.0161 - accuracy: 0.9882\n",
      "Epoch 1005/1024\n",
      "4996/4996 [==============================] - 1s 191us/step - loss: 0.0159 - accuracy: 0.9884\n",
      "Epoch 1006/1024\n",
      "4996/4996 [==============================] - 1s 195us/step - loss: 0.0173 - accuracy: 0.9902\n",
      "Epoch 1007/1024\n",
      "4996/4996 [==============================] - 1s 185us/step - loss: 0.0201 - accuracy: 0.9872\n",
      "Epoch 1008/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0171 - accuracy: 0.9894\n",
      "Epoch 1009/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0166 - accuracy: 0.9886\n",
      "Epoch 1010/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0157 - accuracy: 0.9892\n",
      "Epoch 1011/1024\n",
      "4996/4996 [==============================] - 1s 175us/step - loss: 0.0159 - accuracy: 0.9908\n",
      "Epoch 1012/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0167 - accuracy: 0.9906\n",
      "Epoch 1013/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0154 - accuracy: 0.9908\n",
      "Epoch 1014/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0170 - accuracy: 0.9902\n",
      "Epoch 1015/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0158 - accuracy: 0.9892\n",
      "Epoch 1016/1024\n",
      "4996/4996 [==============================] - 1s 180us/step - loss: 0.0173 - accuracy: 0.9896\n",
      "Epoch 1017/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0191 - accuracy: 0.9878\n",
      "Epoch 1018/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0177 - accuracy: 0.9888\n",
      "Epoch 1019/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0174 - accuracy: 0.9892\n",
      "Epoch 1020/1024\n",
      "4996/4996 [==============================] - 1s 181us/step - loss: 0.0170 - accuracy: 0.9902\n",
      "Epoch 1021/1024\n",
      "4996/4996 [==============================] - 1s 188us/step - loss: 0.0191 - accuracy: 0.9882\n",
      "Epoch 1022/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0172 - accuracy: 0.9878\n",
      "Epoch 1023/1024\n",
      "4996/4996 [==============================] - 1s 182us/step - loss: 0.0171 - accuracy: 0.9896\n",
      "Epoch 1024/1024\n",
      "4996/4996 [==============================] - 1s 183us/step - loss: 0.0169 - accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(40,40,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=5, activation='relu',strides=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=5, activation='relu',strides=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='random_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#Compiling the neural network\n",
    "model.compile(optimizer =optimizers.Adam(amsgrad=True),loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "history = model.fit(X_train,y_train, batch_size=32, epochs=1024, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 38, 38, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 324,417\n",
      "Trainable params: 324,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6771662e5c0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../Figures/CNN_model.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         raise ImportError(\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='../Figures/CNN_model.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 0s 70us/step\n"
     ]
    }
   ],
   "source": [
    "eval_model=model.evaluate(X_train, y_train)\n",
    "eval_model\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('../Figures/CNN_MNIST.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[614  23]\n",
      " [ 66 547]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(cm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[614  23]\n",
      " [ 66 547]]\n",
      "Error Rate:7.120%\n",
      "Accuracy:92.880%\n",
      "Sensitivity:96.389%\n",
      "Specificity :89.233%\n",
      "Precision:90.294%\n",
      "False Positive Rate:10.767%\n",
      "Matthews Correlation Coefficient:85.940%\n",
      "F1 Score:92.477%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, matthews_corrcoef\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "MCC = matthews_corrcoef(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Error Rate:\"+'{:.3%}'.format((cm[0,1]+cm[1,0])/np.sum(cm)))\n",
    "print(\"Accuracy:\"+'{:.3%}'.format((cm[0,0]+cm[1,1])/np.sum(cm)))\n",
    "print(\"Sensitivity:\"+'{:.3%}'.format((cm[0,0])/np.sum(cm[0,:])))\n",
    "print(\"Specificity :\"+'{:.3%}'.format((cm[1,1])/np.sum(cm[1,:])))\n",
    "print(\"Precision:\"+'{:.3%}'.format((cm[0,0])/np.sum(cm[:,0])))\n",
    "print(\"False Positive Rate:\"+'{:.3%}'.format(1-((cm[1,1])/np.sum(cm[1,:]))))\n",
    "print(\"Matthews Correlation Coefficient:\"+'{:.3%}'.format(MCC))\n",
    "print(\"F1 Score:\"+'{:.3%}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/CNN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in glob.iglob('../Data/cutouts/starfits/*fits', recursive=True):\n",
    "    fp = Path(filepath)\n",
    "    hdulist = fits.open(fp)\n",
    "    scidata = hdulist[0].data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../Data/cutouts/starfits/starfits-256.fits'\n",
    "fp = Path(filepath)\n",
    "hdulist = fits.open(fp)\n",
    "scidata = hdulist[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC(matrix):\n",
    "    '''\n",
    "    Calcualtes the Matthews Correlation Coefficient from a confusion matrix\n",
    "    '''\n",
    "    return ((matrix[0,0]*matrix[1,1])-(matrix[1,0]*matrix[0,1]))/np.sqrt((cm[0,0]+cm[1,0])*(cm[0,0]+cm[0,1])*(cm[1,1]+cm[1,0])*(cm[1,1]+cm[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stars should return 0, galaxies return 1\n",
    "model.predict(scidata.reshape(1,40,40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier()\n",
    "# Feed the image classifier with training data.\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(X_test)\n",
    "print(predicted_y)\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "z.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(\"modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
